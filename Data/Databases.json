{
    "Databases": {
        "http://arxiv.org/abs/1810.12100v4": {
            "Paper Title": "The FOLE Table",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.10726v2": {
            "Paper Title": "QDR-Tree: An Efficient Index Scheme for Complex Spatial Keyword Query",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.01538v2": {
            "Paper Title": "A Practical Approach to Proper Inference with Linked Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.00335v3": {
            "Paper Title": "Understanding tree: a tool for estimating one's understanding of\n  conceptual knowledge",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.06402v3": {
            "Paper Title": "RAQ: Relationship-Aware Graph Querying in Large Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.04249v5": {
            "Paper Title": "CoCoS: Fast and Accurate Distributed Triangle Counting in Graph Streams",
            "Sentences": [
                {
                    "Sentence ID": 1,
                    "Sentence": ", (parallel) Neighborhood\nSampling ( NS) [28,29,38], and Graph Sample and Hold ( GSH \ud835\udc47) ",
                    "Citation Text": "Nesreen K Ahmed, Nick Duffield, Jennifer Neville, and Ramana Kompella. 2014. Graph sample and hold: A framework\nfor big-graph analytics. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and\ndata mining . ACM, 1446\u20131455.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1403.3909",
                        "Citation Paper Title": "Title:Graph Sample and Hold: A Framework for Big-Graph Analytics",
                        "Citation Paper Abstract": "Abstract:Sampling is a standard approach in big-graph analytics; the goal is to efficiently estimate the graph properties by consulting a sample of the whole population. A perfect sample is assumed to mirror every property of the whole population. Unfortunately, such a perfect sample is hard to collect in complex populations such as graphs (e.g. web graphs, social networks etc), where an underlying network connects the units of the population. Therefore, a good sample will be representative in the sense that graph properties of interest can be estimated with a known degree of accuracy. While previous work focused particularly on sampling schemes used to estimate certain graph properties (e.g. triangle count), much less is known for the case when we need to estimate various graph properties with the same sampling scheme. In this paper, we propose a generic stream sampling framework for big-graph analytics, called Graph Sample and Hold (gSH). To begin, the proposed framework samples from massive graphs sequentially in a single pass, one edge at a time, while maintaining a small state. We then show how to produce unbiased estimators for various graph properties from the sample. Given that the graph analysis algorithms will run on a sample instead of the whole population, the runtime complexity of these algorithm is kept under control. Moreover, given that the estimators of graph properties are unbiased, the approximation error is kept under control. Finally, we show the performance of the proposed framework (gSH) on various types of graphs, such as social graphs, among others.",
                        "Citation Paper Authors": "Authors:Nesreen K. Ahmed, Nick Duffield, Jennifer Neville, Ramana Kompella"
                    }
                },
                {
                    "Sentence ID": 9,
                    "Sentence": "proposed REPT , which is a parallel version of Mascot in multi-core settings.\nEach processor maintains a separate sample of edges, while all processors update their estimates\nwhenever an edge arrives.\nDe Stefani et al. ",
                    "Citation Text": "Lorenzo De Stefani, Alessandro Epasto, Matteo Riondato, and Eli Upfal. 2017. Tri\u00e8st: counting local and global triangles\nin fully dynamic streams with fixed memory size. ACM Transactions on Knowledge Discovery from Data 11, 4 (2017), 43.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1602.07424",
                        "Citation Paper Title": "Title:TRI\u00c8ST: Counting Local and Global Triangles in Fully-dynamic Streams with Fixed Memory Size",
                        "Citation Paper Abstract": "Abstract:We present TRI\u00c8ST, a suite of one-pass streaming algorithms to compute unbiased, low-variance, high-quality approximations of the global and local (i.e., incident to each vertex) number of triangles in a fully-dynamic graph represented as an adversarial stream of edge insertions and deletions. Our algorithms use reservoir sampling and its variants to exploit the user-specified memory space at all times. This is in contrast with previous approaches which use hard-to-choose parameters (e.g., a fixed sampling probability) and offer no guarantees on the amount of memory they will use. We show a full analysis of the variance of the estimations and novel concentration bounds for these quantities. Our experimental results on very large graphs show that TRI\u00c8ST outperforms state-of-the-art approaches in accuracy and exhibits a small update time.",
                        "Citation Paper Authors": "Authors:Lorenzo De Stefani, Alessandro Epasto, Matteo Riondato, Eli Upfal"
                    }
                },
                {
                    "Sentence ID": 3,
                    "Sentence": ", Park et al. [ 24\u201327], and Arifuzzaman et al. ",
                    "Citation Text": "Shaikh Arifuzzaman, Maleq Khan, and Madhav Marathe. 2013. PATRIC: A parallel algorithm for counting triangles in\nmassive networks. In Proceedings of the 22nd ACM international conference on Information & Knowledge Management .\nACM, 529\u2013538.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1406.5687",
                        "Citation Paper Title": "Title:Parallel Algorithms for Counting Triangles in Networks with Large Degrees",
                        "Citation Paper Abstract": "Abstract:Finding the number of triangles in a network is an important problem in the analysis of complex networks. The number of triangles also has important applications in data mining. Existing distributed memory parallel algorithms for counting triangles are either Map-Reduce based or message passing interface (MPI) based and work with overlapping partitions of the given network. These algorithms are designed for very sparse networks and do not work well when the degrees of the nodes are relatively larger. For networks with larger degrees, Map-Reduce based algorithm generates prohibitively large intermediate data, and in MPI based algorithms with overlapping partitions, each partition can grow as large as the original network, wiping out the benefit of partitioning the network.\nIn this paper, we present two efficient MPI-based parallel algorithms for counting triangles in massive networks with large degrees. The first algorithm is a space-efficient algorithm for networks that do not fit in the main memory of a single compute node. This algorithm divides the network into non-overlapping partitions. The second algorithm is for the case where the main memory of each node is large enough to contain the entire network. We observe that for such a case, computation load can be balanced dynamically and present a dynamic load balancing scheme which improves the performance significantly. Both of our algorithms scale well to large networks and to a large number of processors.",
                        "Citation Paper Authors": "Authors:Shaikh Arifuzzaman, Maleq Khan, Madhav Marathe"
                    }
                },
                {
                    "Sentence ID": 38,
                    "Sentence": "proposed sampling\nwedges (i.e., paths of length two) in addition to edges; and Ahmed et al. [ 1,2] proposed sampling\nedges with different probabilities, depending on the counts of adjacent sampled edges and incident\ntriangles. Tangwongsan et al. ",
                    "Citation Text": "Kanat Tangwongsan, Aduri Pavan, and Srikanta Tirthapura. 2013. Parallel triangle counting in massive streaming\ngraphs. In Proceedings of the 22nd ACM international conference on Information & Knowledge Management . ACM,\n781\u2013786.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1308.2166",
                        "Citation Paper Title": "Title:Parallel Triangle Counting in Massive Streaming Graphs",
                        "Citation Paper Abstract": "Abstract:The number of triangles in a graph is a fundamental metric, used in social network analysis, link classification and recommendation, and more. Driven by these applications and the trend that modern graph datasets are both large and dynamic, we present the design and implementation of a fast and cache-efficient parallel algorithm for estimating the number of triangles in a massive undirected graph whose edges arrive as a stream. It brings together the benefits of streaming algorithms and parallel algorithms. By building on the streaming algorithms framework, the algorithm has a small memory footprint. By leveraging the paralell cache-oblivious framework, it makes efficient use of the memory hierarchy of modern multicore machines without needing to know its specific parameters. We prove theoretical bounds on accuracy, memory access cost, and parallel runtime complexity, as well as showing empirically that the algorithm yields accurate results and substantial speedups compared to an optimized sequential implementation.\n(This is an expanded version of a CIKM'13 paper of the same title.)",
                        "Citation Paper Authors": "Authors:Kanat Tangwongsan, A. Pavan, Srikanta Tirthapura"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1707.06315v9": {
            "Paper Title": "FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal\n  Inference",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.01065v3": {
            "Paper Title": "Detecting Group Anomalies in Tera-Scale Multi-Aspect Data via\n  Dense-Subtensor Mining",
            "Sentences": [
                {
                    "Sentence ID": 3,
                    "Sentence": ", have been\nused for anomaly and fraud detection in graphs. See ",
                    "Citation Text": "Leman Akoglu, Hanghang Tong, and Danai Koutra. Graph based anomaly detection and description: a\nsurvey.Data Mining and Knowledge Discovery , 29(3):626\u2013688, 2015.\n22",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1404.4679",
                        "Citation Paper Title": "Title:Graph-based Anomaly Detection and Description: A Survey",
                        "Citation Paper Abstract": "Abstract:Detecting anomalies in data is a vital task, with numerous high-impact applications in areas such as security, finance, health care, and law enforcement. While numerous techniques have been developed in past years for spotting outliers and anomalies in unstructured collections of multi-dimensional points, with graph data becoming ubiquitous, techniques for structured {\\em graph} data have been of focus recently. As objects in graphs have long-range correlations, a suite of novel technology has been developed for anomaly detection in graph data.\nThis survey aims to provide a general, comprehensive, and structured overview of the state-of-the-art methods for anomaly detection in data represented as graphs. As a key contribution, we provide a comprehensive exploration of both data mining and machine learning algorithms for these {\\em detection} tasks. we give a general framework for the algorithms categorized under various settings: unsupervised vs. (semi-)supervised approaches, for static vs. dynamic graphs, for attributed vs. plain graphs. We highlight the effectiveness, scalability, generality, and robustness aspects of the methods. What is more, we stress the importance of anomaly {\\em attribution} and highlight the major techniques that facilitate digging out the root cause, or the `why', of the detected anomalies for further analysis and sense-making. Finally, we present several real-world applications of graph-based anomaly detection in diverse domains, including financial, auction, computer traffic, and social networks. We conclude our survey with a discussion on open theoretical and practical challenges in the field.",
                        "Citation Paper Authors": "Authors:Leman Akoglu, Hanghang Tong, Danai Koutra"
                    }
                },
                {
                    "Sentence ID": 38,
                    "Sentence": "starts from the output of M-Zoom and repeats adding or removing an attribute greedily until a local\noptimum is reached. Given a dynamic tensor, DenseAlert andDenseStream incrementally compute\na single dense subtensor in it ",
                    "Citation Text": "Kijung Shin, Bryan Hooi, Jisu Kim, and Christos Faloutsos. Densealert: Incremental dense-subtensor\ndetection in tensor streams. In Proceedings of the 23rd ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining , pages 1057\u20131066. ACM, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1706.03374",
                        "Citation Paper Title": "Title:DenseAlert: Incremental Dense-Subtensor Detection in Tensor Streams",
                        "Citation Paper Abstract": "Abstract:Consider a stream of retweet events - how can we spot fraudulent lock-step behavior in such multi-aspect data (i.e., tensors) evolving over time? Can we detect it in real time, with an accuracy guarantee? Past studies have shown that dense subtensors tend to indicate anomalous or even fraudulent behavior in many tensor data, including social media, Wikipedia, and TCP dumps. Thus, several algorithms have been proposed for detecting dense subtensors rapidly and accurately. However, existing algorithms assume that tensors are static, while many real-world tensors, including those mentioned above, evolve over time.\nWe propose DenseStream, an incremental algorithm that maintains and updates a dense subtensor in a tensor stream (i.e., a sequence of changes in a tensor), and DenseAlert, an incremental algorithm spotting the sudden appearances of dense subtensors. Our algorithms are: (1) Fast and 'any time': updates by our algorithms are up to a million times faster than the fastest batch algorithms, (2) Provably accurate: our algorithms guarantee a lower bound on the density of the subtensor they maintain, and (3) Effective: our DenseAlert successfully spots anomalies in real-world tensors, especially those overlooked by existing algorithms.",
                        "Citation Paper Authors": "Authors:Kijung Shin, Bryan Hooi, Jisu Kim, Christos Faloutsos"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1712.01001v7": {
            "Paper Title": "Specifying and Computing Causes for Query Answers in Databases via\n  Database Repairs and Repair Programs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.08245v3": {
            "Paper Title": "Reductive Clustering: An Efficient Linear-time Graph-based Divisive\n  Cluster Analysis Approach",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.09526v4": {
            "Paper Title": "Functional Aggregate Queries with Additive Inequalities",
            "Sentences": [
                {
                    "Sentence ID": 12,
                    "Sentence": ". There are more recent improv ements to Chazelle\u2019s result (see, e.g.,\nChan et al. ",
                    "Citation Text": "Chan, T. M., Larsen, K. G., and P \u02d8atras \u00b8cu, M. Orthogonal range searching on the ram, revisited.\nInSoCG(2011), pp. 1\u201310.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1103.5510",
                        "Citation Paper Title": "Title:Orthogonal Range Searching on the RAM, Revisited",
                        "Citation Paper Abstract": "Abstract:We present several new results on one of the most extensively studied topics in computational geometry, orthogonal range searching. All our results are in the standard word RAM model for points in rank space:\n** We present two data structures for 2-d orthogonal range emptiness. The first achieves O(n lglg n) space and O(lglg n) query time. This improves the previous results by Alstrup, Brodal, and Rauhe(FOCS'00), with O(n lg^eps n) space and O(lglg n) query time, or with O(nlglg n) space and O(lg^2 lg n) query time. Our second data structure uses O(n) space and answers queries in O(lg^eps n) time. The best previous O(n)-space data structure, due to Nekrich (WADS'07), answers queries in O(lg n/lglg n) time.\n** For 3-d orthogonal range reporting, we obtain space O(n lg^{1+eps} n) and query time O(lglg n + k), for any constant eps>0. This improves previous results by Afshani (ESA'08), Karpinski and Nekrich (COCOON'09), and Chan (SODA'11), with O(n lg^3 n) space and O(lglg n + k) query time, or with O(n lg^{1+eps} n) space and O(lg^2 lg n + k) query time. This implies improved bounds for orthogonal range reporting in all constant dimensions above 3.\n** We give a randomized algorithm for 4-d offline dominance range reporting/emptiness with running time O(n lg n + k). This resolves two open problems from Preparata and Shamos' seminal book:\n**** given n axis-aligned rectangles in the plane, we can report all k enclosure pairs in O(n lg n + k) expected time. The best known result was an O([n lg n + k] lglg n) algorithm from SoCG'95 by Gupta, Janardan, Smid, and Dasgupta.\n**** given n points in 4-d, we can find all maximal points in O(n lg n) expected time. The best previous result was an O(n lg n lglg n) algorithm due to Gabow, Bentley, and Tarjan (STOC'84). This implies record time bounds for the maxima problem in all constant dimensions above 4.",
                        "Citation Paper Authors": "Authors:Timothy M. Chan, Kasper Green Larsen, Mihai Patrascu"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1810.05972v3": {
            "Paper Title": "DDSL: Efficient Subgraph Listing on Distributed and Dynamic Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.02935v2": {
            "Paper Title": "Towards Self-Tuning Parameter Servers",
            "Sentences": [
                {
                    "Sentence ID": 28,
                    "Sentence": ", which\npicks the next setting that can maximize the expected im-\nprovement over the current best; (iii) Upper Con\ufb01dence Bound\n(UCB) ",
                    "Citation Text": "E. Contal, D. Buffoni, A. Robicquet, and N. Vayatis, \u201cParallel gaussian\nprocess optimization with upper con\ufb01dence bound and pure exploration,\u201d\ninECML PKDD , 2013, pp. 225\u2013240.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1304.5350",
                        "Citation Paper Title": "Title:Parallel Gaussian Process Optimization with Upper Confidence Bound and Pure Exploration",
                        "Citation Paper Abstract": "Abstract:In this paper, we consider the challenge of maximizing an unknown function f for which evaluations are noisy and are acquired with high cost. An iterative procedure uses the previous measures to actively select the next estimation of f which is predicted to be the most useful. We focus on the case where the function can be evaluated in parallel with batches of fixed size and analyze the benefit compared to the purely sequential procedure in terms of cumulative regret. We introduce the Gaussian Process Upper Confidence Bound and Pure Exploration algorithm (GP-UCB-PE) which combines the UCB strategy and Pure Exploration in the same batch of evaluations along the parallel iterations. We prove theoretical upper bounds on the regret with batches of size K for this procedure which show the improvement of the order of sqrt{K} for fixed iteration cost over purely sequential versions. Moreover, the multiplicative constants involved have the property of being dimension-free. We also confirm empirically the efficiency of GP-UCB-PE on real and synthetic problems compared to state-of-the-art competitors.",
                        "Citation Paper Authors": "Authors:Emile Contal, David Buffoni, Alexandre Robicquet, Nicolas Vayatis"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1812.07208v2": {
            "Paper Title": "High-utility itemset mining for subadditive monotone utility functions",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.01420v2": {
            "Paper Title": "Usable & Scalable Learning Over Relational Data With Automatic Language\n  Bias",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.07024v3": {
            "Paper Title": "Data Lake Organization",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.04780v5": {
            "Paper Title": "Learning Models over Relational Data using Sparse Tensors and Functional\n  Dependencies",
            "Sentences": [
                {
                    "Sentence ID": 20,
                    "Sentence": "that support generalized linear models, Na\u007f \u0010ve Bayes classi\fcation, and respectively linear regression models with\ncontinuous features. This class also contains the recent e\u000borts on in-database linear algebra ",
                    "Citation Text": "L. Chen, A. Kumar, J. F. Naughton, and J. M. Patel. Towards linear algebra over normalized data. PVLDB ,\n10(11):1214{1225, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1612.07448",
                        "Citation Paper Title": "Title:Towards Linear Algebra over Normalized Data",
                        "Citation Paper Abstract": "Abstract:Providing machine learning (ML) over relational data is a mainstream requirement for data analytics systems. While almost all the ML tools require the input data to be presented as a single table, many datasets are multi-table, which forces data scientists to join those tables first, leading to data redundancy and runtime waste. Recent works on \"factorized\" ML mitigate this issue for a few specific ML algorithms by pushing ML through joins. But their approaches require a manual rewrite of ML implementations. Such piecemeal methods create a massive development overhead when extending such ideas to other ML algorithms. In this paper, we show that it is possible to mitigate this overhead by leveraging a popular formal algebra to represent the computations of many ML algorithms: linear algebra. We introduce a new logical data type to represent normalized data and devise a framework of algebraic rewrite rules to convert a large set of linear algebra operations over denormalized data into operations over normalized data. We show how this enables us to automatically \"factorize\" several popular ML algorithms, thus unifying and generalizing several prior works. We prototype our framework in the popular ML environment R and an industrial R-over-RDBMS tool. Experiments with both synthetic and real normalized data show that our framework also yields significant speed-ups, up to 36x on real data.",
                        "Citation Paper Authors": "Authors:Lingjiao Chen, Arun Kumar, Jeffrey Naughton, Jignesh M. Patel"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1812.04379v2": {
            "Paper Title": "On the expressive power of linear algebra on graphs",
            "Sentences": [
                {
                    "Sentence ID": 13,
                    "Sentence": "for a similar approach). More\ngeneral semirings could open the way for modelling and querying labeled graphs using matrix\nquery languages (see also ",
                    "Citation Text": "Robert Brijder, Marc Gyssens, and Jan Van den Bussche. On matrices and k-relations.\nCoRR , 2019. URL: http://arxiv.org/abs/1904.03934 .",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1904.03934",
                        "Citation Paper Title": "Title:On matrices and $K$-relations",
                        "Citation Paper Abstract": "Abstract:We show that the matrix query language $\\mathsf{MATLANG}$ corresponds to a natural fragment of the positive relational algebra on $K$-relations. The fragment is defined by introducing a composition operator and restricting $K$-relation arities to two. We then proceed to show that $\\mathsf{MATLANG}$ can express all matrix queries expressible in the positive relational algebra on $K$-relations, when intermediate arities are restricted to three. Thus we offer an analogue, in a model with numerical data, to the situation in classical logic, where the algebra of binary relations is equivalent to first-order logic with three variables.",
                        "Citation Paper Authors": "Authors:Robert Brijder, Marc Gyssens, Jan Van den Bussche"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1811.07977v3": {
            "Paper Title": "ShapeSearch: A Flexible and Efficient System for Shape-based Exploration\n  of Trendlines",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.01046v2": {
            "Paper Title": "BlazeIt: Optimizing Declarative Aggregation and Limit Queries for Neural\n  Network-Based Video Analytics",
            "Sentences": [
                {
                    "Sentence ID": 36,
                    "Sentence": ". Model dis-\ntillation uses a large NN to train a smaller NN ",
                    "Citation Text": "G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge\nin a neural network. arXiv preprint arXiv:1503.02531 , 2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1503.02531",
                        "Citation Paper Title": "Title:Distilling the Knowledge in a Neural Network",
                        "Citation Paper Abstract": "Abstract:A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.",
                        "Citation Paper Authors": "Authors:Geoffrey Hinton, Oriol Vinyals, Jeff Dean"
                    }
                },
                {
                    "Sentence ID": 29,
                    "Sentence": "weights from the original NN,\nwhich can be amenable to hardware acceleration ",
                    "Citation Text": "S. Han, X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz,\nand W. J. Dally. Eie: ef\ufb01cient inference engine on\ncompressed deep neural network. In ISCA , pages 243\u2013254.\nIEEE, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1602.01528",
                        "Citation Paper Title": "Title:EIE: Efficient Inference Engine on Compressed Deep Neural Network",
                        "Citation Paper Abstract": "Abstract:State-of-the-art deep neural networks (DNNs) have hundreds of millions of connections and are both computationally and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources and power budgets. While custom hardware helps the computation, fetching weights from DRAM is two orders of magnitude more expensive than ALU operations, and dominates the required power.\nPreviously proposed 'Deep Compression' makes it possible to fit large DNNs (AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by pruning the redundant connections and having multiple connections share the same weight. We propose an energy efficient inference engine (EIE) that performs inference on this compressed network model and accelerates the resulting sparse matrix-vector multiplication with weight sharing. Going from DRAM to SRAM gives EIE 120x energy saving; Exploiting sparsity saves 10x; Weight sharing gives 8x; Skipping zero activations from ReLU saves another 3x. Evaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to CPU and GPU implementations of the same DNN without compression. EIE has a processing power of 102GOPS/s working directly on a compressed network, corresponding to 3TOPS/s on an uncompressed network, and processes FC layers of AlexNet at 1.88x10^4 frames/sec with a power dissipation of only 600mW. It is 24,000x and 3,400x more energy efficient than a CPU and GPU respectively. Compared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy efficiency and area efficiency.",
                        "Citation Paper Authors": "Authors:Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A. Horowitz, William J. Dally"
                    }
                },
                {
                    "Sentence ID": 61,
                    "Sentence": ") or increase the throughput of batch analytics\nqueries (e.g., S CANNER ",
                    "Citation Text": "A. Poms, W. Crichton, P. Hanrahan, and K. Fatahalian.\nScanner: Ef\ufb01cient video analysis at scale (to appear). 2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1805.07339",
                        "Citation Paper Title": "Title:Scanner: Efficient Video Analysis at Scale",
                        "Citation Paper Abstract": "Abstract:A growing number of visual computing applications depend on the analysis of large video collections. The challenge is that scaling applications to operate on these datasets requires efficient systems for pixel data access and parallel processing across large numbers of machines. Few programmers have the capability to operate efficiently at these scales, limiting the field's ability to explore new applications that leverage big video data. In response, we have created Scanner, a system for productive and efficient video analysis at scale. Scanner organizes video collections as tables in a data store optimized for sampling frames from compressed video, and executes pixel processing computations, expressed as dataflow graphs, on these frames. Scanner schedules video analysis applications expressed using these abstractions onto heterogeneous throughput computing hardware, such as multi-core CPUs, GPUs, and media processing ASICs, for high-throughput pixel processing. We demonstrate the productivity of Scanner by authoring a variety of video processing applications including the synthesis of stereo VR video streams from multi-camera rigs, markerless 3D human pose reconstruction from video, and data-mining big video datasets such as hundreds of feature-length films or over 70,000 hours of TV news. These applications achieve near-expert performance on a single machine and scale efficiently to hundreds of machines, enabling formerly long-running big video data analysis tasks to be carried out in minutes to hours.",
                        "Citation Paper Authors": "Authors:Alex Poms, Will Crichton, Pat Hanrahan, Kayvon Fatahalian"
                    }
                },
                {
                    "Sentence ID": 37,
                    "Sentence": ", a highly tuned pipeline for\nbinary detection: it returns the presence or absence of a partic-\nular object class in video. Other systems, e.g., F OCUS ",
                    "Citation Text": "K. Hsieh, G. Ananthanarayanan, P. Bodik, P. Bahl,\nM. Philipose, P. B. Gibbons, and O. Mutlu. Focus: Querying\nlarge video datasets with low latency and low cost. OSDI ,\n2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1801.03493",
                        "Citation Paper Title": "Title:Focus: Querying Large Video Datasets with Low Latency and Low Cost",
                        "Citation Paper Abstract": "Abstract:Large volumes of videos are continuously recorded from cameras deployed for traffic control and surveillance with the goal of answering \"after the fact\" queries: identify video frames with objects of certain classes (cars, bags) from many days of recorded video. While advancements in convolutional neural networks (CNNs) have enabled answering such queries with high accuracy, they are too expensive and slow. We build Focus, a system for low-latency and low-cost querying on large video datasets. Focus uses cheap ingestion techniques to index the videos by the objects occurring in them. At ingest-time, it uses compression and video-specific specialization of CNNs. Focus handles the lower accuracy of the cheap CNNs by judiciously leveraging expensive CNNs at query-time. To reduce query time latency, we cluster similar objects and hence avoid redundant processing. Using experiments on video streams from traffic, surveillance and news channels, we see that Focus uses 58X fewer GPU cycles than running expensive ingest processors and is 37X faster than processing all the video at query time.",
                        "Citation Paper Authors": "Authors:Kevin Hsieh, Ganesh Ananthanarayanan, Peter Bodik, Paramvir Bahl, Matthai Philipose, Phillip B. Gibbons, Onur Mutlu"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1711.02476v2": {
            "Paper Title": "SWOOP: Top-k Similarity Joins over Set Streams",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.05983v3": {
            "Paper Title": "Online Variant of Parcel Allocation in Last-mile Delivery",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.04876v2": {
            "Paper Title": "Plato: Approximate Analytics over Compressed Time Series with Tight\n  Deterministic Error Guarantees",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.08083v2": {
            "Paper Title": "Finding Theme Communities from Database Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.00498v4": {
            "Paper Title": "Optimization of Imperative Programs in a Relational Database",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.10404v2": {
            "Paper Title": "MedTruth: A Semi-supervised Approach to Discovering Knowledge Condition\n  Information from Multi-Source Medical Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.00701v4": {
            "Paper Title": "CLX: Towards verifiable PBE data transformation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.02343v3": {
            "Paper Title": "TIPS: Mining Top-K Locations to Minimize User-Inconvenience for\n  Trajectory-Aware Services",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.02869v3": {
            "Paper Title": "Perspectival Knowledge in PSOA RuleML: Representation, Model Theory, and\n  Translation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.10942v2": {
            "Paper Title": "Dynamicity and Durability in Scalable Visual Instance Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.08436v5": {
            "Paper Title": "HyperMinHash: MinHash in LogLog space",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.08062v3": {
            "Paper Title": "Modeling and In-Database Management of Relational, Data-Aware Processes\n  (Extended Version)",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.07514v2": {
            "Paper Title": "NSEEN: Neural Semantic Embedding for Entity Normalization",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.10000v2": {
            "Paper Title": "Enabling Efficient Updates in KV Storage via Hashing: Design and\n  Performance Evaluation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.12125v4": {
            "Paper Title": "Gradual Machine Learning for Entity Resolution",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.01823v3": {
            "Paper Title": "Approximation with Error Bounds in Spark",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.06396v2": {
            "Paper Title": "Computing Possible and Certain Answers over Order-Incomplete Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.08833v2": {
            "Paper Title": "MinJoin: Efficient Edit Similarity Joins via Local Hash Minima",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.11317v7": {
            "Paper Title": "Utility-Optimized Local Differential Privacy Mechanisms for Distribution\n  Estimation",
            "Sentences": [
                {
                    "Sentence ID": 23,
                    "Sentence": "has been widely studied in the\nliterature. For example, Erlingsson et al. ",
                    "Citation Text": "U. Erlingsson, V. Pihur, and A. Korolova. RAPPOR:\nRandomized aggregatable privacy-preserving ordinal\nresponse. In Proc. 2014 ACM SIGSAC Conference on\nComputer and Communications Security (CCS\u201914) ,\npages 1054\u20131067, 2014.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1407.6981",
                        "Citation Paper Title": "Title:RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response",
                        "Citation Paper Abstract": "Abstract:Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports. This paper describes and motivates RAPPOR, details its differential-privacy and utility guarantees, discusses its practical deployment and properties in the face of different attack models, and, finally, gives results of its application to both synthetic and real-world data.",
                        "Citation Paper Authors": "Authors:\u00dalfar Erlingsson, Vasyl Pihur, Aleksandra Korolova"
                    }
                },
                {
                    "Sentence ID": 19,
                    "Sentence": "introduced DP, a number\nof its variants have been studied to provide di\ufb00erent types o f\nprivacy guarantees; e.g., LDP ",
                    "Citation Text": "J. C. Duchi, M. I. Jordan, and M. J. Wainwright.\nLocal privacy and statistical minimax rates. In Proc.\nIEEE 54th Annual Symposium on Foundations of\nComputer Science (FOCS\u201913) , pages 429\u2013438, 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1302.3203",
                        "Citation Paper Title": "Title:Local Privacy, Data Processing Inequalities, and Statistical Minimax Rates",
                        "Citation Paper Abstract": "Abstract:Working under a model of privacy in which data remains private even from the statistician, we study the tradeoff between privacy guarantees and the utility of the resulting statistical estimators. We prove bounds on information-theoretic quantities, including mutual information and Kullback-Leibler divergence, that depend on the privacy guarantees. When combined with standard minimax techniques, including the Le Cam, Fano, and Assouad methods, these inequalities allow for a precise characterization of statistical rates under local privacy constraints. We provide a treatment of several canonical families of problems: mean estimation, parameter estimation in fixed-design regression, multinomial probability estimation, and nonparametric density estimation. For all of these families, we provide lower and upper bounds that match up to constant factors, and exhibit new (optimal) privacy-preserving mechanisms and computationally efficient estimators that achieve the bounds.",
                        "Citation Paper Authors": "Authors:John C. Duchi, Michael I. Jordan, Martin J. Wainwright"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1712.10266v4": {
            "Paper Title": "APEx: Accuracy-Aware Differentially Private Data Exploration",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.06800v2": {
            "Paper Title": "Composite Hashing for Data Stream Sketches",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.00607v3": {
            "Paper Title": "Probabilistic Databases with an Infinite Open-World Assumption",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.01384v2": {
            "Paper Title": "Data Curation with Deep Learning [Vision]",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.09267v2": {
            "Paper Title": "Creating a surrogate commuter network from Australian Bureau of\n  Statistics census data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.01449v3": {
            "Paper Title": "To Index or Not to Index: Optimizing Exact Maximum Inner Product Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.00399v4": {
            "Paper Title": "Towards Scaling Blockchain Systems via Sharding",
            "Sentences": [
                {
                    "Sentence ID": 19,
                    "Sentence": "is the first storage designed for blockchains, supporting\nanalytical queries at a much lower cost than the current key-value\nbackends. Dickerson et al. ",
                    "Citation Text": "Thomas Dickerson, Paul Gazzillo, Maurice Herlihy, and Eric Koskinen. 2017.\nAdding Concurrency to Smart Contracts. In PODC .",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1702.04467",
                        "Citation Paper Title": "Title:Adding Concurrency to Smart Contracts",
                        "Citation Paper Abstract": "Abstract:Modern cryptocurrency systems, such as Ethereum, permit complex financial transactions through scripts called smart contracts. These smart contracts are executed many, many times, always without real concurrency. First, all smart contracts are serially executed by miners before appending them to the blockchain. Later, those contracts are serially re-executed by validators to verify that the smart contracts were executed correctly by miners.\nSerial execution limits system throughput and fails to exploit today's concurrent multicore and cluster architectures. Nevertheless, serial execution appears to be required: contracts share state, and contract programming languages have a serial semantics.\nThis paper presents a novel way to permit miners and validators to execute smart contracts in parallel, based on techniques adapted from software transactional memory. Miners execute smart contracts speculatively in parallel, allowing non-conflicting contracts to proceed concurrently, and \"discovering\" a serializable concurrent schedule for a block's transactions, This schedule is captured and encoded as a deterministic fork-join program used by validators to re-execute the miner's parallel schedule deterministically but concurrently.\nSmart contract benchmarks run on a JVM with ScalaSTM show that a speedup of of 1.33x can be obtained for miners and 1.69x for validators with just three concurrent threads.",
                        "Citation Paper Authors": "Authors:Thomas Dickerson, Paul Gazzillo, Maurice Herlihy, Eric Koskinen"
                    }
                },
                {
                    "Sentence ID": 7,
                    "Sentence": ".\n8 RELATED WORKS\nWe have discussed three related sharded blockchains, namely Elas-\ntico, OmniLedger and RapidChain, extensively in the previous sec-\ntions. Another related system is Chainspace ",
                    "Citation Text": "Mustafa Al-Bassam, Alberto Sonnino, Shehar Bano, Dave Hrycyszyn, and George\nDanezis. 2017. Chainspace: A Sharded Smart Contracts Platform. arXiv preprint\narXiv:1708.03778 (2017).",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1708.03778",
                        "Citation Paper Title": "Title:Chainspace: A Sharded Smart Contracts Platform",
                        "Citation Paper Abstract": "Abstract:Chainspace is a decentralized infrastructure, known as a distributed ledger, that supports user defined smart contracts and executes user-supplied transactions on their objects. The correct execution of smart contract transactions is verifiable by all. The system is scalable, by sharding state and the execution of transactions, and using S-BAC, a distributed commit protocol, to guarantee consistency. Chainspace is secure against subsets of nodes trying to compromise its integrity or availability properties through Byzantine Fault Tolerance (BFT), and extremely high-auditability, non-repudiation and `blockchain' techniques. Even when BFT fails, auditing mechanisms are in place to trace malicious participants. We present the design, rationale, and details of Chainspace; we argue through evaluating an implementation of the system about its scaling and other features; we illustrate a number of privacy-friendly smart contracts for smart metering, polling and banking and measure their performance.",
                        "Citation Paper Authors": "Authors:Mustafa Al-Bassam, Alberto Sonnino, Shehar Bano, Dave Hrycyszyn, George Danezis"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1712.07445v5": {
            "Paper Title": "Boolean Tensor Decomposition for Conjunctive Queries with Negation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.10955v2": {
            "Paper Title": "Efficiently Charting RDF",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.06750v3": {
            "Paper Title": "A Formal Framework For Probabilistic Unclean Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.10286v3": {
            "Paper Title": "Repair-Based Degrees of Database Inconsistency: Computation and\n  Complexity",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.01960v4": {
            "Paper Title": "An Iterative Scheme for Leverage-based Approximate Aggregation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.03196v2": {
            "Paper Title": "Learning to Optimize Join Queries With Deep Reinforcement Learning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.07695v2": {
            "Paper Title": "Index-based, High-dimensional, Cosine Threshold Querying with Optimality\n  Guarantees",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.05199v5": {
            "Paper Title": "A Blockchain Database Application Platform",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.08896v2": {
            "Paper Title": "Efficient Data Ingestion and Query Processing for LSM-Based Storage\n  Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.04486v4": {
            "Paper Title": "DeepBase: Deep Inspection of Neural Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.10942v2": {
            "Paper Title": "Answering Range Queries Under Local Differential Privacy",
            "Sentences": [
                {
                    "Sentence ID": 9,
                    "Sentence": ".\nHowever, in the last few years, the model of local data perturba-\ntion has risen in prominence: initially from a theoretical interest ",
                    "Citation Text": "John C Duchi, Michael I Jordan, and Martin J Wainwright. 2013. Local privacy\nand statistical minimax rates. In FOCS . IEEE.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1302.3203",
                        "Citation Paper Title": "Title:Local Privacy, Data Processing Inequalities, and Statistical Minimax Rates",
                        "Citation Paper Abstract": "Abstract:Working under a model of privacy in which data remains private even from the statistician, we study the tradeoff between privacy guarantees and the utility of the resulting statistical estimators. We prove bounds on information-theoretic quantities, including mutual information and Kullback-Leibler divergence, that depend on the privacy guarantees. When combined with standard minimax techniques, including the Le Cam, Fano, and Assouad methods, these inequalities allow for a precise characterization of statistical rates under local privacy constraints. We provide a treatment of several canonical families of problems: mean estimation, parameter estimation in fixed-design regression, multinomial probability estimation, and nonparametric density estimation. For all of these families, we provide lower and upper bounds that match up to constant factors, and exhibit new (optimal) privacy-preserving mechanisms and computationally efficient estimators that achieve the bounds.",
                        "Citation Paper Authors": "Authors:John C. Duchi, Michael I. Jordan, Martin J. Wainwright"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1812.10734v1": {
            "Paper Title": "Facetize: An Interactive Tool for Cleaning and Transforming Datasets for\n  Facilitating Exploratory Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.09905v1": {
            "Paper Title": "PatientEG Dataset: Bringing Event Graph Model with Temporal Relations to\n  Electronic Medical Records",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.09551v1": {
            "Paper Title": "TaxoGen: Unsupervised Topic Taxonomy Construction by Adaptive Term\n  Embedding and Clustering",
            "Sentences": [
                {
                    "Sentence ID": 13,
                    "Sentence": ".\nOur method differs from these existing ones in two aspects. First,\nwe do not need labeled hypernym-hyponym pairs as supervision\nfor learning either semantic projections or dynamic weighting neu-\nral network. Second, we employ a technique called local embedding ",
                    "Citation Text": "H. Gui, Q. Zhu, L. Liu, A. Zhang, and J. Han. Expert finding in heterogeneous\nbibliographic networks with locally-trained embeddings. CoRR , abs/1803.03370,\n2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1803.03370",
                        "Citation Paper Title": "Title:Expert Finding in Heterogeneous Bibliographic Networks with Locally-trained Embeddings",
                        "Citation Paper Abstract": "Abstract:Expert finding is an important task in both industry and academia. It is challenging to rank candidates with appropriate expertise for various queries. In addition, different types of objects interact with one another, which naturally forms heterogeneous information networks. We study the task of expert finding in heterogeneous bibliographical networks based on two aspects: textual content analysis and authority ranking. Regarding the textual content analysis, we propose a new method for query expansion via locally-trained embedding learning with concept hierarchy as guidance, which is particularly tailored for specific queries with narrow semantic meanings. Compared with global embedding learning, locally-trained embedding learning projects the terms into a latent semantic space constrained on relevant topics, therefore it preserves more precise and subtle information for specific queries. Considering the candidate ranking, the heterogeneous information network structure, while being largely ignored in the previous studies of expert finding, provides additional information. Specifically, different types of interactions among objects play different roles. We propose a ranking algorithm to estimate the authority of objects in the network, treating each strongly-typed edge type individually. To demonstrate the effectiveness of the proposed framework, we apply the proposed method to a large-scale bibliographical dataset with over two million entries and one million researcher candidates. The experiment results show that the proposed framework outperforms existing methods for both general and specific queries.",
                        "Citation Paper Authors": "Authors:Huan Gui, Qi Zhu, Liyuan Liu, Aston Zhang, Jiawei Han"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1812.09141v1": {
            "Paper Title": "Speeding-up the Verification Phase of Set Similarity Joins in the GPGPU\n  paradigm",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.09233v1": {
            "Paper Title": "Partitioned Data Security on Outsourced Sensitive and Non-sensitive Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.07607v1": {
            "Paper Title": "DeepLens: Towards a Visual Data Management System",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.00677v2": {
            "Paper Title": "Learned Cardinalities: Estimating Correlated Joins with Deep Learning",
            "Sentences": [
                {
                    "Sentence ID": 29,
                    "Sentence": "to learn flexible\nmappings f(S)for arbitrary sets S. Applying a learnable mapping\nfor each set element individually (with shared parameters) is similar\nto the concept of a 1\u00d71convolution, often used in CNNs for image\nclassification ",
                    "Citation Text": "C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the\ninception architecture for computer vision. In Proceedings of the IEEE conference\non computer vision and pattern recognition , pages 2818\u20132826, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1512.00567",
                        "Citation Paper Title": "Title:Rethinking the Inception Architecture for Computer Vision",
                        "Citation Paper Abstract": "Abstract:Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error on the validation set (3.6% error on the test set) and 17.3% top-1 error on the validation set.",
                        "Citation Paper Authors": "Authors:Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1812.05804v1": {
            "Paper Title": "Data Provenance for Sport",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.05762v1": {
            "Paper Title": "Helix: Holistic Optimization for Accelerating Iterative Machine Learning",
            "Sentences": [
                {
                    "Sentence ID": 36,
                    "Sentence": "opti-\nmizes feature selection speci\ufb01cally for regression models. Active-\nClean ",
                    "Citation Text": "S. Krishnan, J. Wang, E. Wu, M. J. Franklin, and\nK. Goldberg. Activeclean: Interactive data cleaning while\nlearning convex loss models. arXiv preprint\narXiv:1601.03797 , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1601.03797",
                        "Citation Paper Title": "Title:ActiveClean: Interactive Data Cleaning While Learning Convex Loss Models",
                        "Citation Paper Abstract": "Abstract:Data cleaning is often an important step to ensure that predictive models, such as regression and classification, are not affected by systematic errors such as inconsistent, out-of-date, or outlier data. Identifying dirty data is often a manual and iterative process, and can be challenging on large datasets. However, many data cleaning workflows can introduce subtle biases into the training processes due to violation of independence assumptions. We propose ActiveClean, a progressive cleaning approach where the model is updated incrementally instead of re-training and can guarantee accuracy on partially cleaned data. ActiveClean supports a popular class of models called convex loss models (e.g., linear regression and SVMs). ActiveClean also leverages the structure of a user's model to prioritize cleaning those records likely to affect the results. We evaluate ActiveClean on five real-world datasets UCI Adult, UCI EEG, MNIST, Dollars For Docs, and WorldBank with both real and synthetic errors. Our results suggest that our proposed optimizations can improve model accuracy by up-to 2.5x for the same amount of data cleaned. Furthermore for a fixed cleaning budget and on all real dirty datasets, ActiveClean returns more accurate models than uniform sampling and Active Learning.",
                        "Citation Paper Authors": "Authors:Sanjay Krishnan, Jiannan Wang, Eugene Wu, Michael J. Franklin, Ken Goldberg"
                    }
                },
                {
                    "Sentence ID": 15,
                    "Sentence": "optimizes generalized\nlinear models directly over factorized / normalized representations\nof relational data, avoiding key-foreign key joins. Morpheus ",
                    "Citation Text": "L. Chen, A. Kumar, J. Naughton, and J. M. Patel. Towards\nlinear algebra over normalized data. Proceedings of the\nVLDB Endowment , 10(11):1214\u20131225, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1612.07448",
                        "Citation Paper Title": "Title:Towards Linear Algebra over Normalized Data",
                        "Citation Paper Abstract": "Abstract:Providing machine learning (ML) over relational data is a mainstream requirement for data analytics systems. While almost all the ML tools require the input data to be presented as a single table, many datasets are multi-table, which forces data scientists to join those tables first, leading to data redundancy and runtime waste. Recent works on \"factorized\" ML mitigate this issue for a few specific ML algorithms by pushing ML through joins. But their approaches require a manual rewrite of ML implementations. Such piecemeal methods create a massive development overhead when extending such ideas to other ML algorithms. In this paper, we show that it is possible to mitigate this overhead by leveraging a popular formal algebra to represent the computations of many ML algorithms: linear algebra. We introduce a new logical data type to represent normalized data and devise a framework of algebraic rewrite rules to convert a large set of linear algebra operations over denormalized data into operations over normalized data. We show how this enables us to automatically \"factorize\" several popular ML algorithms, thus unifying and generalizing several prior works. We prototype our framework in the popular ML environment R and an industrial R-over-RDBMS tool. Experiments with both synthetic and real normalized data show that our framework also yields significant speed-ups, up to 36x on real data.",
                        "Citation Paper Authors": "Authors:Lingjiao Chen, Arun Kumar, Jeffrey Naughton, Jignesh M. Patel"
                    }
                },
                {
                    "Sentence ID": 54,
                    "Sentence": ".3.1 Operations in ML Work\ufb02ows\nIn this section, we argue that common operations in ML work-\n\ufb02ows can be decomposed into a small set of basis functionsF.\nWe \ufb01rst introduceFand then enumerate its mapping onto opera-\ntions in Scikit-learn ",
                    "Citation Text": "F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,\nV . Dubourg, et al. Scikit-learn: Machine learning in python.\nJournal of Machine Learning Research , 12(Oct):2825\u20132830,\n2011.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1201.0490",
                        "Citation Paper Title": "Title:Scikit-learn: Machine Learning in Python",
                        "Citation Paper Abstract": "Abstract:Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from this http URL.",
                        "Citation Paper Authors": "Authors:Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Andreas M\u00fcller, Joel Nothman, Gilles Louppe, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, \u00c9douard Duchesnay"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1807.01016v2": {
            "Paper Title": "Industrial Big Data Analytics: Challenges, Methodologies, and\n  Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.03975v1": {
            "Paper Title": "Scaling-Up In-Memory Datalog Processing: Observations and Techniques",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.03651v1": {
            "Paper Title": "Serverless Computing: One Step Forward, Two Steps Back",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.02386v1": {
            "Paper Title": "vChain: Enabling Verifiable Boolean Range Queries over Blockchain\n  Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.01741v1": {
            "Paper Title": "Exploiting Data Sensitivity on Partitioned Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.01663v1": {
            "Paper Title": "Skyline Diagram: Efficient Space Partitioning for Skyline Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1812.01790v1": {
            "Paper Title": "Hybrid Microaggregation for Privacy-Preserving Data Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.00511v2": {
            "Paper Title": "Chasing Similarity: Distribution-aware Aggregation Scheduling (Extended\n  Version)",
            "Sentences": [
                {
                    "Sentence ID": 12,
                    "Sentence": "used SIMD and MIMD to par-\nallelize the execution of aggregation. Gan et al. ",
                    "Citation Text": "E. Gan, J. Ding, K. S. Tai, V. Sharan, and P. Bailis.\nMoment-Based Quantile Sketches for E\ufb03cient High\nCardinality Aggregation Queries. CoRR,\nabs/1803.01969, 2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1803.01969",
                        "Citation Paper Title": "Title:Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries",
                        "Citation Paper Abstract": "Abstract:Interactive analytics increasingly involves querying for quantiles over sub-populations of high cardinality datasets. Data processing engines such as Druid and Spark use mergeable summaries to estimate quantiles, but summary merge times can be a bottleneck during aggregation. We show how a compact and efficiently mergeable quantile sketch can support aggregation workloads. This data structure, which we refer to as the moments sketch, operates with a small memory footprint (200 bytes) and computationally efficient (50ns) merges by tracking only a set of summary statistics, notably the sample moments. We demonstrate how we can efficiently and practically estimate quantiles using the method of moments and the maximum entropy principle, and show how the use of a cascade further improves query time for threshold predicates. Empirical evaluation on real-world datasets shows that the moments sketch can achieve less than 1 percent error with 15 times less merge overhead than comparable summaries, improving end query time in the MacroBase engine by up to 7 times and the Druid engine by up to 60 times.",
                        "Citation Paper Authors": "Authors:Edward Gan, Jialin Ding, Kai Sheng Tai, Vatsal Sharan, Peter Bailis"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1811.11593v1": {
            "Paper Title": "Attendance Maximization for Successful Social Event Planning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.11561v1": {
            "Paper Title": "Approximate Evaluation of Label-Constrained Reachability Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.10861v1": {
            "Paper Title": "AstroServ: Distributed Database for Serving Large-Scale Full Life-Cycle\n  Astronomical Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.10855v1": {
            "Paper Title": "Data Management in Time-Domain Astronomy: Requirements and Challenges",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.10835v1": {
            "Paper Title": "A Frequency Scaling based Performance Indicator Framework for Big Data\n  Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.10191v1": {
            "Paper Title": "Ontology Matching Techniques: A Gold Standard Model",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.05714v3": {
            "Paper Title": "r-HUMO: A Risk-Aware Human-Machine Cooperation Framework for Entity\n  Resolution with Quality Guarantees",
            "Sentences": [
                {
                    "Sentence ID": 23,
                    "Sentence": ",\nthe authors studied the more complicated problem of relational\nER, in which a resolution of some entities might in\ufb02uence the\nresolution of other entities. A similar iterative algorithm, SiGMa,\nwas proposed in ",
                    "Citation Text": "S. Lacoste-Julien, K. Palla, A. Davies, G. Kasneci, T. Graepel, and\nZ. Ghahramani, \u201cSigma: Simple greedy matching for aligning large\nknowledge bases, \u201d pp. 572\u2013580, 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1207.4525",
                        "Citation Paper Title": "Title:SiGMa: Simple Greedy Matching for Aligning Large Knowledge Bases",
                        "Citation Paper Abstract": "Abstract:The Internet has enabled the creation of a growing number of large-scale knowledge bases in a variety of domains containing complementary information. Tools for automatically aligning these knowledge bases would make it possible to unify many sources of structured knowledge and answer complex queries. However, the efficient alignment of large-scale knowledge bases still poses a considerable challenge. Here, we present Simple Greedy Matching (SiGMa), a simple algorithm for aligning knowledge bases with millions of entities and facts. SiGMa is an iterative propagation algorithm which leverages both the structural information from the relationship graph as well as flexible similarity measures between entity properties in a greedy local search, thus making it scalable. Despite its greedy nature, our experiments indicate that SiGMa can efficiently match some of the world's largest knowledge bases with high precision. We provide additional experiments on benchmark datasets which demonstrate that SiGMa can outperform state-of-the-art approaches both in accuracy and efficiency.",
                        "Citation Paper Authors": "Authors:Simon Lacoste-Julien, Konstantina Palla, Alex Davies, Gjergji Kasneci, Thore Graepel, Zoubin Ghahramani"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1811.09529v1": {
            "Paper Title": "Competency Questions and SPARQL-OWL Queries Dataset and Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.08181v1": {
            "Paper Title": "HyperBench: A Benchmark and Tool for Hypergraphs and Empirical Findings",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.08143v1": {
            "Paper Title": "StarStar Models: Process Analysis on top of Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.07525v1": {
            "Paper Title": "DEXON: A Highly Scalable, Decentralized DAG-Based Consensus Algorithm",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.02291v3": {
            "Paper Title": "The Window Validity Problem in Rule-Based Stream Reasoning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.04013v2": {
            "Paper Title": "Stream Reasoning in Temporal Datalog",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.06224v1": {
            "Paper Title": "Model-based Approximate Query Processing",
            "Sentences": [
                {
                    "Sentence ID": 8,
                    "Sentence": ". For example, such data structures\ncan be materialized views or data cubes ",
                    "Citation Text": "J. Gray, S. Chaudhuri, A. Bosworth, A. Layman, D. Reichart, M. Venkatrao,\nF. Pellow, and H. Pirahesh. Data Cube: A Relational Aggregation Operator Gen-\neralizing Group-By, Cross-Tab, and Sub-Totals. Data Mining and KnowledgeDiscovery , 1(1):29\u201353, March 1997.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:cs/0701155",
                        "Citation Paper Title": "Title:Data Cube: A Relational Aggregation Operator Generalizing Group-By, Cross-Tab, and Sub-Totals",
                        "Citation Paper Abstract": "Abstract:  Data analysis applications typically aggregate data across many dimensions looking for anomalies or unusual patterns. The SQL aggregate functions and the GROUP BY operator produce zero-dimensional or one-dimensional aggregates. Applications need the N-dimensional generalization of these operators. This paper defines that operator, called the data cube or simply cube. The cube operator generalizes the histogram, cross-tabulation, roll-up, drill-down, and sub-total constructs found in most report writers. The novelty is that cubes are relations. Consequently, the cube operator can be imbedded in more complex non-procedural data analysis programs. The cube operator treats each of the N aggregation attributes as a dimension of N-space. The aggregate of a particular set of attribute values is a point in this space. The set of points forms an N-dimensional cube. Super-aggregates are computed by aggregating the N-cube to lower dimensional spaces. This paper (1) explains the cube and roll-up operators, (2) shows how they fit in SQL, (3) explains how users can define new aggregate functions for cubes, and (4) discusses efficient techniques to compute the cube. Many of these features are being added to the SQL Standard.",
                        "Citation Paper Authors": "Authors:Jim Gray, Surajit Chaudhuri, Adam Bosworth, Andrew Layman, Don Reichart, Murali Venkatrao, Frank Pellow, Hamid Pirahesh"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1811.05065v1": {
            "Paper Title": "PanJoin: A Partition-based Adaptive Stream Join",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.04967v1": {
            "Paper Title": "The Impact of Timestamp Granularity in Optimistic Concurrency Control",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.04162v1": {
            "Paper Title": "Computational Thinking with the Web Crowd using CodeMapper",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.08182v2": {
            "Paper Title": "Instance-Optimality in the Noisy Value-and Comparison-Model --- Accept,\n  Accept, Strong Accept: Which Papers get in?",
            "Sentences": []
        },
        "http://arxiv.org/abs/1811.01313v1": {
            "Paper Title": "Lower Bounds for External Memory Integer Sorting via Network Coding",
            "Sentences": [
                {
                    "Sentence ID": 6,
                    "Sentence": "showed how to exploit\ninteger input to develop external memory priority queues with DecreaseKeys that outperform their\ncomparison based counterparts. Their upper bound almost matches an unconditional lower bound\nby Eenberg et al. ",
                    "Citation Text": "Eenberg, K., Larsen, K. G., and Yu, H. (2017). Decreasekeys are expensive for external memory\npriority queues. In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of\nComputing, STOC 2017 , pages 1081{1093.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1611.00911",
                        "Citation Paper Title": "Title:DecreaseKeys are Expensive for External Memory Priority Queues",
                        "Citation Paper Abstract": "Abstract:One of the biggest open problems in external memory data structures is the priority queue problem with DecreaseKey operations. If only Insert and ExtractMin operations need to be supported, one can design a comparison-based priority queue performing $O((N/B)\\lg_{M/B} N)$ I/Os over a sequence of $N$ operations, where $B$ is the disk block size in number of words and $M$ is the main memory size in number of words. This matches the lower bound for comparison-based sorting and is hence optimal for comparison-based priority queues. However, if we also need to support DecreaseKeys, the performance of the best known priority queue is only $O((N/B) \\lg_2 N)$ I/Os. The big open question is whether a degradation in performance really is necessary. We answer this question affirmatively by proving a lower bound of $\\Omega((N/B) \\lg_{\\lg N} B)$ I/Os for processing a sequence of $N$ intermixed Insert, ExtraxtMin and DecreaseKey operations. Our lower bound is proved in the cell probe model and thus holds also for non-comparison-based priority queues.",
                        "Citation Paper Authors": "Authors:Kasper Eenberg, Kasper Green Larsen, Huacheng Yu"
                    }
                },
                {
                    "Sentence ID": 11,
                    "Sentence": "Proving lower bounds for external memory algorithms and data structures without assumptions\nsuch as indivisibility and comparison based has been the focus of a number of recent papers. Quite\nsurprisingly, Iacono and P\u0015 atra\u0018 scu ",
                    "Citation Text": "Iacono, J. and P\u0015 atra\u0018 scu, M. (2012). Using hashing to solve the dictionary problem (in ex-\nternal memory). In Proceedings of the twenty-third annual ACM-SIAM symposium on Discrete\nalgorithms , pages 570{582. SIAM.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1104.2799",
                        "Citation Paper Title": "Title:Using Hashing to Solve the Dictionary Problem (In External Memory)",
                        "Citation Paper Abstract": "Abstract:We consider the dictionary problem in external memory and improve the update time of the well-known buffer tree by roughly a logarithmic factor. For any \\lambda >= max {lg lg n, log_{M/B} (n/B)}, we can support updates in time O(\\lambda / B) and queries in sublogarithmic time, O(log_\\lambda n). We also present a lower bound in the cell-probe model showing that our data structure is optimal.\nIn the RAM, hash tables have been used to solve the dictionary problem faster than binary search for more than half a century. By contrast, our data structure is the first to beat the comparison barrier in external memory. Ours is also the first data structure to depart convincingly from the indivisibility paradigm.",
                        "Citation Paper Authors": "Authors:John Iacono, Mihai P\u01cetra\u015fcu"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1811.00602v1": {
            "Paper Title": "VizRec: A framework for secure data exploration via visual\n  representation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.11308v1": {
            "Paper Title": "Sub-O(log n) Out-of-Order Sliding-Window Aggregation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.11152v1": {
            "Paper Title": "Efficient and High-Quality Seeded Graph Matching: Employing High Order\n  Structural Information",
            "Sentences": [
                {
                    "Sentence ID": 26,
                    "Sentence": "2:4M 5:0M 9:2M 3:6\nTable 3: Snapshots of Superuser and AskUbuntu.\nPeriod jVj jEj jV1\\V2j jE1\\E2j\nSuperuser ",
                    "Citation Text": "A. Paranjape, A. R. Benson, and J. Leskovec. Motifs in\ntemporal networks. In Proceedings of the Tenth ACM\nInternational Conference on Web Search and Data Mining ,\npages 601\u2013610. ACM, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1612.09259",
                        "Citation Paper Title": "Title:Motifs in Temporal Networks",
                        "Citation Paper Abstract": "Abstract:Networks are a fundamental tool for modeling complex systems in a variety of domains including social and communication networks as well as biology and neuroscience. Small subgraph patterns in networks, called network motifs, are crucial to understanding the structure and function of these systems. However, the role of network motifs in temporal networks, which contain many timestamped links between the nodes, is not yet well understood.\nHere we develop a notion of a temporal network motif as an elementary unit of temporal networks and provide a general methodology for counting such motifs. We define temporal network motifs as induced subgraphs on sequences of temporal edges, design fast algorithms for counting temporal motifs, and prove their runtime complexity. Our fast algorithms achieve up to 56.5x speedup compared to a baseline method. Furthermore, we use our algorithms to count temporal motifs in a variety of networks. Results show that networks from different domains have significantly different motif counts, whereas networks from the same domain tend to have similar motif counts. We also find that different motifs occur at different time scales, which provides further insights into structure and function of temporal networks.",
                        "Citation Paper Authors": "Authors:Ashwin Paranjape, Austin R. Benson, Jure Leskovec"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1810.09780v1": {
            "Paper Title": "Heuristics-based Query Reordering for Federated Queries in SPARQL 1.1\n  and SPARQL-LD",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.09378v1": {
            "Paper Title": "biggy: An Implementation of Unified Framework for Big Data Management\n  System",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.09355v1": {
            "Paper Title": "Fast Dual Simulation Processing of Graph Database Queries (Supplement)",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.09227v1": {
            "Paper Title": "Knowledge Graph Completion to Predict Polypharmacy Side Effects",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.09007v1": {
            "Paper Title": "Spatial Co-location Pattern Mining - A new perspective using Graph\n  Database",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.04968v2": {
            "Paper Title": "Crowd-Powered Data Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.08047v1": {
            "Paper Title": "Finding Average Regret Ratio Minimizing Set in Database",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.07355v1": {
            "Paper Title": "Optimization of Indexing Based on k-Nearest Neighbor Graph for Proximity\n  Search in High-dimensional Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.01223v2": {
            "Paper Title": "Eclipse: Practicability Beyond kNN and Skyline",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.06911v1": {
            "Paper Title": "Cyber-Physical Systems, a new formal paradigm to model redundancy and\n  resiliency",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.04599v2": {
            "Paper Title": "Understanding Data Science Lifecycle Provenance via Graph Segmentation\n  and Summarization",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.06021v1": {
            "Paper Title": "DPASF: A Flink Library for Streaming Data preprocessing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.05570v1": {
            "Paper Title": "Characterization and extraction of condensed representation of\n  correlated patterns based on formal concept analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.05357v1": {
            "Paper Title": "On The Equivalence of Tries and Dendrograms - Efficient Hierarchical\n  Clustering of Traffic Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.04915v1": {
            "Paper Title": "A Comparative Study of Consistent Snapshot Algorithms for Main-Memory\n  Database Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.04604v1": {
            "Paper Title": "A Similarity Measure for Weaving Patterns in Textiles",
            "Sentences": [
                {
                    "Sentence ID": 16,
                    "Sentence": ".  Hass et al. review a number of knot algorithms  and conclude that they are impractical and that the exact complexity  of \nseveral general problems in this area is not even clear ",
                    "Citation Text": "J. Hass, J. Lagarias, and N. Pippenger. The computational  complexity of knot and link problems. J. ACM , 46(2):185 \u2013\n211, 1999.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:math/9807016",
                        "Citation Paper Title": "Title:The Computational Complexity of Knot and Link Problems",
                        "Citation Paper Abstract": "Abstract:  We consider the problem of deciding whether a polygonal knot in 3-dimensional Euclidean space is unknotted, capable of being continuously deformed without self-intersection so that it lies in a plane. We show that this problem, {\\sc unknotting problem} is in {\\bf NP}. We also consider the problem, {\\sc unknotting problem} of determining whether two or more such polygons can be split, or continuously deformed without self-intersection so that they occupy both sides of a plane without intersecting it. We show that it also is in NP. Finally, we show that the problem of determining the genus of a polygonal knot (a generalization of the problem of determining whether it is unknotted) is in {\\bf PSPACE}. We also give exponential worst-case running time bounds for deterministic algorithms to solve each of these problems. These algorithms are based on the use of normal surfaces and decision procedures due to W. Haken, with recent extensions by W. Jaco and J. L. Tollefson.",
                        "Citation Paper Authors": "Authors:Joel Hass, Jeffrey C. Lagarias, Nicholas Pippenger"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1810.03386v1": {
            "Paper Title": "Consistent Query Answering for Primary Keys in Logspace",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.01997v1": {
            "Paper Title": "Improving High Contention OLTP Performance via Transaction Scheduling",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": "identify lock contention as a significant overhead\nproposes an MVCC based optimization to reduce it.\nOrthrus ",
                    "Citation Text": "Kun Ren, Jose M. Faleiro, and Daniel J. Abadi. 2016. Design Principles\nfor Scaling Multi-core OLTP Under High Contention. In Proceedings\nof the 2016 International Conference on Management of Data (SIGMOD\n\u201916). ACM, New York, NY, USA, 1583\u20131598. https://doi.org/10.1145/\n2882903.2882958",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1512.06168",
                        "Citation Paper Title": "Title:Design Principles for Scaling Multi-core OLTP Under High Contention",
                        "Citation Paper Abstract": "Abstract:Although significant recent progress has been made in improving the multi-core scalability of high throughput transactional database systems, modern systems still fail to achieve scalable throughput for workloads involving frequent access to highly contended data. Most of this inability to achieve high throughput is explained by the fundamental constraints involved in guaranteeing ACID --- the addition of cores results in more concurrent transactions accessing the same contended data for which access must be serialized in order to guarantee isolation. Thus, linear scalability for contended workloads is impossible. However, there exist flaws in many modern architectures that exacerbate their poor scalability, and result in throughput that is much worse than fundamentally required by the workload.\nIn this paper we identify two prevalent design principles that limit the multi-core scalability of many (but not all) transactional database systems on contended workloads: the multi-purpose nature of execution threads in these systems, and the lack of advanced planning of data access. We demonstrate the deleterious results of these design principles by implementing a prototype system, ORTHRUS, that is motivated by the principles of separation of database component functionality and advanced planning of transactions. We find that these two principles alone result in significantly improved scalability on high-contention workloads, and an order of magnitude increase in throughput for a non-trivial subset of these contended workloads.",
                        "Citation Paper Authors": "Authors:Kun Ren, Jose M. Faleiro, Daniel J. Abadi"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1810.01816v1": {
            "Paper Title": "Shrinkwrap: Differentially-Private Query Processing in Private Data\n  Federations",
            "Sentences": [
                {
                    "Sentence ID": 4,
                    "Sentence": "to implement our RAM\nbased relational operators, under a SMCQL ",
                    "Citation Text": "J. Bater, G. Elliott, C. Eggen, S. Goel, A. Kho, and J. Rogers.\nSMCQL. Proceedings of the VLDB Endowment ,\n10(6):673{684, feb 2017.\n12",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1606.06808",
                        "Citation Paper Title": "Title:SMCQL: Secure Querying for Federated Databases",
                        "Citation Paper Abstract": "Abstract:People and machines are collecting data at an unprecedented rate. Despite this newfound abundance of data, progress has been slow in sharing it for open science, business, and other data-intensive endeavors. Many such efforts are stymied by privacy concerns and regulatory compliance issues. For example, many hospitals are interested in pooling their medical records for research, but none may disclose arbitrary patient records to researchers or other healthcare providers. In this context we propose the Private Data Network (PDN), a federated database for querying over the collective data of mutually distrustful parties. In a PDN, each member database does not reveal its tuples to its peers nor to the query writer. Instead, the user submits a query to an honest broker that plans and coordinates its execution over multiple private databases using secure multiparty computation (SMC). Here, each database's query execution is oblivious, and its program counters and memory traces are agnostic to the inputs of others. We introduce a framework for executing PDN queries named SMCQL. This system translates SQL statements into SMC primitives to compute query results over the union of its source databases without revealing sensitive information about individual tuples to peer data providers or the honest broker. Only the honest broker and the querier receive the results of a PDN query. For fast, secure query evaluation, we explore a heuristics-driven optimizer that minimizes the PDN's use of secure computation and partitions its query evaluation into scalable slices.",
                        "Citation Paper Authors": "Authors:Johes Bater, Gregory Elliott, Craig Eggen, Satyender Goel, Abel Kho, Jennie Rogers"
                    }
                },
                {
                    "Sentence ID": 35,
                    "Sentence": "or (ii) optimizing privacy budget alloca-\ntion across the operators of a workload of prede\fned SQL\nqueries (e.g. using ",
                    "Citation Text": "R. McKenna, G. Miklau, M. Hay, and A. Machanavajjhala.\nOptimizing error of high-dimensional statistical queries under\ndi\u000berential privacy. Proc. VLDB Endow. , 2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1808.03537",
                        "Citation Paper Title": "Title:Optimizing error of high-dimensional statistical queries under differential privacy",
                        "Citation Paper Abstract": "Abstract:Differentially private algorithms for answering sets of predicate counting queries on a sensitive database have many applications. Organizations that collect individual-level data, such as statistical agencies and medical institutions, use them to safely release summary tabulations. However, existing techniques are accurate only on a narrow class of query workloads, or are extremely slow, especially when analyzing more than one or two dimensions of the data. In this work we propose HDMM, a new differentially private algorithm for answering a workload of predicate counting queries, that is especially effective for higher-dimensional datasets. HDMM represents query workloads using an implicit matrix representation and exploits this compact representation to efficiently search (a subset of) the space of differentially private algorithms for one that answers the input query workload with high accuracy. We empirically show that HDMM can efficiently answer queries with lower error than state-of-the-art techniques on a variety of low and high dimensional datasets.",
                        "Citation Paper Authors": "Authors:Ryan McKenna, Gerome Miklau, Michael Hay, Ashwin Machanavajjhala"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1810.01037v1": {
            "Paper Title": "Heterogeneous Replica for Query on Cassandra",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.05054v2": {
            "Paper Title": "IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic\n  Oracles",
            "Sentences": []
        },
        "http://arxiv.org/abs/1810.00326v1": {
            "Paper Title": "Using Graph-Pattern Association Rules On Yago Knowledge Base",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.00405v2": {
            "Paper Title": "Query Log Compression for Workload Analytics",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.11084v1": {
            "Paper Title": "Reuse and Adaptation for Entity Resolution through Transfer Learning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.10054v1": {
            "Paper Title": "General-purpose Declarative Inductive Programming with Domain-Specific\n  Background Knowledge for Data Wrangling Automation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.04159v2": {
            "Paper Title": "Mining Non-Redundant Local Process Models From Sequence Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.06859v1": {
            "Paper Title": "HDTCat: let's make HDT scale",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.12319v3": {
            "Paper Title": "Skyblocking for Entity Resolution",
            "Sentences": [
                {
                    "Sentence ID": 7,
                    "Sentence": "showed that active learning may provide al-\nmost the same or even better results in solving the class imbal-\nance problem, compared with the random sampling approaches,\nsuch as oversampling the minority class and /or undersampling\nthe majority class ",
                    "Citation Text": "N. V . Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. Smote:\nsynthetic minority over-sampling technique. Journal of arti\ufb01cial intelli-\ngence research , 16:321\u2013357, 2002.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1106.1813",
                        "Citation Paper Title": "Title:SMOTE: Synthetic Minority Over-sampling Technique",
                        "Citation Paper Abstract": "Abstract:An approach to the construction of classifiers from    imbalanced datasets is described. A dataset is imbalanced if the    classification categories are not approximately equally    represented. Often real-world data sets are predominately composed of    \"normal\" examples with only a small percentage of \"abnormal\" or    \"interesting\" examples. It is also the case that the cost of    misclassifying an abnormal (interesting) example as a normal example    is often much higher than the cost of the reverse    error. Under-sampling of the majority (normal) class has been proposed    as a good means of increasing the sensitivity of a classifier to the    minority class. This paper shows that a combination of our method of    over-sampling the minority (abnormal) class and under-sampling the    majority (normal) class can achieve better classifier performance (in    ROC space) than only under-sampling the majority class.  This paper    also shows that a combination of our method of over-sampling the    minority class and under-sampling the majority class can achieve    better classifier performance (in ROC space) than varying the loss    ratios in Ripper or class priors in Naive Bayes. Our method of    over-sampling the minority class involves creating synthetic minority    class examples.  Experiments are performed using C4.5, Ripper and a    Naive Bayes classifier. The method is evaluated using the area under    the Receiver Operating Characteristic curve (AUC) and the ROC convex    hull strategy.",
                        "Citation Paper Authors": "Authors:N. V. Chawla, K. W. Bowyer, L. O. Hall, W. P. Kegelmeyer"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1809.05495v1": {
            "Paper Title": "Auto-tuning Distributed Stream Processing Systems using Reinforcement\n  Learning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.05234v1": {
            "Paper Title": "In-Route Task Selection in Crowdsourcing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.00370v2": {
            "Paper Title": "Differentially Private Hierarchical Count-of-Counts Histograms",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.11728v2": {
            "Paper Title": "Sapphire: Querying RDF Data Made Simple",
            "Sentences": [
                {
                    "Sentence ID": 13,
                    "Sentence": "in Section 2 and present the ar-\nchitecture of Sapphire in Section 3. We present the Sapphire\nuser interface from ",
                    "Citation Text": "A. El-Roby, K. Ammar, A. Aboulnaga, and J. Lin.\nSapphire: Querying RDF data made simple (demo).\nProceedings of the VLDB Endowment (PVLDB) , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1805.11728",
                        "Citation Paper Title": "Title:Sapphire: Querying RDF Data Made Simple",
                        "Citation Paper Abstract": "Abstract:RDF data in the linked open data (LOD) cloud is very valuable for many different applications. In order to unlock the full value of this data, users should be able to issue complex queries on the RDF datasets in the LOD cloud. SPARQL can express such complex queries, but constructing SPARQL queries can be a challenge to users since it requires knowing the structure and vocabulary of the datasets being queried. In this paper, we introduce Sapphire, a tool that helps users write syntactically and semantically correct SPARQL queries without prior knowledge of the queried datasets. Sapphire interactively helps the user while typing the query by providing auto-complete suggestions based on the queried data. After a query is issued, Sapphire provides suggestions on ways to change the query to better match the needs of the user. We evaluated Sapphire based on performance experiments and a user study and showed it to be superior to competing approaches.",
                        "Citation Paper Authors": "Authors:Ahmed El-Roby, Khaled Ammar, Ashraf Aboulnaga, Jimmy Lin"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1807.03100v3": {
            "Paper Title": "Robust Text-to-SQL Generation with Execution-Guided Decoding",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.03222v2": {
            "Paper Title": "Forecasting Across Time Series Databases using Recurrent Neural Networks\n  on Groups of Similar Series: A Clustering Approach",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.04284v1": {
            "Paper Title": "An Approach to Handle Big Data Warehouse Evolution",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.04017v1": {
            "Paper Title": "Reducing Uncertainty of Schema Matching via Crowdsourcing with Accuracy\n  Rates",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.03048v3": {
            "Paper Title": "Clustrophile 2: Guided Visual Clustering Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.02631v1": {
            "Paper Title": "Pushing the Limits of Encrypted Databases with Secure Hardware",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.02345v1": {
            "Paper Title": "Hierarchical Characteristic Set Merging for Optimizing SPARQL Queries in\n  Heterogeneous RDF",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.01622v1": {
            "Paper Title": "Ranking RDF Instances in Degree-decoupled RDF Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.09240v3": {
            "Paper Title": "Time Constrained Continuous Subgraph Search over Streaming Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.00641v1": {
            "Paper Title": "Typed Linear Algebra for Efficient Analytical Querying",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.00458v1": {
            "Paper Title": "GB-KMV: An Augmented KMV Sketch for Approximate Containment Similarity\n  Search",
            "Sentences": [
                {
                    "Sentence ID": 19,
                    "Sentence": ", Christiani et al. give a data structure for approximate\nsimilarity search under Braun-Blanquet similarity which h as a\n1-1 mapping to Jaccard similarity if all the sizes of records are\n\ufb01xed. In ",
                    "Citation Text": "R. Cohen, L. Katzir, and A. Yehezkel. A minimal variance estimator\nfor the cardinality of big data set intersection. In SIGKDD , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1606.00996",
                        "Citation Paper Title": "Title:A Minimal Variance Estimator for the Cardinality of Big Data Set Intersection",
                        "Citation Paper Abstract": "Abstract:In recent years there has been a growing interest in developing \"streaming algorithms\" for efficient processing and querying of continuous data streams. These algorithms seek to provide accurate results while minimizing the required storage and the processing time, at the price of a small inaccuracy in their output. A fundamental query of interest is the intersection size of two big data streams. This problem arises in many different application areas, such as network monitoring, database systems, data integration and information retrieval. In this paper we develop a new algorithm for this problem, based on the Maximum Likelihood (ML) method. We show that this algorithm outperforms all known schemes and that it asymptotically achieves the optimal variance.",
                        "Citation Paper Authors": "Authors:Reuven Cohen, Liran Katzir, Aviv Yehezkel"
                    }
                },
                {
                    "Sentence ID": 23,
                    "Sentence": "consider the relations among\nrecords in query processing to improve the performance. Den g\net al. in ",
                    "Citation Text": "D. Deng, A. Kim, S. Madden, and M. Stonebraker. Silkmoth : An\nef\ufb01cient method for \ufb01nding related sets with maximum matchi ng\nconstraints. arXiv preprint arXiv:1704.04738 , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1704.04738",
                        "Citation Paper Title": "Title:SilkMoth: An Efficient Method for Finding Related Sets with Maximum Matching Constraints",
                        "Citation Paper Abstract": "Abstract:Determining if two sets are related - that is, if they have similar values or if one set contains the other - is an important problem with many applications in data cleaning, data integration, and information retrieval. A particularly popular metric that has been proposed is to measure the relatedness of two sets by treating the elements as vertices of a bipartite graph and calculating the score of the maximum matching pairing between elements. Compared to other metrics which require exact matchings between elements, this metric uses a similarity function to compare elements between the two sets, making it robust to small dissimilarities in elements and more useful for real-world, dirty data. Unfortunately, the metric suffers from expensive computational cost, taking O(n^3) time, where n is the number of elements in sets, for each set-to-set comparison. Thus for applications which try to search for all pairings of related sets in a brute-force manner, the runtime becomes unacceptably large.\nTo address this challenge, we developed SilkMoth, a system capable of rapidly discovering related set pairs in collections of sets. Internally, SilkMoth creates a signature for each set, with the property that any other set which is related must match the signature. SilkMoth then uses these signatures to prune the search space, so only sets which match the signatures are left as candidates. Finally, SilkMoth applies the maximum matching metric on remaining candidates to verify which of these candidates are truly related sets. Thus, a contribution of this paper is the characterization of the space of signatures which enable this property. We show that selecting the optimal signature in this space is NP-complete, and based on insights from the characterization of the space, we propose two novel filters which help to prune the candidates further before verification.",
                        "Citation Paper Authors": "Authors:Dong Deng, Albert Kim, Samuel Madden, Michael Stonebraker"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1809.00089v1": {
            "Paper Title": "Eliminating Boundaries in Cloud Storage with Anna",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.07686v2": {
            "Paper Title": "Verifying Text Summaries of Relational Data Sets",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.05369v2": {
            "Paper Title": "Foundations of Complex Event Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1809.00974v1": {
            "Paper Title": "Performing energy modelling exercises in a transparent way the issue of\n  data quality in power plant databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.09545v1": {
            "Paper Title": "Cost-efficient Data Acquisition on Online Data Marketplaces for\n  Correlation Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.08634v2": {
            "Paper Title": "Rule Module Inheritance with Modification Restrictions",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.08355v1": {
            "Paper Title": "Database-Agnostic Workload Management",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.08181v1": {
            "Paper Title": "Truth Inference on Sparse Crowdsourcing Data with Local Differential\n  Privacy",
            "Sentences": [
                {
                    "Sentence ID": 14,
                    "Sentence": ". Microsoft adapts LDP to its collection process of a\nvariety of telemetry data ",
                    "Citation Text": "B. Ding, J. Kulkarni, and S. Yekhanin. Collecting telemetry data\nprivately. In Advances in Neural Information Processing Systems , pages\n3574\u20133583, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1712.01524",
                        "Citation Paper Title": "Title:Collecting Telemetry Data Privately",
                        "Citation Paper Abstract": "Abstract:The collection and analysis of telemetry data from users' devices is routinely performed by many software companies. Telemetry collection leads to improved user experience but poses significant risks to users' privacy. Locally differentially private (LDP) algorithms have recently emerged as the main tool that allows data collectors to estimate various population statistics, while preserving privacy. The guarantees provided by such algorithms are typically very strong for a single round of telemetry collection, but degrade rapidly when telemetry is collected regularly. In particular, existing LDP algorithms are not suitable for repeated collection of counter data such as daily app usage statistics. In this paper, we develop new LDP mechanisms geared towards repeated collection of counter data, with formal privacy guarantees even after being executed for an arbitrarily long period of time. For two basic analytical tasks, mean estimation and histogram estimation, our LDP mechanisms for repeated data collection provide estimates with comparable or even the same accuracy as existing single-round LDP collection mechanisms. We conduct empirical evaluation on real-world counter datasets to verify our theoretical results. Our mechanisms have been deployed by Microsoft to collect telemetry across millions of devices.",
                        "Citation Paper Authors": "Authors:Bolin Ding, Janardhan Kulkarni, Sergey Yekhanin"
                    }
                },
                {
                    "Sentence ID": 29,
                    "Sentence": ".\nRecently, a variant of DP, named local differential privacy\n(LDP) ",
                    "Citation Text": "S. P. Kasiviswanathan, H. K. Lee, K. Nissim, S. Raskhodnikova, and\nA. Smith. What can we learn privately? SIAM Journal on Computing ,\n40(3):793\u2013826, 2011.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:0803.0924",
                        "Citation Paper Title": "Title:What Can We Learn Privately?",
                        "Citation Paper Abstract": "Abstract:  Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets. We ask: what concept classes can be learned privately, namely, by an algorithm whose output does not depend too heavily on any one input or specific training example? More precisely, we investigate learning algorithms that satisfy differential privacy, a notion that provides strong confidentiality guarantees in contexts where aggregate information is released about a database containing sensitive information about individuals. We demonstrate that, ignoring computational constraints, it is possible to privately agnostically learn any concept class using a sample size approximately logarithmic in the cardinality of the concept class. Therefore, almost anything learnable is learnable privately: specifically, if a concept class is learnable by a (non-private) algorithm with polynomial sample complexity and output size, then it can be learned privately using a polynomial number of samples. We also present a computationally efficient private PAC learner for the class of parity functions. Local (or randomized response) algorithms are a practical class of private algorithms that have received extensive investigation. We provide a precise characterization of local private learning algorithms. We show that a concept class is learnable by a local algorithm if and only if it is learnable in the statistical query (SQ) model. Finally, we present a separation between the power of interactive and noninteractive local learning algorithms.",
                        "Citation Paper Authors": "Authors:Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova, Adam Smith"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1805.05670v3": {
            "Paper Title": "NEURON: Query Optimization Meets Natural Language Processing For\n  Augmenting Database Education",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.06298v1": {
            "Paper Title": "FedMark: A Marketplace for Federated Data on the Web",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": "utilized\na market mechanism to optimize the use of idle resources in a network of workstations.\nMore recently, ",
                    "Citation Text": "Kevin Lai, Lars Rasmusson, Eytan Adar, Li Zhang, and Bernardo A. Huberman.\nTycoon: An Implementation of a Distributed, Market-based Resource Allocation\nSystem. Multiagent and Grid Systems , 1(3):169{182, August 2005.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:cs/0412038",
                        "Citation Paper Title": "Title:Tycoon: an Implementation of a Distributed, Market-based Resource Allocation System",
                        "Citation Paper Abstract": "Abstract:  Distributed clusters like the Grid and PlanetLab enable the same statistical multiplexing efficiency gains for computing as the Internet provides for networking. One major challenge is allocating resources in an economically efficient and low-latency way. A common solution is proportional share, where users each get resources in proportion to their pre-defined weight. However, this does not allow users to differentiate the value of their jobs. This leads to economic inefficiency. In contrast, systems that require reservations impose a high latency (typically minutes to hours) to acquire resources.\nWe present Tycoon, a market based distributed resource allocation system based on proportional share. The key advantages of Tycoon are that it allows users to differentiate the value of their jobs, its resource acquisition latency is limited only by communication delays, and it imposes no manual bidding overhead on users. We present experimental results using a prototype implementation of our design.",
                        "Citation Paper Authors": "Authors:Kevin Lai, Lars Rasmusson, Eytan Adar, Stephen Sorkin, Li Zhang, Bernardo A. Huberman"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1808.05698v1": {
            "Paper Title": "Session Guarantees with Raft and Hybrid Logical Clocks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.05448v1": {
            "Paper Title": "Automatic Generation of a Hybrid Query Execution Engine",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.01367v2": {
            "Paper Title": "EmbNum: Semantic labeling for numerical values with deep metric learning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.05752v1": {
            "Paper Title": "PUG: A Framework and Practical Implementation for Why & Why-Not\n  Provenance (extended version)",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.05215v1": {
            "Paper Title": "Vis4DD: A visualization system that supports Data Quality Visual\n  Assessment",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.02850v1": {
            "Paper Title": "Relaxing and Restraining Queries for OBDA",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.02793v1": {
            "Paper Title": "Efficient Continuous Top-$k$ Geo-Image Search on Road Network",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.02066v1": {
            "Paper Title": "The Internals of the Data Calculator",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.01624v1": {
            "Paper Title": "On the Fairness of Quality-based Data Markets",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.01621v1": {
            "Paper Title": "Mining CFD Rules on Big Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.01620v1": {
            "Paper Title": "Schema Integration on Massive Data Sources",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.00986v1": {
            "Paper Title": "Diversification on Big Data in Query Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.01596v4": {
            "Paper Title": "A Survey of State Management in Big Data Processing Systems",
            "Sentences": [
                {
                    "Sentence ID": 47,
                    "Sentence": "introduce a new mathematical theory (i.e., the theory of changes and derivatives) for incremental computation. Hammer et al. ",
                    "Citation Text": "M. A. Hammer, J. Dunfield, K. Headley, N. Labich, J. S. Foster, M. Hicks, and D. V. Horn. 2015. Incremental computation with names. SIGPLAN, 50(10):748-766, 2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1503.07792",
                        "Citation Paper Title": "Title:Incremental Computation with Names",
                        "Citation Paper Abstract": "Abstract:Over the past thirty years, there has been significant progress in developing general-purpose, language-based approaches to incremental computation, which aims to efficiently update the result of a computation when an input is changed. A key design challenge in such approaches is how to provide efficient incremental support for a broad range of programs. In this paper, we argue that first-class names are a critical linguistic feature for efficient incremental computation. Names identify computations to be reused across differing runs of a program, and making them first class gives programmers a high level of control over reuse. We demonstrate the benefits of names by presenting NOMINAL ADAPTON, an ML-like language for incremental computation with names. We describe how to use NOMINAL ADAPTON to efficiently incrementalize several standard programming patterns -- including maps, folds, and unfolds -- and show how to build efficient, incremental probabilistic trees and tries. Since NOMINAL ADAPTON's implementation is subtle, we formalize it as a core calculus and prove it is from-scratch consistent, meaning it always produces the same answer as simply re-running the computation. Finally, we demonstrate that NOMINAL ADAPTON can provide large speedups over both from-scratch computation and ADAPTON, a previous state-of-the-art incremental computation system.",
                        "Citation Paper Authors": "Authors:Matthew A. Hammer, Jana Dunfield, Kyle Headley, Nicholas Labich, Jeffrey S. Foster, Michael Hicks, David Van Horn"
                    }
                },
                {
                    "Sentence ID": 81,
                    "Sentence": "reuse checkpoints for load balancing fault tolerance,     state migration,      and load balancing ",
                    "Citation Text": "K. G. S. Madsen, Y. Zhou, J. Cao. Integrative Dynamic Reconfiguration in a Parallel Stream Processing Engine. The Computing Research Repository (CoRR), abs/1602.03770, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1602.03770",
                        "Citation Paper Title": "Title:Integrative Dynamic Reconfiguration in a Parallel Stream Processing Engine",
                        "Citation Paper Abstract": "Abstract:Load balancing, operator instance collocations and horizontal scaling are critical issues in Parallel Stream Processing Engines to achieve low data processing latency, optimized cluster utilization and minimized communication cost respectively. In previous work, these issues are typically tackled separately and independently. We argue that these problems are tightly coupled in the sense that they all need to determine the allocations of workloads and migrate computational states at runtime. Optimizing them independently would result in suboptimal solutions. Therefore, in this paper, we investigate how these three issues can be modeled as one integrated optimization problem. In particular, we first consider jobs where workload allocations have little effect on the communication cost, and model the problem of load balance as a Mixed-Integer Linear Program. Afterwards, we present an extended solution called ALBIC, which support general jobs. We implement the proposed techniques on top of Apache Storm, an open-source Parallel Stream Processing Engine. The extensive experimental results over both synthetic and real datasets show that our techniques clearly outperform existing approaches.",
                        "Citation Paper Authors": "Authors:Kasper Grud Skat Madsen, Yongluan Zhou, Jianneng Cao"
                    }
                },
                {
                    "Sentence ID": 124,
                    "Sentence": ", since they incur a large overhead, in particular for many graph or social network analysis algorithms. These often times needlessly reload and reprocess data during iterations; even though they leave large parts of the data unchanged ",
                    "Citation Text": "S. Sakr, A. Liu, A. Fayoumi. The Family of MapReduce and Large Scale Data Processing Systems. Journal of ACM Computing Surveys (ACM CSUR), 46(1), 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1302.2966",
                        "Citation Paper Title": "Title:The Family of MapReduce and Large Scale Data Processing Systems",
                        "Citation Paper Abstract": "Abstract:In the last two decades, the continuous increase of computational power has produced an overwhelming flow of data which has called for a paradigm shift in the computing architecture and large scale data processing mechanisms. MapReduce is a simple and powerful programming model that enables easy development of scalable parallel applications to process vast amounts of data on large clusters of commodity machines. It isolates the application from the details of running a distributed program such as issues on data distribution, scheduling and fault tolerance. However, the original implementation of the MapReduce framework had some limitations that have been tackled by many research efforts in several followup works after its introduction. This article provides a comprehensive survey for a family of approaches and mechanisms of large scale data processing mechanisms that have been implemented based on the original idea of the MapReduce framework and are currently gaining a lot of momentum in both research and industrial communities. We also cover a set of introduced systems that have been implemented to provide declarative programming interfaces on top of the MapReduce framework. In addition, we review several large scale data processing systems that resemble some of the ideas of the MapReduce framework for different purposes and application scenarios. Finally, we discuss some of the future research directions for implementing the next generation of MapReduce-like solutions.",
                        "Citation Paper Authors": "Authors:Sherif Sakr, Anna Liu, Ayman G. Fayoumi"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1808.00197v1": {
            "Paper Title": "MaxMin Linear Initialization for Fuzzy C-Means",
            "Sentences": []
        },
        "http://arxiv.org/abs/1808.00024v1": {
            "Paper Title": "Improve3C: Data Cleaning on Consistency and Completeness with Currency",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.11634v1": {
            "Paper Title": "Interactive Summarization and Exploration of Top Aggregate Query Answers",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.10436v4": {
            "Paper Title": "Unsupervised String Transformation Learning for Entity Consolidation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.11104v1": {
            "Paper Title": "DataJoint: A Simpler Relational Data Model",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.11054v1": {
            "Paper Title": "MISS: Finding Optimal Sample Sizes for Approximate Analytics",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.10792v1": {
            "Paper Title": "NDBench: Benchmarking Microservices at Scale",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.10009v1": {
            "Paper Title": "General Context-Aware Data Matching and Merging Framework",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.09920v1": {
            "Paper Title": "Budget-aware Online Task Assignment in Spatial Crowdsourcing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.09899v1": {
            "Paper Title": "Validation and Inference of Schema-Level Workflow Data-Dependency\n  Annotations",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.09887v1": {
            "Paper Title": "Compiling Database Application Programs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.01256v2": {
            "Paper Title": "NegPSpan: efficient extraction of negative sequential patterns with\n  embedding constraints",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.04562v2": {
            "Paper Title": "Bias in OLAP Queries: Detection, Explanation, and Removal",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.09835v2": {
            "Paper Title": "Locality-Sensitive Hashing for Earthquake Detection: A Case Study of\n  Scaling Data-Driven Science",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.08888v1": {
            "Paper Title": "An Efficient System for Subgraph Discovery",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.08712v1": {
            "Paper Title": "Data Science with Vadalog: Bridging Machine Learning and Reasoning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.08709v1": {
            "Paper Title": "The Vadalog System: Datalog-based Reasoning for Knowledge Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.08461v1": {
            "Paper Title": "A Cache-based Optimizer for Querying Enhanced Knowledge Bases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.07691v1": {
            "Paper Title": "gSMat: A Scalable Sparse Matrix-based Join for SPARQL Query Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.07346v1": {
            "Paper Title": "Indexing Execution Patterns in Workflow Provenance Graphs through\n  Generalized Trie Structures",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.05614v2": {
            "Paper Title": "ANN-Benchmarks: A Benchmarking Tool for Approximate Nearest Neighbor\n  Algorithms",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.08804v1": {
            "Paper Title": "GPU-based Commonsense Paradigms Reasoning for Real-Time Query Answering\n  and Multimodal Analysis",
            "Sentences": [
                {
                    "Sentence ID": 31,
                    "Sentence": "which can support a wide range of rule sets including RDFS\nand OWL. In the latest version of Jena, some generic inference rules can be applied\nin combination with some RDFS or OWL inference. Kollia et. al. ",
                    "Citation Text": "I. Kollia, B. Glimm, and I. Horrocks, \\Sparql query answering over owl ontolo-\ngies,\" in Extended Semantic Web Conference . Springer, 2011, pp. 382{396.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1402.0576",
                        "Citation Paper Title": "Title:Optimizing SPARQL Query Answering over OWL Ontologies",
                        "Citation Paper Abstract": "Abstract:The SPARQL query language is currently being extended by the World Wide Web Consortium (W3C) with so-called entailment regimes. An entailment regime defines how queries are evaluated under more expressive semantics than SPARQLs standard simple entailment, which is based on subgraph matching. The queries are very expressive since variables can occur within complex concepts and can also bind to concept or role names. In this paper, we describe a sound and complete algorithm for the OWL Direct Semantics entailment regime. We further propose several novel optimizations such as strategies for determining a good query execution order, query rewriting techniques, and show how specialized OWL reasoning tasks and the concept and role hierarchy can be used to reduce the query execution time. For determining a good execution order, we propose a cost-based model, where the costs are based on information about the instances of concepts and roles that are extracted from a model abstraction built by an OWL reasoner. We present two ordering strategies: a static and a dynamic one. For the dynamic case, we improve the performance by exploiting an individual clustering approach that allows for computing the cost functions based on one individual sample from a cluster. We provide a prototypical implementation and evaluate the efficiency of the proposed optimizations. Our experimental study shows that the static ordering usually outperforms the dynamic one when accurate statistics are available. This changes, however, when the statistics are less accurate, e.g., due to nondeterministic reasoning decisions. For queries that go beyond conjunctive instance queries we observe an improvement of up to three orders of magnitude due to the proposed optimizations.",
                        "Citation Paper Authors": "Authors:Ilianna Kollia, Birte Glimm"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1803.01969v2": {
            "Paper Title": "Moment-Based Quantile Sketches for Efficient High Cardinality\n  Aggregation Queries",
            "Sentences": [
                {
                    "Sentence ID": 71,
                    "Sentence": ". We do not compare\nagainst fixed-universe quantile summaries such as the Q-Digest ",
                    "Citation Text": "Nisheeth Shrivastava, Chiranjeeb Buragohain, Divyakant Agrawal, and Subhash\nSuri. 2004. Medians and beyond: new aggregation techniques for sensor networks.\nInInternational conference on Embedded networked sensor systems . 239\u2013249.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:cs/0408039",
                        "Citation Paper Title": "Title:Medians and Beyond: New Aggregation Techniques for Sensor Networks",
                        "Citation Paper Abstract": "Abstract:  Wireless sensor networks offer the potential to span and monitor large geographical areas inexpensively. Sensors, however, have significant power constraint (battery life), making communication very expensive. Another important issue in the context of sensor-based information systems is that individual sensor readings are inherently unreliable. In order to address these two aspects, sensor database systems like TinyDB and Cougar enable in-network data aggregation to reduce the communication cost and improve reliability. The existing data aggregation techniques, however, are limited to relatively simple types of queries such as SUM, COUNT, AVG, and MIN/MAX. In this paper we propose a data aggregation scheme that significantly extends the class of queries that can be answered using sensor networks. These queries include (approximate) quantiles, such as the median, the most frequent data values, such as the consensus value, a histogram of the data distribution, as well as range queries. In our scheme, each sensor aggregates the data it has received from other sensors into a fixed (user specified) size message. We provide strict theoretical guarantees on the approximation quality of the queries in terms of the message size. We evaluate the performance of our aggregation scheme by simulation and demonstrate its accuracy, scalability and low resource utilization for highly variable input data sets.",
                        "Citation Paper Authors": "Authors:Nisheeth Shrivastava, Chiranjeeb Buragohain, Divyakant Agrawal, Subhash Suri"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1807.04035v1": {
            "Paper Title": "Modeling Data Lake Metadata with a Data Vault",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.04639v1": {
            "Paper Title": "Moving Objects Analytics: Survey on Future Location & Trajectory\n  Prediction Methods",
            "Sentences": [
                {
                    "Sentence ID": 72,
                    "Sentence": ", start ing versus  ending activity \npoints , (distinguishable) change in velocity vector ",
                    "Citation Text": "Patroumpas, K., Alevizos, E., Artikis, A., Vodas, M., Pelekis, N., &  Theodoridis, Y. (2017) \nOnline event recognition from moving vessel t rajectories. Geoinformatica , 21(2), 389-\n427.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1601.06041",
                        "Citation Paper Title": "Title:Online Event Recognition from Moving Vessel Trajectories",
                        "Citation Paper Abstract": "Abstract:We present a system for online monitoring of maritime activity over streaming positions from numerous vessels sailing at sea. It employs an online tracking module for detecting important changes in the evolving trajectory of each vessel across time, and thus can incrementally retain concise, yet reliable summaries of its recent movement. In addition, thanks to its complex event recognition module, this system can also offer instant notification to marine authorities regarding emergency situations, such as risk of collisions, suspicious moves in protected zones, or package picking at open sea. Not only did our extensive tests validate the performance, efficiency, and robustness of the system against scalable volumes of real-world and synthetically enlarged datasets, but its deployment against online feeds from vessels has also confirmed its capabilities for effective, real-time maritime surveillance.",
                        "Citation Paper Authors": "Authors:Kostas Patroumpas, Elias Alevizos, Alexander Artikis, Marios Vodas, Nikos Pelekis, Yannis Theodoridis"
                    }
                },
                {
                    "Sentence ID": 9,
                    "Sentence": "eliminate the number of potentially occurring conflicts) . In addition, the \ncapability of each C D&R concept regarding the traffic density is mainly based on the \nnetwork connectivity and vulnerability ; e.g., scale -free networks (SFNs) ",
                    "Citation Text": "Barabasi , A. & Albert, R. (1999) Emergence of scaling in random networks. Science , 286, \n509-512.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:cond-mat/9910332",
                        "Citation Paper Title": "Title:Emergence of scaling in random networks",
                        "Citation Paper Abstract": "Abstract:  Systems as diverse as genetic networks or the world wide web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature is found to be a consequence of the two generic mechanisms that networks expand continuously by the addition of new vertices, and new vertices attach preferentially to already well connected sites. A model based on these two ingredients reproduces the observed stationary scale-free distributions, indicating that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.",
                        "Citation Paper Authors": "Authors:Albert-Laszlo Barabasi, Reka Albert (Univ. of Notre Dame)"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1703.05547v4": {
            "Paper Title": "Compact Neighborhood Index for Subgraph Queries in Massive Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.04595v2": {
            "Paper Title": "Efficient Destination Prediction Based on Route Choices with Transition\n  Matrix Optimization",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.02957v1": {
            "Paper Title": "Scaling-Up Reasoning and Advanced Analytics on BigData",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.02262v1": {
            "Paper Title": "Temporal graph-based clustering for historical record linkage",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.06632v2": {
            "Paper Title": "A Guided FP-growth algorithm for multitude-targeted mining of big data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.01706v1": {
            "Paper Title": "Mining Periodic Patterns with a MDL Criterion",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.11517v3": {
            "Paper Title": "You Say 'What', I Hear 'Where' and 'Why': (Mis-)Interpreting SQL to\n  Derive Fine-Grained Provenance",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.10078v2": {
            "Paper Title": "A General Framework for Anytime Approximation in Probabilistic Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.01190v2": {
            "Paper Title": "FLASH: Randomized Algorithms Accelerated over CPU-GPU for Ultra-High\n  Dimensional Similarity Search",
            "Sentences": [
                {
                    "Sentence ID": 35,
                    "Sentence": ". This\nis a friendship graph with 65 million nodes. Every node is\nrepresented as 65 million dimensional sparse binary vector\nindicatingadirectedgetoothernodes.Theaveragenumber\nofnon-zerosisaround27.Weusethisdatasetprimarilytobenchmark computations of heavy entries of large matrix\nmultiplication outputs as shown in ",
                    "Citation Text": "A. Sharma, C. Seshadhri, and A. Goel. When hashes met wedges: A distributed\nalgorithm forfinding highsimilarity vectors. In Proceedings ofthe 26thInterna-\ntional Conference on World Wide Web , pages 431\u2013440. International World Wide\nWeb Conferences Steering Committee, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1703.01054",
                        "Citation Paper Title": "Title:When Hashes Met Wedges: A Distributed Algorithm for Finding High Similarity Vectors",
                        "Citation Paper Abstract": "Abstract:Finding similar user pairs is a fundamental task in social networks, with numerous applications in ranking and personalization tasks such as link prediction and tie strength detection. A common manifestation of user similarity is based upon network structure: each user is represented by a vector that represents the user's network connections, where pairwise cosine similarity among these vectors defines user similarity. The predominant task for user similarity applications is to discover all similar pairs that have a pairwise cosine similarity value larger than a given threshold $\\tau$. In contrast to previous work where $\\tau$ is assumed to be quite close to 1, we focus on recommendation applications where $\\tau$ is small, but still meaningful. The all pairs cosine similarity problem is computationally challenging on networks with billions of edges, and especially so for settings with small $\\tau$. To the best of our knowledge, there is no practical solution for computing all user pairs with, say $\\tau = 0.2$ on large social networks, even using the power of distributed algorithms.\nOur work directly addresses this challenge by introducing a new algorithm --- WHIMP --- that solves this problem efficiently in the MapReduce model. The key insight in WHIMP is to combine the \"wedge-sampling\" approach of Cohen-Lewis for approximate matrix multiplication with the SimHash random projection techniques of Charikar. We provide a theoretical analysis of WHIMP, proving that it has near optimal communication costs while maintaining computation cost comparable with the state of the art. We also empirically demonstrate WHIMP's scalability by computing all highly similar pairs on four massive data sets, and show that it accurately finds high similarity pairs. In particular, we note that WHIMP successfully processes the entire Twitter network, which has tens of billions of edges.",
                        "Citation Paper Authors": "Authors:Aneesh Sharma, C. Seshadhri, Ashish Goel"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1807.00971v1": {
            "Paper Title": "Analytics for the Internet of Things: A Survey",
            "Sentences": [
                {
                    "Sentence ID": 150,
                    "Sentence": "inspired data structure that summarises\nthis context and identifies set membership in a probabilistic way so resources can be discovered\nand grouped. Perera et al. ",
                    "Citation Text": "Charith Perera, Arkady Zaslavsky, Peter Christen, Michael Compton, and Dimitrios Georgakopoulos. 2013. Context-\naware Sensor Search, Selection And Ranking Model For Internet Of Things Middleware. In Proceedings of IEEE\nInternational Conference on Mobile Data Management . https://doi.org/10.1109/MDM.2013.46",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1303.2447",
                        "Citation Paper Title": "Title:Context-aware Sensor Search, Selection and Ranking Model for Internet of Things Middleware",
                        "Citation Paper Abstract": "Abstract:As we are moving towards the Internet of Things (IoT), the number of sensors deployed around the world is growing at a rapid pace. Market research has shown a significant growth of sensor deployments over the past decade and has predicted a substantial acceleration of the growth rate in the future. It is also evident that the increasing number of IoT middleware solutions are developed in both research and commercial environments. However, sensor search and selection remain a critical requirement and a challenge. In this paper, we present CASSARAM, a context-aware sensor search, selection, and ranking model for Internet of Things to address the research challenges of selecting sensors when large numbers of sensors with overlapping and sometimes redundant functionality are available. CASSARAM proposes the search and selection of sensors based on user priorities. CASSARAM considers a broad range of characteristics of sensors for search such as reliability, accuracy, battery life just to name a few. Our approach utilises both semantic querying and quantitative reasoning techniques. User priority based weighted Euclidean distance comparison in multidimensional space technique is used to index and rank sensors. Our objectives are to highlight the importance of sensor search in IoT paradigm, identify important characteristics of both sensors and data acquisition processes which help to select sensors, understand how semantic and statistical reasoning can be combined together to address this problem in an efficient manner. We developed a tool called CASSARA to evaluate the proposed model in terms of resource consumption and response time.",
                        "Citation Paper Authors": "Authors:Charith Perera, Arkady Zaslavsky, Peter Christen, Michael Compton, Dimitrios Georgakopoulos"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1807.00878v1": {
            "Paper Title": "Distributed Statistical Estimation of Matrix Products with Applications",
            "Sentences": [
                {
                    "Sentence ID": 20,
                    "Sentence": ",D/i.sc/s.sc/t.sc/r.sc/i.sc/b.sc/u.sc/t.sc/e.sc/d.scM/a.sc/t.sc/r.sc/i.sc/x.scM/u.sc/l.sc/t.sc/i.sc/p.sc/l.sc/i.sc/c.sc/a.sc/t.sc/i.sc/o.sc/n.sc). Sup-\npose Alice holds a matrix A\u2208Rn\u00d7n, and Bob holds a matrix B\u2208\nRn\u00d7n. There is an algorithm for Alice and Bob to compute CAand\nCBsuch that with probability 1\u22121/n10,CA+CB=AB. The algo-\nrithmuses \u02dcO(n/radicalbig\n/bardblAB/bardbl0)bitsofcommunicationand 2rounds.\nL/e.sc/m.sc/m.sc/a.sc 2.6 ( ",
                    "Citation Text": "H. Jowhari, M. Saglam, and G. Tardos. Tight bounds for lp samplers, \ufb01nding\nduplicates instreams,and related problems. In PODS,pages49\u201358,2011.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1012.4889",
                        "Citation Paper Title": "Title:Tight Bounds for Lp Samplers, Finding Duplicates in Streams, and Related Problems",
                        "Citation Paper Abstract": "Abstract:In this paper, we present near-optimal space bounds for Lp-samplers. Given a stream of updates (additions and subtraction) to the coordinates of an underlying vector x \\in R^n, a perfect Lp sampler outputs the i-th coordinate with probability |x_i|^p/||x||_p^p. In SODA 2010, Monemizadeh and Woodruff showed polylog space upper bounds for approximate Lp-samplers and demonstrated various applications of them. Very recently, Andoni, Krauthgamer and Onak improved the upper bounds and gave a O(\\epsilon^{-p} log^3 n) space \\epsilon relative error and constant failure rate Lp-sampler for p \\in [1,2]. In this work, we give another such algorithm requiring only O(\\epsilon^{-p} log^2 n) space for p \\in (1,2). For p \\in (0,1), our space bound is O(\\epsilon^{-1} log^2 n), while for the $p=1$ case we have an O(log(1/\\epsilon)\\epsilon^{-1} log^2 n) space algorithm. We also give a O(log^2 n) bits zero relative error L0-sampler, improving the O(log^3 n) bits algorithm due to Frahling, Indyk and Sohler.\nAs an application of our samplers, we give better upper bounds for the problem of finding duplicates in data streams. In case the length of the stream is longer than the alphabet size, L1 sampling gives us an O(log^2 n) space algorithm, thus improving the previous O(log^3 n) bound due to Gopalan and Radhakrishnan.\nIn the second part of our work, we prove an Omega(log^2 n) lower bound for sampling from 0, \\pm 1 vectors (in this special case, the parameter p is not relevant for Lp sampling). This matches the space of our sampling algorithms for constant \\epsilon > 0. We also prove tight space lower bounds for the finding duplicates and heavy hitters problems. We obtain these lower bounds using reductions from the communication complexity problem augmented indexing.",
                        "Citation Paper Authors": "Authors:Hossein Jowhari, Mert Sa\u011flam, G\u00e1bor Tardos"
                    }
                },
                {
                    "Sentence ID": 5,
                    "Sentence": ". In contrast we show that s ur-\nprisingly, at least to the authors, \u02dcO(n/\u03f5)bits of communication ispossiblewithonly2rounds.In ",
                    "Citation Text": "R. R. Amossen, A. Campagna, and R. Pagh. Better size estim ation for sparse\nmatrixproducts. Algorithmica ,69(3):741\u2013757, 2014.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1006.4173",
                        "Citation Paper Title": "Title:Better size estimation for sparse matrix products",
                        "Citation Paper Abstract": "Abstract:We consider the problem of doing fast and reliable estimation of the number of non-zero entries in a sparse boolean matrix product. This problem has applications in databases and computer algebra. Let n denote the total number of non-zero entries in the input matrices. We show how to compute a 1 +- epsilon approximation (with small probability of error) in expected time O(n) for any epsilon > 4/\\sqrt[4]{z}. The previously best estimation algorithm, due to Cohen (JCSS 1997), uses time O(n/epsilon^2). We also present a variant using O(sort(n)) I/Os in expectation in the cache-oblivious model. In contrast to these results, the currently best algorithms for computing a sparse boolean matrix product use time omega(n^{4/3}) (resp. omega(n^{4/3}/B) I/Os), even if the result matrix has only z=O(n) nonzero entries. Our algorithm combines the size estimation technique of Bar-Yossef et al. (RANDOM 2002) with a particular class of pairwise independent hash functions that allows the sketch of a set of the form A x C to be computed in expected time O(|A|+|C|) and O(sort(|A|+|C|)) I/Os. We then describe how sampling can be used to maintain (independent) sketches of matrices that allow estimation to be performed in time o(n) if z is sufficiently large. This gives a simpler alternative to the sketching technique of Ganguly et al. (PODS 2005), and matches a space lower bound shown in that paper. Finally, we present experiments on real-world data sets that show the accuracy of both our methods to be significantly better than the worst-case analysis predicts.",
                        "Citation Paper Authors": "Authors:Rasmus Resen Amossen, Andrea Campagna, Rasmus Pagh"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1807.00602v1": {
            "Paper Title": "Semantic Query Language for Temporal Genealogical Trees",
            "Sentences": []
        },
        "http://arxiv.org/abs/1807.00035v1": {
            "Paper Title": "An Efficient Data Warehouse for Crop Yield Prediction",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.09930v3": {
            "Paper Title": "Worst-Case Optimal Join Algorithms: Techniques, Results, and Open\n  Problems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.09339v1": {
            "Paper Title": "SAQL: A Stream-based Query System for Real-Time Abnormal System Behavior\n  Detection",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.09256v1": {
            "Paper Title": "Track Xplorer: A System for Visual Analysis of Sensor-based Motor\n  Activity Predictions",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.08384v1": {
            "Paper Title": "Novel Selectivity Estimation Strategy for Modern DBMS",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.07728v1": {
            "Paper Title": "Parallelization of XPath Queries using Modern XQuery Processors",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.07691v1": {
            "Paper Title": "Searching of interesting itemsets for negative association rules",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.07598v1": {
            "Paper Title": "A Faster External Memory Priority Queue with DecreaseKeys",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.07524v1": {
            "Paper Title": "Developing a Temporal Bibliographic Data Set for Entity Resolution",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.07344v1": {
            "Paper Title": "Reducing Property Graph Queries to Relational Algebra for Incremental\n  View Maintenance",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.07084v1": {
            "Paper Title": "Itemsets of interest for negative association rules",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.06978v1": {
            "Paper Title": "A Web of Blocks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.06205v1": {
            "Paper Title": "TrQuery: An Embedding-based Framework for Recommanding SPARQL Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.07480v2": {
            "Paper Title": "AC/DC: In-Database Learning Thunderstruck",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.04004v1": {
            "Paper Title": "PubMed Labs: An experimental platform for improving biomedical\n  literature search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.09999v2": {
            "Paper Title": "Symbolic Automata with Memory: a Computational Model for Complex Event\n  Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.04545v3": {
            "Paper Title": "Efficient Computation of Multiple Density-Based Clustering Hierarchies",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.02290v2": {
            "Paper Title": "AIQL: Enabling Efficient Attack Investigation from System Monitoring\n  Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.02227v1": {
            "Paper Title": "Curator: Provenance Management for Modern Distributed Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.03168v1": {
            "Paper Title": "Data-driven Analytics for Business Architectures: Proposed Use of Graph\n  Theory",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.04301v2": {
            "Paper Title": "Deep Learning for IoT Big Data and Streaming Analytics: A Survey",
            "Sentences": [
                {
                    "Sentence ID": 201,
                    "Sentence": "reports about 5:6seconds for returning a prediction\nresponse, while consuming 83% of the CPU and 67MB of\nmemory. Howard et al. ",
                    "Citation Text": "A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang,\nT. Weyand, M. Andreetto, and H. Adam, \u201cMobilenets: Ef\ufb01cient convo-\nlutional neural networks for mobile vision applications,\u201d arXiv preprint\narXiv:1704.04861v1 [cs.CV] , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1704.04861",
                        "Citation Paper Title": "Title:MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications",
                        "Citation Paper Abstract": "Abstract:We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.",
                        "Citation Paper Authors": "Authors:Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam"
                    }
                },
                {
                    "Sentence ID": 78,
                    "Sentence": "Tensor\ufb02ow C++Python, Java,\nC, C++, Go\u000fFast on LSTM training\n\u000fSupport to visualize\nnetworks\u000fSlower training\ncompared to other\nPython-based frameworks ",
                    "Citation Text": "A. Luckow, M. Cook, N. Ashcraft, E. Weill, E. Djerekarov, and\nB. V orster, \u201cDeep learning in the automotive industry: Applications and\ntools,\u201d in Big Data (Big Data), 2016 IEEE International Conference\non. IEEE, 2016, pp. 3759\u20133768.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1705.00346",
                        "Citation Paper Title": "Title:Deep Learning in the Automotive Industry: Applications and Tools",
                        "Citation Paper Abstract": "Abstract:Deep Learning refers to a set of machine learning techniques that utilize neural networks with many hidden layers for tasks, such as image classification, speech recognition, language understanding. Deep learning has been proven to be very effective in these domains and is pervasively used by many Internet services. In this paper, we describe different automotive uses cases for deep learning in particular in the domain of computer vision. We surveys the current state-of-the-art in libraries, tools and infrastructures (e.\\,g.\\ GPUs and clouds) for implementing, training and deploying deep neural networks. We particularly focus on convolutional neural networks and computer vision use cases, such as the visual inspection process in manufacturing plants and the analysis of social media data. To train neural networks, curated and labeled datasets are essential. In particular, both the availability and scope of such datasets is typically very limited. A main contribution of this paper is the creation of an automotive dataset, that allows us to learn and automatically recognize different vehicle properties. We describe an end-to-end deep learning application utilizing a mobile app for data collection and process support, and an Amazon-based cloud backend for storage and training. For training we evaluate the use of cloud and on-premises infrastructures (including multiple GPUs) in conjunction with different neural network architectures and frameworks. We assess both the training times as well as the accuracy of the classifier. Finally, we demonstrate the effectiveness of the trained classifier in a real world setting during manufacturing process.",
                        "Citation Paper Authors": "Authors:Andre Luckow, Matthew Cook, Nathan Ashcraft, Edwin Weill, Emil Djerekarov, Bennie Vorster"
                    }
                },
                {
                    "Sentence ID": 182,
                    "Sentence": ". Luckily,\nit has been recently shown that many parameters that are\nstored in DNNs may be redundant ",
                    "Citation Text": "M. Denil, B. Shakibi, L. Dinh, N. de Freitas et al. , \u201cPredicting\nparameters in deep learning,\u201d in Advances in Neural Information\nProcessing Systems , 2013, pp. 2148\u20132156.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1306.0543",
                        "Citation Paper Title": "Title:Predicting Parameters in Deep Learning",
                        "Citation Paper Abstract": "Abstract:We demonstrate that there is significant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95% of the weights of a network without any drop in accuracy.",
                        "Citation Paper Authors": "Authors:Misha Denil, Babak Shakibi, Laurent Dinh, Marc'Aurelio Ranzato, Nando de Freitas"
                    }
                },
                {
                    "Sentence ID": 142,
                    "Sentence": ". Moreover, DL\ncan be used as a personalized recommendation module ",
                    "Citation Text": "H. Wang, N. Wang, and D.-Y . Yeung, \u201cCollaborative deep learning\nfor recommender systems,\u201d in Proceedings of the 21th ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining .\nACM, 2015, pp. 1235\u20131244.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1409.2944",
                        "Citation Paper Title": "Title:Collaborative Deep Learning for Recommender Systems",
                        "Citation Paper Abstract": "Abstract:Collaborative filtering (CF) is a successful approach commonly used by many recommender systems. Conventional CF-based methods use the ratings given to items by users as the sole source of information for learning to make recommendation. However, the ratings are often very sparse in many applications, causing CF-based methods to degrade significantly in their recommendation performance. To address this sparsity problem, auxiliary information such as item content information may be utilized. Collaborative topic regression (CTR) is an appealing recent method taking this approach which tightly couples the two components that learn from two different sources of information. Nevertheless, the latent representation learned by CTR may not be very effective when the auxiliary information is very sparse. To address this problem, we generalize recent advances in deep learning from i.i.d. input to non-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesian model called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative filtering for the ratings (feedback) matrix. Extensive experiments on three real-world datasets from different domains show that CDL can significantly advance the state of the art.",
                        "Citation Paper Authors": "Authors:Hao Wang, Naiyan Wang, Dit-Yan Yeung"
                    }
                },
                {
                    "Sentence ID": 69,
                    "Sentence": ".\nTensor\ufb02ow : Initially developed for Google Brain project,\nTensor\ufb02ow is an open source library for machine learning\nsystems using various kinds of DNNs ",
                    "Citation Text": "M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S.\nCorrado, A. Davis, J. Dean, M. Devin et al. , \u201cTensor\ufb02ow: Large-scale\nmachine learning on heterogeneous distributed systems,\u201d arXiv preprint\narXiv:1603.04467v2 [cs.DC] , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1603.04467",
                        "Citation Paper Title": "Title:TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
                        "Citation Paper Abstract": "Abstract:TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at this http URL.",
                        "Citation Paper Authors": "Authors:Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, Xiaoqiang Zheng"
                    }
                },
                {
                    "Sentence ID": 50,
                    "Sentence": "to support unsupervised learning. Later, they were extended to\nwork in semi-supervised settings ",
                    "Citation Text": "A. Rasmus, M. Berglund, M. Honkala, H. Valpola, and T. Raiko,\n\u201cSemi-supervised learning with ladder networks,\u201d in Advances in\nNeural Information Processing Systems , 2015, pp. 3546\u20133554.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1507.02672",
                        "Citation Paper Title": "Title:Semi-Supervised Learning with Ladder Networks",
                        "Citation Paper Abstract": "Abstract:We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on the Ladder network proposed by Valpola (2015), which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification, in addition to permutation-invariant MNIST classification with all labels.",
                        "Citation Paper Authors": "Authors:Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, Tapani Raiko"
                    }
                },
                {
                    "Sentence ID": 44,
                    "Sentence": ". Moreover, this model has\nbeen used for semi-supervised learning ",
                    "Citation Text": "D. P. Kingma, S. Mohamed, D. J. Rezende, and M. Welling, \u201cSemi-\nsupervised learning with deep generative models,\u201d in Advances in\nNeural Information Processing Systems , 2014, pp. 3581\u20133589.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1406.5298",
                        "Citation Paper Title": "Title:Semi-Supervised Learning with Deep Generative Models",
                        "Citation Paper Abstract": "Abstract:The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.",
                        "Citation Paper Authors": "Authors:Diederik P. Kingma, Danilo J. Rezende, Shakir Mohamed, Max Welling"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1704.01355v2": {
            "Paper Title": "Decentralizing MVCC by Leveraging Visibility",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.01168v1": {
            "Paper Title": "Secure and Efficient Skyline Queries on Encrypted Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.01270v1": {
            "Paper Title": "Alchemist: An Apache Spark <=> MPI Interface",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.00637v1": {
            "Paper Title": "Quality-Assured Synchronized Task Assignment in Crowdsourcing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.00571v1": {
            "Paper Title": "Efficient Interactive Search for Geo-tagged Multimedia Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.11531v2": {
            "Paper Title": "SemTK: An Ontology-first, Open Source Semantic Toolkit for Managing and\n  Querying Knowledge Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1806.00227v1": {
            "Paper Title": "SaGe: Preemptive Query Execution for High Data Availability on the Web",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.12503v1": {
            "Paper Title": "Practical Study of Deterministic Regular Expressions from Large-scale\n  XML and Schema Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.12320v1": {
            "Paper Title": "QuickIM: Efficient, Accurate and Robust Influence Maximization Algorithm\n  on Billion-Scale Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.07138v4": {
            "Paper Title": "Historical collaborative geocoding",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.11900v1": {
            "Paper Title": "Q-Graph: Preserving Query Locality in Multi-Query Graph Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.11780v1": {
            "Paper Title": "Detecting Data Leakage from Databases on Android Apps with Concept Drift",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.08435v2": {
            "Paper Title": "Analyzing Query Performance and Attributing Blame for Contentions in a\n  Cluster Computing Framework",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.11723v1": {
            "Paper Title": "Building your Cross-Platform Application with RHEEM",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.11450v1": {
            "Paper Title": "Model-based Pricing for Machine Learning in a Data Marketplace",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.02229v3": {
            "Paper Title": "Axiomatic Foundations and Algorithms for Deciding Semantic Equivalences\n  of SQL Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.09149v1": {
            "Paper Title": "Agilit{\u00e9} de d{\u00e9}veloppement des SI informatis{\u00e9}s et outils MDE :\n  d{\u00e9}marche p{\u00e9}dagogique dans un cours de conception de syst{\u00e8}mes\n  d'information informatis{\u00e9}s",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.08037v3": {
            "Paper Title": "Algorithms and Analysis for the SPARQL Constructs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.09008v2": {
            "Paper Title": "Recurrent Meta-Structure for Robust Similarity Measure in Heterogeneous\n  Information Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.08650v1": {
            "Paper Title": "Cache-based Multi-query Optimization for Data-intensive Scalable\n  Computing Frameworks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.08520v1": {
            "Paper Title": "MonetDBLite: An Embedded Analytical Database",
            "Sentences": [
                {
                    "Sentence ID": 3,
                    "Sentence": "(Version 0.22.0) is a Python library for perform-\ning common database operations.\n\u2022Julia ",
                    "Citation Text": "Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and Alan Edelman. 2012. Julia: A\nFast Dynamic Language for Technical Computing. CoRR abs/1209.5145 (2012).\narXiv:1209.5145 http://arxiv.org/abs/1209.5145",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1209.5145",
                        "Citation Paper Title": "Title:Julia: A Fast Dynamic Language for Technical Computing",
                        "Citation Paper Abstract": "Abstract:Dynamic languages have become popular for scientific computing. They are generally considered highly productive, but lacking in performance. This paper presents Julia, a new dynamic language for technical computing, designed for performance from the beginning by adapting and extending modern programming language techniques. A design based on generic functions and a rich type system simultaneously enables an expressive programming model and successful type inference, leading to good performance for a wide range of programs. This makes it possible for much of the Julia library to be written in Julia itself, while also incorporating best-of-breed C and Fortran libraries.",
                        "Citation Paper Authors": "Authors:Jeff Bezanson, Stefan Karpinski, Viral B. Shah, Alan Edelman"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1805.09157v1": {
            "Paper Title": "A New Finitely Controllable Class of Tuple Generating Dependencies: The\n  Triangularly-Guarded Class",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.07599v1": {
            "Paper Title": "A hybrid index model for efficient spatio-temporal search in HBase",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.07505v1": {
            "Paper Title": "Free-rider Episode Screening via Dual Partition Model",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.08169v1": {
            "Paper Title": "Cancer Research UK Drug Discovery Process Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.10311v2": {
            "Paper Title": "How Developers Iterate on Machine Learning Workflows -- A Survey of the\n  Applied Machine Learning Literature",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.06757v1": {
            "Paper Title": "Matching Consecutive Subpatterns Over Streaming Time Series",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.05874v1": {
            "Paper Title": "Approximate Distributed Joins in Apache Spark",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.03644v2": {
            "Paper Title": "Multidimensional Range Queries on Modern Hardware",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.04642v1": {
            "Paper Title": "HOC-Tree: A Novel Index for efficient Spatio-temporal Range Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.04265v1": {
            "Paper Title": "Scripting Relational Database Engine Using Transducer",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.03677v1": {
            "Paper Title": "The Dataset Nutrition Label: A Framework To Drive Higher Data Quality\n  Standards",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.03320v1": {
            "Paper Title": "Mining Top-k Sequential Patterns in Database Graphs:A New Challenging\n  Problem and a Sampling-based Approach",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.03141v1": {
            "Paper Title": "Parallel Computation of PDFs on Big Spatial Data Using Spark",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.05918v3": {
            "Paper Title": "Adaptive Sampling for Rapidly Matching Histograms",
            "Sentences": [
                {
                    "Sentence ID": 61,
                    "Sentence": "develops techniques to bound the probability of a\ngiven set of items being part of the top-k. Pietracaprina et al. ",
                    "Citation Text": "A. Pietracaprina, M. Riondato, E. Upfal, and F. Vandin.\nMining top-k frequent itemsets through progressive\nsampling. Data Mining and Knowledge Discovery ,\n21(2):310\u2013326, 2010.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1006.5235",
                        "Citation Paper Title": "Title:Mining Top-K Frequent Itemsets Through Progressive Sampling",
                        "Citation Paper Abstract": "Abstract:We study the use of sampling for efficiently mining the top-K frequent itemsets of cardinality at most w. To this purpose, we define an approximation to the top-K frequent itemsets to be a family of itemsets which includes (resp., excludes) all very frequent (resp., very infrequent) itemsets, together with an estimate of these itemsets' frequencies with a bounded error. Our first result is an upper bound on the sample size which guarantees that the top-K frequent itemsets mined from a random sample of that size approximate the actual top-K frequent itemsets, with probability larger than a specified value. We show that the upper bound is asymptotically tight when w is constant. Our main algorithmic contribution is a progressive sampling approach, combined with suitable stopping conditions, which on appropriate inputs is able to extract approximate top-K frequent itemsets from samples whose sizes are smaller than the general upper bound. In order to test the stopping conditions, this approach maintains the frequency of all itemsets encountered, which is practical only for small w. However, we show how this problem can be mitigated by using a variation of Bloom filters. A number of experiments conducted on both synthetic and real bench- mark datasets show that using samples substantially smaller than the original dataset (i.e., of size defined by the upper bound or reached through the progressive sampling approach) enable to approximate the actual top-K frequent itemsets with accuracy much higher than what analytically proved.",
                        "Citation Paper Authors": "Authors:Andrea Pietracaprina, Matteo Riondato, Eli Upfal, Fabio Vandin"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1805.02622v1": {
            "Paper Title": "Provenance for Interactive Visualizations",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.01083v1": {
            "Paper Title": "Scalable Semantic Querying of Text",
            "Sentences": []
        },
        "http://arxiv.org/abs/1805.00680v1": {
            "Paper Title": "BUDAMAF: Data Management in Cloud Federations",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.01208v3": {
            "Paper Title": "The Case for Learned Index Structures",
            "Sentences": [
                {
                    "Sentence ID": 62,
                    "Sentence": ". With the growth of neural networks, this has become more common and demonstrated\nincreased usefulness ",
                    "Citation Text": "N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously large\nneural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:1701.06538 , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1701.06538",
                        "Citation Paper Title": "Title:Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
                        "Citation Paper Abstract": "Abstract:The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.",
                        "Citation Paper Authors": "Authors:Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1804.11052v1": {
            "Paper Title": "Relational to RDF Data Exchange in Presence of a Shape Expression Schema",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.08588v2": {
            "Paper Title": "Efficient Adaptive Detection of Complex Event Patterns",
            "Sentences": [
                {
                    "Sentence ID": 18,
                    "Sentence": ". Thiswasfollowedbytheemergenceofabroadvarietyofsolutions\nfor detecting occurrences of situations of interest, as opposed to generic data,\nincluding frameworks such as SASE/SASE+ [49, 7, 51], CEDR ",
                    "Citation Text": "R. S. Barga, J. Goldstein, M. H. Ali, and M. Hong. Consistent streaming\nthrough time: A vision for event stream processing. In CIDR, pages 363\u2013\n374, 2007.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:cs/0612115",
                        "Citation Paper Title": "Title:Consistent Streaming Through Time: A Vision for Event Stream Processing",
                        "Citation Paper Abstract": "Abstract:  Event processing will play an increasingly important role in constructing enterprise applications that can immediately react to business critical events. Various technologies have been proposed in recent years, such as event processing, data streams and asynchronous messaging (e.g. pub/sub). We believe these technologies share a common processing model and differ only in target workload, including query language features and consistency requirements. We argue that integrating these technologies is the next step in a natural progression. In this paper, we present an overview and discuss the foundations of CEDR, an event streaming system that embraces a temporal stream model to unify and further enrich query language features, handle imperfections in event delivery and define correctness guarantees. We describe specific contributions made so far and outline next steps in developing the CEDR system.",
                        "Citation Paper Authors": "Authors:Roger S. Barga, Jonathan Goldstein, Mohamed Ali, Mingsheng Hong"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1801.09413v2": {
            "Paper Title": "Join Query Optimization Techniques for Complex Event Processing\n  Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.10711v1": {
            "Paper Title": "Modified Apriori Graph Algorithm for Frequent Pattern Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.10565v1": {
            "Paper Title": "Certified Graph View Maintenance with Regular Datalog",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.09996v2": {
            "Paper Title": "Link and code: Fast indexing with graphs and compact regression codes",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.09997v1": {
            "Paper Title": "PANDA: Facilitating Usable AI Development",
            "Sentences": [
                {
                    "Sentence ID": 21,
                    "Sentence": ", which\nprovides training and deployment services for analytics tasks. CohAna ",
                    "Citation Text": "D. Jiang, Q. Cai, G. Chen, H. Jagadish, B. C. Ooi, K.-L. Tan, and A. K. Tung. Cohort query\nprocessing. PVLDB , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1601.00182",
                        "Citation Paper Title": "Title:Cohort Query Processing",
                        "Citation Paper Abstract": "Abstract:Modern Internet applications often produce a large volume of user activity records. Data analysts are interested in cohort analysis, or finding unusual user behavioral trends, in these large tables of activity records. In a traditional database system, cohort analysis queries are both painful to specify and expensive to evaluate. We propose to extend database systems to support cohort analysis. We do so by extending SQL with three new operators. We devise three different evaluation schemes for cohort query processing. Two of them adopt a non-intrusive approach. The third approach employs a columnar based evaluation scheme with optimizations specifically designed for cohort query processing. Our experimental results confirm the performance benefits of our proposed columnar database system, compared against the two non-intrusive approaches that implement cohort queries on top of regular relational databases.",
                        "Citation Paper Authors": "Authors:Dawei Jiang, Qingchao Cai, Gang Chen, H. V. Jagadish, Beng Chin Ooi, Kian-Lee Tan, Anthony K. H. Tung"
                    }
                },
                {
                    "Sentence ID": 48,
                    "Sentence": "is a deep learning platform initiated by us, which focuses on memory\nand speed ef\ufb01ciency optimization. On top of SINGA, we have a platform called Ra\ufb01ki ",
                    "Citation Text": "W. Wang, S. Wang, J. Gao, M. Zhang, G. Chen, T. K. Ng, and B. C. Ooi. Ra\ufb01ki: Machine\nlearning as an analytics service system. arXiv preprint arXiv:1804.06087 , 2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1804.06087",
                        "Citation Paper Title": "Title:Rafiki: Machine Learning as an Analytics Service System",
                        "Citation Paper Abstract": "Abstract:Big data analytics is gaining massive momentum in the last few years. Applying machine learning models to big data has become an implicit requirement or an expectation for most analysis tasks, especially on high-stakes applications.Typical applications include sentiment analysis against reviews for analyzing on-line products, image classification in food logging applications for monitoring user's daily intake and stock movement prediction. Extending traditional database systems to support the above analysis is intriguing but challenging. First, it is almost impossible to implement all machine learning models in the database engines. Second, expertise knowledge is required to optimize the training and inference procedures in terms of efficiency and effectiveness, which imposes heavy burden on the system users. In this paper, we develop and present a system, called Rafiki, to provide the training and inference service of machine learning models, and facilitate complex analytics on top of cloud platforms. Rafiki provides distributed hyper-parameter tuning for the training service, and online ensemble modeling for the inference service which trades off between latency and accuracy. Experimental results confirm the efficiency, effectiveness, scalability and usability of Rafiki.",
                        "Citation Paper Authors": "Authors:Wei Wang, Sheng Wang, Jinyang Gao, Meihui Zhang, Gang Chen, Teck Khim Ng, Beng Chin Ooi"
                    }
                },
                {
                    "Sentence ID": 36,
                    "Sentence": ". The Tensor\nTrain line of work is an example of such kind of model reduction effort ",
                    "Citation Text": "A. Novikov, D. Podoprikhin, A. Osokin, and D. Vetrov. Tensorizing Neural Networks. In NIPS ,\n2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1509.06569",
                        "Citation Paper Title": "Title:Tensorizing Neural Networks",
                        "Citation Paper Abstract": "Abstract:Deep neural networks currently demonstrate state-of-the-art performance in several domains. At the same time, models of this class are very demanding in terms of computational resources. In particular, a large amount of memory is required by commonly used fully-connected layers, making it hard to use the models on low-end devices and stopping the further increase of the model size. In this paper we convert the dense weight matrices of the fully-connected layers to the Tensor Train format such that the number of parameters is reduced by a huge factor and at the same time the expressive power of the layer is preserved. In particular, for the Very Deep VGG networks we report the compression factor of the dense weight matrix of a fully-connected layer up to 200000 times leading to the compression factor of the whole network up to 7 times.",
                        "Citation Paper Authors": "Authors:Alexander Novikov, Dmitry Podoprikhin, Anton Osokin, Dmitry Vetrov"
                    }
                },
                {
                    "Sentence ID": 7,
                    "Sentence": "are\ndesigned to optimize AI and data analytic operations. Model compression that reduces the memory\nand computation cost for deploying models on small devices is a hot research topic ",
                    "Citation Text": "Y . Cheng, D. Wang, P. Zhou, and T. Zhang. A survey of model compression and acceleration\nfor deep neural networks. arXiv preprint arXiv:1710.09282 , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1710.09282",
                        "Citation Paper Title": "Title:A Survey of Model Compression and Acceleration for Deep Neural Networks",
                        "Citation Paper Abstract": "Abstract:Deep neural networks (DNNs) have recently achieved great success in many visual recognition tasks. However, existing deep neural network models are computationally expensive and memory intensive, hindering their deployment in devices with low memory resources or in applications with strict latency requirements. Therefore, a natural thought is to perform model compression and acceleration in deep networks without significantly decreasing the model performance. During the past five years, tremendous progress has been made in this area. In this paper, we review the recent techniques for compacting and accelerating DNN models. In general, these techniques are divided into four categories: parameter pruning and quantization, low-rank factorization, transferred/compact convolutional filters, and knowledge distillation. Methods of parameter pruning and quantization are described first, after that the other techniques are introduced. For each category, we also provide insightful analysis about the performance, related applications, advantages, and drawbacks. Then we go through some very recent successful methods, for example, dynamic capacity networks and stochastic depths networks. After that, we survey the evaluation matrices, the main datasets used for evaluating the model performance, and recent benchmark efforts. Finally, we conclude this paper, discuss remaining the challenges and possible directions for future work.",
                        "Citation Paper Authors": "Authors:Yu Cheng, Duo Wang, Pan Zhou, Tao Zhang"
                    }
                },
                {
                    "Sentence ID": 28,
                    "Sentence": "are all CNN models for image classi\ufb01cation. However, they have different\ncharacteristics, where some models are more accurate but more resource hungry. Model selection is a\nresearch problem ",
                    "Citation Text": "T. Li, J. Zhong, J. Liu, W. Wu, and C. Zhang. Ease. ml: towards multi-tenant resource sharing\nfor machine learning workloads. PVLDB , 2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1708.07308",
                        "Citation Paper Title": "Title:Ease.ml: Towards Multi-tenant Resource Sharing for Machine Learning Workloads",
                        "Citation Paper Abstract": "Abstract:We present this http URL, a declarative machine learning service platform we built to support more than ten research groups outside the computer science departments at ETH Zurich for their machine learning needs. With this http URL, a user defines the high-level schema of a machine learning application and submits the task via a Web interface. The system automatically deals with the rest, such as model selection and data movement. In this paper, we describe the this http URL architecture and focus on a novel technical problem introduced by this http URL regarding resource allocation. We ask, as a \"service provider\" that manages a shared cluster of machines among all our users running machine learning workloads, what is the resource allocation strategy that maximizes the global satisfaction of all our users?\nResource allocation is a critical yet subtle issue in this multi-tenant scenario, as we have to balance between efficiency and fairness. We first formalize the problem that we call multi-tenant model selection, aiming for minimizing the total regret of all users running automatic model selection tasks. We then develop a novel algorithm that combines multi-armed bandits with Bayesian optimization and prove a regret bound under the multi-tenant setting. Finally, we report our evaluation of this http URL on synthetic data and on one service we are providing to our users, namely, image classification with deep neural networks. Our experimental evaluation results show that our proposed solution can be up to 9.8x faster in achieving the same global quality for all users as the two popular heuristics used by our users before this http URL.",
                        "Citation Paper Authors": "Authors:Tian Li, Jie Zhong, Ji Liu, Wentao Wu, Ce Zhang"
                    }
                },
                {
                    "Sentence ID": 51,
                    "Sentence": ". It remains challenging\nfor (asynchronous) distributed training due to gradient staleness ",
                    "Citation Text": "J. Wei, W. Dai, A. Kumar, X. Zheng, Q. Ho, and E. P. Xing. Consistent bounded-asynchronous\nparameter servers for distributed ml. arXiv preprint arXiv:1312.7869 , 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1312.7869",
                        "Citation Paper Title": "Title:Consistent Bounded-Asynchronous Parameter Servers for Distributed ML",
                        "Citation Paper Abstract": "Abstract:In distributed ML applications, shared parameters are usually replicated among computing nodes to minimize network overhead. Therefore, proper consistency model must be carefully chosen to ensure algorithm's correctness and provide high throughput. Existing consistency models used in general-purpose databases and modern distributed ML systems are either too loose to guarantee correctness of the ML algorithms or too strict and thus fail to fully exploit the computing power of the underlying distributed system.\nMany ML algorithms fall into the category of \\emph{iterative convergent algorithms} which start from a randomly chosen initial point and converge to optima by repeating iteratively a set of procedures. We've found that many such algorithms are to a bounded amount of inconsistency and still converge correctly. This property allows distributed ML to relax strict consistency models to improve system performance while theoretically guarantees algorithmic correctness. In this paper, we present several relaxed consistency models for asynchronous parallel computation and theoretically prove their algorithmic correctness. The proposed consistency models are implemented in a distributed parameter server and evaluated in the context of a popular ML application: topic modeling.",
                        "Citation Paper Authors": "Authors:Jinliang Wei, Wei Dai, Abhimanu Kumar, Xun Zheng, Qirong Ho, Eric P. Xing"
                    }
                },
                {
                    "Sentence ID": 42,
                    "Sentence": ". A tool with distributed\nhyper-parameter search, e.g. based on Bayesian optimization ",
                    "Citation Text": "J. Snoek, H. Larochelle, and R. P. Adams. Practical bayesian optimization of machine learning\nalgorithms. In NIPS , 2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1206.2944",
                        "Citation Paper Title": "Title:Practical Bayesian Optimization of Machine Learning Algorithms",
                        "Citation Paper Abstract": "Abstract:Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a \"black art\" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.",
                        "Citation Paper Authors": "Authors:Jasper Snoek, Hugo Larochelle, Ryan P. Adams"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1804.09324v1": {
            "Paper Title": "Processing Database Joins over a Shared-Nothing System of Multicore\n  Machines",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.08985v1": {
            "Paper Title": "On-Demand Big Data Integration: A Hybrid ETL Approach for Reproducible\n  Scientific Research",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.08822v1": {
            "Paper Title": "In-Browser Split-Execution Support for Interactive Analytics in the\n  Cloud",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.07550v1": {
            "Paper Title": "Specialty-Aware Task Assignment in Spatial Crowdsourcing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.06764v1": {
            "Paper Title": "A Parallel/Distributed Algorithmic Framework for Mining All Quantitative\n  Association Rules",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.06653v1": {
            "Paper Title": "Consensus Community Detection in Multilayer Networks using\n  Parameter-free Graph Pruning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.07156v1": {
            "Paper Title": "Heuristic and Cost-based Optimization for Diverse Provenance Tasks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.06087v1": {
            "Paper Title": "Rafiki: Machine Learning as an Analytics Service System",
            "Sentences": [
                {
                    "Sentence ID": 28,
                    "Sentence": "randomly selects the value of each hyper-parameter and\nthen try it. It has shown to be more ef\ufb01cient than grid search that\nenumerates all possible hyper-parameter combinations. Bayesian\noptimization ",
                    "Citation Text": "J. Snoek, H. Larochelle, and R. P. Adams. Practical Bayesian\nOptimization of Machine Learning Algorithms. ArXiv\ne-prints , June 2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1206.2944",
                        "Citation Paper Title": "Title:Practical Bayesian Optimization of Machine Learning Algorithms",
                        "Citation Paper Abstract": "Abstract:Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a \"black art\" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.",
                        "Citation Paper Authors": "Authors:Jasper Snoek, Hugo Larochelle, Ryan P. Adams"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1804.05892v1": {
            "Paper Title": "Accelerating Human-in-the-loop Machine Learning: Challenges and\n  Opportunities",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.04526v1": {
            "Paper Title": "EventKG: A Multilingual Event-Centric Temporal Knowledge Graph",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.04367v1": {
            "Paper Title": "BigSR: an empirical study of real-time expressive RDF stream reasoning\n  on modern Big Data platforms",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.04343v1": {
            "Paper Title": "On Using Non-Volatile Memory in Apache Lucene",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.04260v1": {
            "Paper Title": "Graph Pattern Matching Preserving Label-Repetition Constraints",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.01942v1": {
            "Paper Title": "Scaling Out Acid Applications with Operation Partitioning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.01640v1": {
            "Paper Title": "Hypertree Decompositions Revisited for PGMs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.00742v1": {
            "Paper Title": "Minimizing Content Staleness in Dynamo-Style Replicated Storage Systems",
            "Sentences": [
                {
                    "Sentence ID": 19,
                    "Sentence": ", update messages are repl i-\ncated and sent to the receiver through multiple servers; giv en a\ngeneral packet arrival process and memoryless packet servi ce\ntimes, it was shown that Last-Generated First-Serve schedu ling\npolicy is age-optimal. In ",
                    "Citation Text": "Y . Sang, B. Li, and B. Ji, \u201cThe power of waiting for more th an\none response in minimizing the age-of-information,\u201d arXiv preprint\narXiv:1704.04848 , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1704.04848",
                        "Citation Paper Title": "Title:The Power of Waiting for More than One Response in Minimizing the Age-of-Information",
                        "Citation Paper Abstract": "Abstract:The Age-of-Information (AoI) has recently been proposed as an important metric for investigating the timeliness performance in information-update systems. Prior studies on AoI optimization often consider a Push model, which is concerned about when and how to \"push\" (i.e., generate and transmit) the updated information to the user. In stark contrast, in this paper we introduce a new Pull model, which is more relevant for certain applications (such as the real-time stock quotes service), where a user sends requests to the servers to proactively \"pull\" the information of interest. Moreover, we propose to employ request replication to reduce the AoI. Interestingly, we find that under this new Pull model, replication schemes capture a novel tradeoff between different levels of information freshness and different response times across the servers, which can be exploited to minimize the expected AoI at the user's side. Specifically, assuming Poisson updating process at the servers and exponentially distributed response time, we derive a closedform formula for computing the expected AoI and obtain the optimal number of responses to wait for to minimize the expected AoI. Finally, we conduct numerical simulations to elucidate our theoretical results. Our findings show that waiting for more than one response can significantly reduce the AoI in most scenarios.",
                        "Citation Paper Authors": "Authors:Yu Sang, Bin Li, Bo Ji"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1804.00465v1": {
            "Paper Title": "Database as a Service - Current Issues and Its Future",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.00204v2": {
            "Paper Title": "Enabling Quality Control for Entity Resolution: A Human and Machine\n  Cooperation Framework",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.00401v1": {
            "Paper Title": "An End-to-end Neural Natural Language Interface for Databases",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": ", our system\ngenerates a synthetic training set that requires only minimal\nannotations to the database schema.\nAnother recent paper that also uses a deep model to trans-\nlate NL to SQL is ",
                    "Citation Text": "X. Xu, C. Liu, and D. Song. Sqlnet: Generating structured queries from\nnatural language without reinforcement learning. CoRR , abs/1711.04436,\n2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1711.04436",
                        "Citation Paper Title": "Title:SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning",
                        "Citation Paper Abstract": "Abstract:Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.\nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.",
                        "Citation Paper Authors": "Authors:Xiaojun Xu, Chang Liu, Dawn Song"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1804.00224v1": {
            "Paper Title": "A comparative analysis of state-of-the-art SQL-on-Hadoop systems for\n  interactive analytics",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.11328v1": {
            "Paper Title": "Scaling Ordered Stream Processing on Shared-Memory Multicores",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06186v3": {
            "Paper Title": "Compressed Representations of Conjunctive Query Results",
            "Sentences": [
                {
                    "Sentence ID": 8,
                    "Sentence": ".\nThe problem of \ufb01nding class of queries that can be maintained in constant time under updates\nand admit constant delay enumeration is also of considerabl e interest. Recent work ",
                    "Citation Text": "C. Berkholz, J. Keppeler, and N. Schweikardt. Answering conju nctive queries under updates. In\nproceedings of the 36th ACM SIGMOD-SIGACT-SIGAI symposium on Principles of database systems ,\npages 303\u2013318. ACM, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1702.06370",
                        "Citation Paper Title": "Title:Answering Conjunctive Queries under Updates",
                        "Citation Paper Abstract": "Abstract:We consider the task of enumerating and counting answers to $k$-ary conjunctive queries against relational databases that may be updated by inserting or deleting tuples. We exhibit a new notion of q-hierarchical conjunctive queries and show that these can be maintained efficiently in the following sense. During a linear time preprocessing phase, we can build a data structure that enables constant delay enumeration of the query results; and when the database is updated, we can update the data structure and restart the enumeration phase within constant time. For the special case of self-join free conjunctive queries we obtain a dichotomy: if a query is not q-hierarchical, then query enumeration with sublinear$^\\ast$ delay and sublinear update time (and arbitrary preprocessing time) is impossible.\nFor answering Boolean conjunctive queries and for the more general problem of counting the number of solutions of k-ary queries we obtain complete dichotomies: if the query's homomorphic core is q-hierarchical, then size of the the query result can be computed in linear time and maintained with constant update time. Otherwise, the size of the query result cannot be maintained with sublinear update time. All our lower bounds rely on the OMv-conjecture, a conjecture on the hardness of online matrix-vector multiplication that has recently emerged in the field of fine-grained complexity to characterise the hardness of dynamic problems. The lower bound for the counting problem additionally relies on the orthogonal vectors conjecture, which in turn is implied by the strong exponential time hypothesis.\n$^\\ast)$ By sublinear we mean $O(n^{1-\\varepsilon})$ for some $\\varepsilon>0$, where $n$ is the size of the active domain of the current database.",
                        "Citation Paper Authors": "Authors:Christoph Berkholz, Jens Keppeler, Nicole Schweikardt"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1706.05916v4": {
            "Paper Title": "Local Differential Privacy for Physical Sensor Data and Sparse Recovery",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.09627v1": {
            "Paper Title": "GreyCat: Efficient What-If Analytics for Data in Motion at Scale",
            "Sentences": [
                {
                    "Sentence ID": 20,
                    "Sentence": "show how to compute PageRank on evolving\ngraphs. Khurana and Deshpande ",
                    "Citation Text": "U. Khurana, A. Deshpande, Storing and analyzing historical\ngraph data at scale, arXiv preprint arXiv:1509.08960.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1509.08960",
                        "Citation Paper Title": "Title:Storing and Analyzing Historical Graph Data at Scale",
                        "Citation Paper Abstract": "Abstract:The work on large-scale graph analytics to date has largely focused on the study of static properties of graph snapshots. However, a static view of interactions between entities is often an oversimplification of several complex phenomena like the spread of epidemics, information diffusion, formation of online communities}, and so on. Being able to find temporal interaction patterns, visualize the evolution of graph properties, or even simply compare them across time, adds significant value in reasoning over graphs. However, because of lack of underlying data management support, an analyst today has to manually navigate the added temporal complexity of dealing with large evolving graphs. In this paper, we present a system, called Historical Graph Store, that enables users to store large volumes of historical graph data and to express and run complex temporal graph analytical tasks against that data. It consists of two key components: a Temporal Graph Index (TGI), that compactly stores large volumes of historical graph evolution data in a partitioned and distributed fashion; it provides support for retrieving snapshots of the graph as of any timepoint in the past or evolution histories of individual nodes or neighborhoods; and a Spark-based Temporal Graph Analysis Framework (TAF), for expressing complex temporal analytical tasks and for executing them in an efficient and scalable manner. Our experiments demonstrate our system's efficient storage, retrieval and analytics across a wide variety of queries on large volumes of historical graph data.",
                        "Citation Paper Authors": "Authors:Udayan Khurana, Amol Deshpande"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1803.08604v1": {
            "Paper Title": "Learning State Representations for Query Optimization with Deep\n  Reinforcement Learning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.07847v1": {
            "Paper Title": "On-demand Relational Concept Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.09427v3": {
            "Paper Title": "SpinArt: A Spin-based Verifier for Artifact Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1804.01379v1": {
            "Paper Title": "Mining User Behavioral Rules from Smartphone Data through Association\n  Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.09691v3": {
            "Paper Title": "Scalable Entity Resolution Using Probabilistic Signatures on Parallel\n  Databases",
            "Sentences": [
                {
                    "Sentence ID": 39,
                    "Sentence": ", which iteratively blocks,\ncompares, and then merges records, where merged records\nare re-hashed to improve the overall ER quality. However,\na recent evaluation of blocking techniques has found ",
                    "Citation Text": "R. C. Steorts, S. L. Ventura, M. Sadinle, and S. E.\nFienberg. A comparison of blocking methods for\nrecord linkage. In PSD, pages 253{268, 2014.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1407.3191",
                        "Citation Paper Title": "Title:A Comparison of Blocking Methods for Record Linkage",
                        "Citation Paper Abstract": "Abstract:Record linkage seeks to merge databases and to remove duplicates when unique identifiers are not available. Most approaches use blocking techniques to reduce the computational complexity associated with record linkage. We review traditional blocking techniques, which typically partition the records according to a set of field attributes, and consider two variants of a method known as locality sensitive hashing, sometimes referred to as \"private blocking.\" We compare these approaches in terms of their recall, reduction ratio, and computational complexity. We evaluate these methods using different synthetic datafiles and conclude with a discussion of privacy-related issues.",
                        "Citation Paper Authors": "Authors:Rebecca C. Steorts, Samuel L. Ventura, Mauricio Sadinle, Stephen E. Fienberg"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1803.06674v1": {
            "Paper Title": "A View-based Programmable Architecture for Controlling and Integrating\n  Decentralized Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.06416v1": {
            "Paper Title": "Differential Privacy for Growing Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.06089v1": {
            "Paper Title": "Distributed Caching for Complex Querying of Raw Arrays",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.06015v1": {
            "Paper Title": "Database Perspectives on Blockchains",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.05277v1": {
            "Paper Title": "Constant delay algorithms for regular document spanners",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.04884v1": {
            "Paper Title": "IDEL: In-Database Entity Linking with Neural Embeddings",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.04292v1": {
            "Paper Title": "Geodabs: Trajectory Indexing Meets Fingerprinting at Scale",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.04237v1": {
            "Paper Title": "Causal Consistency and Latency Optimality: Friend or Foe?",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.04141v1": {
            "Paper Title": "A Modular Design for Geo-Distributed Querying",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.04120v1": {
            "Paper Title": "GPU Accelerated Self-join for the Distance Similarity Metric",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.09973v2": {
            "Paper Title": "Social Event Scheduling",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.01390v1": {
            "Paper Title": "Comparing Downward Fragments of the Relational Calculus with Transitive\n  Closure on Trees",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.01135v1": {
            "Paper Title": "MaskLink: Efficient Link Discovery for Spatial Relations via Masking\n  Areas",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.01024v1": {
            "Paper Title": "PRESISTANT: Learning based assistant for data pre-processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.01618v2": {
            "Paper Title": "Enabling Strong Database Integrity using Trusted Execution Environments",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.06814v3": {
            "Paper Title": "Scalable and robust set similarity join",
            "Sentences": []
        },
        "http://arxiv.org/abs/1803.00497v1": {
            "Paper Title": "Graph Based Proactive Secure Decomposition Algorithm for Context\n  Dependent Attribute Based Inference Control Problem",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.07484v2": {
            "Paper Title": "Incremental View Maintenance with Triple Lock Factorization Benefits",
            "Sentences": [
                {
                    "Sentence ID": 8,
                    "Sentence": "as it can support cyclic joins (see Section 6). The so-called q-hierarchical join queries (such\nas the Housing query in our experiments) are exactly those self-join-free conjunctive queries that admit\nconstant time update ",
                    "Citation Text": "C. Berkholz, J. Keppeler, and N. Schweikardt. Answering Conjunctive Queries under Updates. In\nPODS , pages 303{318, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1702.06370",
                        "Citation Paper Title": "Title:Answering Conjunctive Queries under Updates",
                        "Citation Paper Abstract": "Abstract:We consider the task of enumerating and counting answers to $k$-ary conjunctive queries against relational databases that may be updated by inserting or deleting tuples. We exhibit a new notion of q-hierarchical conjunctive queries and show that these can be maintained efficiently in the following sense. During a linear time preprocessing phase, we can build a data structure that enables constant delay enumeration of the query results; and when the database is updated, we can update the data structure and restart the enumeration phase within constant time. For the special case of self-join free conjunctive queries we obtain a dichotomy: if a query is not q-hierarchical, then query enumeration with sublinear$^\\ast$ delay and sublinear update time (and arbitrary preprocessing time) is impossible.\nFor answering Boolean conjunctive queries and for the more general problem of counting the number of solutions of k-ary queries we obtain complete dichotomies: if the query's homomorphic core is q-hierarchical, then size of the the query result can be computed in linear time and maintained with constant update time. Otherwise, the size of the query result cannot be maintained with sublinear update time. All our lower bounds rely on the OMv-conjecture, a conjecture on the hardness of online matrix-vector multiplication that has recently emerged in the field of fine-grained complexity to characterise the hardness of dynamic problems. The lower bound for the counting problem additionally relies on the orthogonal vectors conjecture, which in turn is implied by the strong exponential time hypothesis.\n$^\\ast)$ By sublinear we mean $O(n^{1-\\varepsilon})$ for some $\\varepsilon>0$, where $n$ is the size of the active domain of the current database.",
                        "Citation Paper Authors": "Authors:Christoph Berkholz, Jens Keppeler, Nicole Schweikardt"
                    }
                },
                {
                    "Sentence ID": 7,
                    "Sentence": ", and propose a uni\fed approach for factorized computation of aggregates over joins ",
                    "Citation Text": "N. Bakibayev, T. Kocisk\u0013 y, D. Olteanu, and J. Z\u0013 avodn\u0012 y. Aggregation and Ordering in Factorised\nDatabases. PVLDB , 6(14):1990{2001, 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1307.0441",
                        "Citation Paper Title": "Title:Aggregation and Ordering in Factorised Databases",
                        "Citation Paper Abstract": "Abstract:A common approach to data analysis involves understanding and manipulating succinct representations of data. In earlier work, we put forward a succinct representation system for relational data called factorised databases and reported on the main-memory query engine FDB for select-project-join queries on such databases.\nIn this paper, we extend FDB to support a larger class of practical queries with aggregates and ordering. This requires novel optimisation and evaluation techniques. We show how factorisation coupled with partial aggregation can effectively reduce the number of operations needed for query evaluation. We also show how factorisations of query results can support enumeration of tuples in desired orders as efficiently as listing them from the unfactorised, sorted results.\nWe experimentally observe that FDB can outperform off-the-shelf relational engines by orders of magnitude.",
                        "Citation Paper Authors": "Authors:Nurzhan Bakibayev, Tom\u00e1\u0161 Ko\u010disk\u00fd, Dan Olteanu, Jakub Z\u00e1vodn\u00fd"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1802.10543v1": {
            "Paper Title": "A Frequent Itemset Hiding Toolbox",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.08905v3": {
            "Paper Title": "Navigating the Data Lake with Datamaran: Automatically Extracting\n  Structure from Log Datasets",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.09594v1": {
            "Paper Title": "All nearest neighbor calculation based on Delaunay graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.09488v1": {
            "Paper Title": "Adaptive Geospatial Joins for Modern Hardware",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.04891v3": {
            "Paper Title": "Cobra: A Framework for Cost Based Rewriting of Database Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.09180v1": {
            "Paper Title": "Cuttlefish: A Lightweight Primitive for Adaptive Query Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.08800v1": {
            "Paper Title": "Stochastic Gradient Descent on Highly-Parallel Architectures",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.08586v1": {
            "Paper Title": "Database Aggregation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.07693v2": {
            "Paper Title": "RStore: A Distributed Multi-version Document Store",
            "Sentences": [
                {
                    "Sentence ID": 24,
                    "Sentence": ". Our work can\nbe seen as exploring a different design point in that space, with a\nfocus on storing versions of a collection of semi-structured or un-\nstructured records in the cloud and supporting ef\ufb01cient key-based\naccess to them. ",
                    "Citation Text": "S. Huang, L. Xu, J. Liu, A. J. Elmore, and A. G.\nParameswaran. OrpheusDB: Bolt-on versioning for\nrelational databases. In PVLDB , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1703.02475",
                        "Citation Paper Title": "Title:OrpheusDB: Bolt-on Versioning for Relational Databases",
                        "Citation Paper Abstract": "Abstract:Data science teams often collaboratively analyze datasets, generating dataset versions at each stage of iterative exploration and analysis. There is a pressing need for a system that can support dataset versioning, enabling such teams to efficiently store, track, and query across dataset versions. We introduce OrpheusDB, a dataset version control system that \"bolts on\" versioning capabilities to a traditional relational database system, thereby gaining the analytics capabilities of the database \"for free\". We develop and evaluate multiple data models for representing versioned data, as well as a light-weight partitioning scheme, LyreSplit, to further optimize the models for reduced query latencies. With LyreSplit, OrpheusDB is on average 1000x faster in finding effective (and better) partitionings than competing approaches, while also reducing the latency of version retrieval by up to 20x relative to schemes without partitioning. LyreSplit can be applied in an online fashion as new versions are added, alongside an intelligent migration scheme that reduces migration time by 10x on average.",
                        "Citation Paper Authors": "Authors:Silu Huang, Liqi Xu, Jialin Liu, Aaron Elmore, Aditya Parameswaran"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1802.08052v1": {
            "Paper Title": "Data Consistency Simulation Tool for NoSQL Database Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.09039v3": {
            "Paper Title": "Variance-Optimal Offline and Streaming Stratified Random Sampling",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.05898v1": {
            "Paper Title": "PRoST: Distributed Execution of SPARQL Queries Using Mixed Partitioning\n  Strategies",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.04949v1": {
            "Paper Title": "ForkBase: An Efficient Storage Engine for Blockchain and Forkable\n  Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.03638v2": {
            "Paper Title": "Beyond Markov Logic: Efficient Mining of Prediction Rules in Large\n  Graphs",
            "Sentences": [
                {
                    "Sentence ID": 11,
                    "Sentence": ", an approach to link prediction using analogies\namong nodes embedded in a vector space; an ensemble learning\napproach dubbed D/i.sc/s.sc/t.scM/u.sc/l.sc/t.sc , by ",
                    "Citation Text": "Rudolf Kadlec, Ondrej Bajgar, and Jan Kleindienst. 2017. Knowledge Base Com-\npletion: Baselines Strike Back. arXiv preprint arXiv:1705.10744 (2017).",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1705.10744",
                        "Citation Paper Title": "Title:Knowledge Base Completion: Baselines Strike Back",
                        "Citation Paper Abstract": "Abstract:Many papers have been published on the knowledge base completion task in the past few years. Most of these introduce novel architectures for relation learning that are evaluated on standard datasets such as FB15k and WN18. This paper shows that the accuracy of almost all models published on the FB15k can be outperformed by an appropriately tuned baseline - our reimplementation of the DistMult model. Our findings cast doubt on the claim that the performance improvements of recent models are due to architectural changes as opposed to hyper-parameter tuning or different training objectives. This should prompt future research to re-consider how the performance of models is evaluated and reported.",
                        "Citation Paper Authors": "Authors:Rudolf Kadlec, Ondrej Bajgar, Jan Kleindienst"
                    }
                },
                {
                    "Sentence ID": 18,
                    "Sentence": "and the following: H/o.sc/l.scE , a state-of-the-art algorithm\nfor link prediction based on holographic embeddings and neural\nnetworks by ",
                    "Citation Text": "Maximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio. 2015. Holographic\nEmbeddings of Knowledge Graphs. AAAI (2015).",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1510.04935",
                        "Citation Paper Title": "Title:Holographic Embeddings of Knowledge Graphs",
                        "Citation Paper Abstract": "Abstract:Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. In extensive experiments we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction in knowledge graphs and relational learning benchmark datasets.",
                        "Citation Paper Authors": "Authors:Maximilian Nickel, Lorenzo Rosasco, Tomaso Poggio"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1801.02911v2": {
            "Paper Title": "A Stitch in Time Saves Nine -- SPARQL querying of Property Graphs using\n  Gremlin Traversals",
            "Sentences": [
                {
                    "Sentence ID": 12,
                    "Sentence": "by in-\ntroducing the notion of vertex labels, a detailed discus-\nsion on which can be found in ",
                    "Citation Text": "H. Thakkar, D. Punjani, M.-E. Vidal and S. Auer, Towards\nan Integrated Graph Algebra for Graph Pattern Matching with\nGremlin, in: Proceedings of the 28th International Conference,\nDEXA 2017, Lyon, France, August 28-31, 2017, Proceedings,\nPart I , Springer, 2017, pp. 81\u201391.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1908.06265",
                        "Citation Paper Title": "Title:Towards an Integrated Graph Algebra for Graph Pattern Matching with Gremlin (Extended Version)",
                        "Citation Paper Abstract": "Abstract:Graph data management (also called NoSQL) has revealed beneficial characteristics in terms of flexibility and scalability by differently balancing between query expressivity and schema flexibility. This peculiar advantage has resulted into an unforeseen race of developing new task-specific graph systems, query languages and data models, such as property graphs, key-value, wide column, resource description framework (RDF), etc. Present-day graph query languages are focused towards flexible graph pattern matching (aka sub-graph matching), whereas graph computing frameworks aim towards providing fast parallel (distributed) execution of instructions. The consequence of this rapid growth in the variety of graph-based data management systems has resulted in a lack of standardization. Gremlin, a graph traversal language, and machine provides a common platform for supporting any graph computing system (such as an OLTP graph database or OLAP graph processors). We present a formalization of graph pattern matching for Gremlin queries. We also study, discuss and consolidate various existing graph algebra operators into an integrated graph algebra.",
                        "Citation Paper Authors": "Authors:Harsh Thakkar, Dharmen Punjani, Soeren Auer, Maria-Esther Vidal"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1802.04060v1": {
            "Paper Title": "Notable Characteristics Search through Knowledge Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.03855v1": {
            "Paper Title": "MedTQ: Dynamic Topic Discovery and Query Generation for Medical\n  Ontologies",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.03760v1": {
            "Paper Title": "Distributed Evaluation of Subgraph Queries Using Worstcase Optimal\n  LowMemory Dataflows",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.03057v1": {
            "Paper Title": "System G Distributed Graph Database",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.00345v2": {
            "Paper Title": "Users Constraints in Itemset Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.02872v1": {
            "Paper Title": "SQL Query Completion for Data Exploration",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.05613v2": {
            "Paper Title": "Query2Vec: An Evaluation of NLP Techniques for Generalized Workload\n  Analytics",
            "Sentences": [
                {
                    "Sentence ID": 46,
                    "Sentence": "aims to map some semi-struct-\nured input (e.g., text at various resolutions [36, 35, 29],\nan image, a video ",
                    "Citation Text": "N. Srivastava, E. Mansimov, and R. Salakhutdinov.\nUnsupervised learning of video representations using\nlstms. CoRR , abs/1502.04681, 2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1502.04681",
                        "Citation Paper Title": "Title:Unsupervised Learning of Video Representations using LSTMs",
                        "Citation Paper Abstract": "Abstract:We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations (\"percepts\") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.",
                        "Citation Paper Authors": "Authors:Nitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1707.06974v2": {
            "Paper Title": "Cost-Driven Ontology-Based Data Access (Extended Version)",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.00696v1": {
            "Paper Title": "Size-aware Sharding For Improving Tail Latencies in In-memory Key-value\n  Stores",
            "Sentences": []
        },
        "http://arxiv.org/abs/1802.00230v1": {
            "Paper Title": "Integrity Coded Databases: An Evaluation of Performance, Efficiency, and\n  Practicality",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.09709v1": {
            "Paper Title": "Temporally-Biased Sampling for Online Model Management",
            "Sentences": [
                {
                    "Sentence ID": 3,
                    "Sentence": "and\ncould potentially be used in a system like Velox to help deployed\nmodels recover from poor performance more quickly. The de-\nvelopers of the recent MacroBase system ",
                    "Citation Text": "Peter Bailis, Edward Gan, Samuel Madden, Deepak Narayanan, Kexin Rong,\nand Sahaana Suri. 2017. MacroBase: Prioritizing Attention in Fast Data. In\nSIGMOD . 541\u2013556.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1603.00567",
                        "Citation Paper Title": "Title:MacroBase: Prioritizing Attention in Fast Data",
                        "Citation Paper Abstract": "Abstract:As data volumes continue to rise, manual inspection is becoming increasingly untenable. In response, we present MacroBase, a data analytics engine that prioritizes end-user attention in high-volume fast data streams. MacroBase enables efficient, accurate, and modular analyses that highlight and aggregate important and unusual behavior, acting as a search engine for fast data. MacroBase is able to deliver order-of-magnitude speedups over alternatives by optimizing the combination of explanation and classification tasks and by leveraging a new reservoir sampler and heavy-hitters sketch specialized for fast data streams. As a result, MacroBase delivers accurate results at speeds of up to 2M events per second per query on a single core. The system has delivered meaningful results in production, including at a telematics company monitoring hundreds of thousands of vehicles.",
                        "Citation Paper Authors": "Authors:Peter Bailis, Edward Gan, Samuel Madden, Deepak Narayanan, Kexin Rong, Sahaana Suri"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1801.09639v1": {
            "Paper Title": "ONCE and ONCE+: Counting the Frequency of Time-constrained Serial\n  Episodes in a Streaming Sequence",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.00783v3": {
            "Paper Title": "A Semantic-Rich Similarity Measure in Heterogeneous Information Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.09556v1": {
            "Paper Title": "Killing Two Birds with One Stone -- Querying Property Graphs using\n  SPARQL via GREMLINATOR",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.08052v1": {
            "Paper Title": "The Historic Development of the Zooarchaeological Database OssoBook and\n  the xBook Framework for Scientific Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.07947v1": {
            "Paper Title": "TritanDB: Time-series Rapid Internet of Things Analytics",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.05476v2": {
            "Paper Title": "An Efficient Probabilistic Approach for Graph Similarity Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.07237v1": {
            "Paper Title": "Smoke: Fine-grained Lineage at Interactive Speed",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.07215v1": {
            "Paper Title": "Get Your Workload in Order: Game Theoretic Prioritization of Database\n  Auditing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.07005v1": {
            "Paper Title": "ACGreGate: A Framework for Practical Access Control for Applications\n  using Weakly Consistent Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.06965v1": {
            "Paper Title": "An Efficient Density-based Clustering Algorithm for Higher-Dimensional\n  Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.06766v1": {
            "Paper Title": "Learning to Speed Up Query Planning in Graph Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.06408v1": {
            "Paper Title": "PRESTO: Probabilistic Cardinality Estimation for RDF Queries Based on\n  Subgraph Overlapping",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.06258v1": {
            "Paper Title": "Towards a Theory of Data-Diff: Optimal Synthesis of Succinct Data\n  Modification Scripts",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.05206v1": {
            "Paper Title": "Sequences, yet Functions: The Dual Nature of Data-Stream Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.05064v1": {
            "Paper Title": "DKVF: A Framework for Rapid Prototyping and Evaluating Distributed\n  Key-value Stores",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.05055v1": {
            "Paper Title": "Toward Metric Indexes for Incremental Insertion and Querying",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.05360v1": {
            "Paper Title": "One-Pass Trajectory Simplification Using the Synchronous Euclidean\n  Distance",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.01600v2": {
            "Paper Title": "Covers of Query Results",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.03493v1": {
            "Paper Title": "Focus: Querying Large Video Datasets with Low Latency and Low Cost",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.03233v1": {
            "Paper Title": "Eliciting Worker Preference for Task Completion",
            "Sentences": []
        },
        "http://arxiv.org/abs/1801.03190v1": {
            "Paper Title": "Risk-Averse Matchings over Uncertain Graph Databases",
            "Sentences": [
                {
                    "Sentence ID": 5,
                    "Sentence": "provide a\nconstant factor approximation on unweighted graphs based on a simple greedy approach, Bansal et\nal. ",
                    "Citation Text": "N. Bansal, A. Gupta, J. Li, J. Mestre, V. Nagarajan, and A. Rudra. When lp is the cure for\nyour matching woes: Improved bounds for stochastic matchings. Algorithmica , 63(4):733{762,\n2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1008.5356",
                        "Citation Paper Title": "Title:When LP is the Cure for Your Matching Woes: Improved Bounds for Stochastic Matchings",
                        "Citation Paper Abstract": "Abstract:Consider a random graph model where each possible edge $e$ is present independently with some probability $p_e$. Given these probabilities, we want to build a large/heavy matching in the randomly generated graph. However, the only way we can find out whether an edge is present or not is to query it, and if the edge is indeed present in the graph, we are forced to add it to our matching. Further, each vertex $i$ is allowed to be queried at most $t_i$ times. How should we adaptively query the edges to maximize the expected weight of the matching? We consider several matching problems in this general framework (some of which arise in kidney exchanges and online dating, and others arise in modeling online advertisements); we give LP-rounding based constant-factor approximation algorithms for these problems. Our main results are the following:\nWe give a 4 approximation for weighted stochastic matching on general graphs, and a 3 approximation on bipartite graphs. This answers an open question from [Chen etal ICALP 09]. Combining our LP-rounding algorithm with the natural greedy algorithm, we give an improved 3.46 approximation for unweighted stochastic matching on general graphs.\nWe introduce a generalization of the stochastic online matching problem [Feldman etal FOCS 09] that also models preference-uncertainty and timeouts of buyers, and give a constant factor approximation algorithm.",
                        "Citation Paper Authors": "Authors:Nikhil Bansal, Anupam Gupta, Jian Li, Julian Mestre, Viswanath Nagarajan, Atri Rudra"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1801.01012v1": {
            "Paper Title": "Graph Pattern Matching for Dynamic Team Formation",
            "Sentences": [
                {
                    "Sentence ID": 29,
                    "Sentence": "and its extensions have been intro-\nduced for graph pattern matching [11,14,28,29], in which\nstrong simulation introduces duality and locality into simu-lation ",
                    "Citation Text": "S. Ma, Y. Cao, W. Fan, J. Huai, and T. Wo. Strong\nsimulation: Capturing topology in graph pattern matching.\nACM Trans. Database Syst. , 39(1):4:1\u20134:46, 2014.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1201.0229",
                        "Citation Paper Title": "Title:Capturing Topology in Graph Pattern Matching",
                        "Citation Paper Abstract": "Abstract:Graph pattern matching is often defined in terms of subgraph isomorphism, an NP-complete problem. To lower its complexity, various extensions of graph simulation have been considered instead. These extensions allow pattern matching to be conducted in cubic-time. However, they fall short of capturing the topology of data graphs, i.e., graphs may have a structure drastically different from pattern graphs they match, and the matches found are often too large to understand and analyze. To rectify these problems, this paper proposes a notion of strong simulation, a revision of graph simulation, for graph pattern matching. (1) We identify a set of criteria for preserving the topology of graphs matched. We show that strong simulation preserves the topology of data graphs and finds a bounded number of matches. (2) We show that strong simulation retains the same complexity as earlier extensions of simulation, by providing a cubic-time algorithm for computing strong simulation. (3) We present the locality property of strong simulation, which allows us to effectively conduct pattern matching on distributed graphs. (4) We experimentally verify the effectiveness and efficiency of these algorithms, using real-life data and synthetic data.",
                        "Citation Paper Authors": "Authors:Shuai Ma, Yang Cao, Wenfei Fan, Jinpeng Huai, Tianyu Wo"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1801.00829v1": {
            "Paper Title": "On Optimizing Operator Fusion Plans for Large-Scale Machine Learning in\n  SystemML",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.02982v2": {
            "Paper Title": "How to Balance Privacy and Money through Pricing Mechanism in Personal\n  Data Market",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.08971v2": {
            "Paper Title": "Human-Centric Data Cleaning [Vision]",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.09624v1": {
            "Paper Title": "Cuckoo++ Hash Tables: High-Performance Hash Tables for Networking\n  Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.09437v1": {
            "Paper Title": "Pattern-Driven Data Cleaning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.08707v1": {
            "Paper Title": "Freebase-triples: A Methodology for Processing the Freebase Data Dumps",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.07705v1": {
            "Paper Title": "Computing Optimal Repairs for Functional Dependencies",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.07199v1": {
            "Paper Title": "Cognitive Database: A Step towards Endowing Relational Databases with\n  Artificial Intelligence Capabilities",
            "Sentences": [
                {
                    "Sentence ID": 29,
                    "Sentence": ", or for\npersonalized fashion shopping [47, 2]. Hope et. al. have pro-\nposed using word embedding for supporting analogy queries\nover knowledge bases such as the US Patent database ",
                    "Citation Text": "T. Hope, J. Chan, A. Kittur, and D. Shahaf.\nAccelerating innovation through analogy mining. In\nProceedings of the 23rd ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining ,\nKDD '17, pages 235{243, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1706.05585",
                        "Citation Paper Title": "Title:Accelerating Innovation Through Analogy Mining",
                        "Citation Paper Abstract": "Abstract:The availability of large idea repositories (e.g., the U.S. patent database) could significantly accelerate innovation and discovery by providing people with inspiration from solutions to analogous problems. However, finding useful analogies in these large, messy, real-world repositories remains a persistent challenge for either human or automated methods. Previous approaches include costly hand-created databases that have high relational structure (e.g., predicate calculus representations) but are very sparse. Simpler machine-learning/information-retrieval similarity metrics can scale to large, natural-language datasets, but struggle to account for structural similarity, which is central to analogy. In this paper we explore the viability and value of learning simpler structural representations, specifically, \"problem schemas\", which specify the purpose of a product and the mechanisms by which it achieves that purpose. Our approach combines crowdsourcing and recurrent neural networks to extract purpose and mechanism vector representations from product descriptions. We demonstrate that these learned vectors allow us to find analogies with higher precision and recall than traditional information-retrieval methods. In an ideation experiment, analogies retrieved by our models significantly increased people's likelihood of generating creative ideas compared to analogies retrieved by traditional methods. Our results suggest a promising approach to enabling computational analogy at scale is to learn and leverage weaker structural representations.",
                        "Citation Paper Authors": "Authors:Tom Hope, Joel Chan, Aniket Kittur, Dafna Shahaf"
                    }
                },
                {
                    "Sentence ID": 64,
                    "Sentence": ".\nApplications of Word Embedding: The word embed-\nding model is being used for a wide variety of applications\nbeyond NLP. Wu et al ",
                    "Citation Text": "L. Wu, A. Fisch, S. Chopra, K. Adams, A. Bordes,\nand J. Weston. Starspace: Embed all the things!\nCoRR , abs/1709.03856, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1709.03856",
                        "Citation Paper Title": "Title:StarSpace: Embed All The Things!",
                        "Citation Paper Abstract": "Abstract:We present StarSpace, a general-purpose neural embedding model that can solve a wide variety of problems: labeling tasks such as text classification, ranking tasks such as information retrieval/web search, collaborative filtering-based or content-based recommendation, embedding of multi-relational graphs, and learning word, sentence or document level embeddings. In each case the model works by embedding those entities comprised of discrete features and comparing them against each other -- learning similarities dependent on the task. Empirical results on a number of tasks show that StarSpace is highly competitive with existing methods, whilst also being generally applicable to new cases where those methods are not.",
                        "Citation Paper Authors": "Authors:Ledell Wu, Adam Fisch, Sumit Chopra, Keith Adams, Antoine Bordes, Jason Weston"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1712.06802v1": {
            "Paper Title": "Estimation of Individual Micro Data from Aggregated Open Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.04738v3": {
            "Paper Title": "SilkMoth: An Efficient Method for Finding Related Sets with Maximum\n  Matching Constraints",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.05193v1": {
            "Paper Title": "Rate of Change Analysis for Interestingness Measures",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.05857v2": {
            "Paper Title": "An Optimal and Progressive Approach to Online Search of Top-k\n  Influential Communities",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.04202v1": {
            "Paper Title": "Interactive graph query language for multidimensional data in\n  Collaboration Spotting visual analytics framework",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.04108v1": {
            "Paper Title": "Incremental View Maintenance for Property Graph Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.03438v1": {
            "Paper Title": "Assessing Achievability of Queries and Constraints",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.03900v1": {
            "Paper Title": "Developing a Spatial-Temporal Contextual and Semantic Trajectory\n  Clustering Framework",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.02912v1": {
            "Paper Title": "Exploiting Modern Hardware for High-Dimensional Nearest Neighbor Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.11528v2": {
            "Paper Title": "Extracting Syntactic Patterns from Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.01550v2": {
            "Paper Title": "G-CORE: A Core for Future Graph Query Languages",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.01817v1": {
            "Paper Title": "Analyzing Large-Scale, Distributed and Uncertain Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.01063v1": {
            "Paper Title": "A Second-Order Approach to Complex Event Recognition",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.10088v3": {
            "Paper Title": "Fine-grained Pattern Matching Over Streaming Time Series",
            "Sentences": []
        },
        "http://arxiv.org/abs/1712.00078v1": {
            "Paper Title": "Mining Precision Interfaces From Query Logs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.10933v1": {
            "Paper Title": "Learning Interesting Categorical Attributes for Refined Data Exploration",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.09543v1": {
            "Paper Title": "DTranx: A SEDA-based Distributed and Transactional Key Value Store with\n  Persistent Memory Log",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.09411v1": {
            "Paper Title": "BL-ECD: Broad Learning based Enterprise Community Detection via\n  Hierarchical Structure Fusion",
            "Sentences": [
                {
                    "Sentence ID": 24,
                    "Sentence": ". In addition, many community\ndetection works have been done on heterogeneous online social\nnetworks. Sun et al. ",
                    "Citation Text": "Y. Sun, C. Aggarwal, and J. Han. Relation strength-aware clustering of heteroge-\nneous information networks with incomplete a/t_tributes. VLDB , 2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1201.6563",
                        "Citation Paper Title": "Title:Relation Strength-Aware Clustering of Heterogeneous Information Networks with Incomplete Attributes",
                        "Citation Paper Abstract": "Abstract:With the rapid development of online social media, online shopping sites and cyber-physical systems, heterogeneous information networks have become increasingly popular and content-rich over time. In many cases, such networks contain multiple types of objects and links, as well as different kinds of attributes. The clustering of these objects can provide useful insights in many applications. However, the clustering of such networks can be challenging since (a) the attribute values of objects are often incomplete, which implies that an object may carry only partial attributes or even no attributes to correctly label itself; and (b) the links of different types may carry different kinds of semantic meanings, and it is a difficult task to determine the nature of their relative importance in helping the clustering for a given purpose. In this paper, we address these challenges by proposing a model-based clustering algorithm. We design a probabilistic model which clusters the objects of different types into a common hidden space, by using a user-specified set of attributes, as well as the links from different relations. The strengths of different types of links are automatically learned, and are determined by the given purpose of clustering. An iterative algorithm is designed for solving the clustering problem, in which the strengths of different types of links and the quality of clustering results mutually enhance each other. Our experimental results on real and synthetic data sets demonstrate the effectiveness and efficiency of the algorithm.",
                        "Citation Paper Authors": "Authors:Yizhou Sun, Charu C. Aggarwal, Jiawei Han"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1711.09409v1": {
            "Paper Title": "BL-MNE: Emerging Heterogeneous Social Network Embedding through Broad\n  Learning with Aligned Autoencoder",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.09279v1": {
            "Paper Title": "A Big Data Analysis Framework Using Apache Spark and Deep Learning",
            "Sentences": [
                {
                    "Sentence ID": 18,
                    "Sentence": "proposed a cascade of feature-sharing deep classi\ufb01ers, called\nOnionNet, where subsequent stages added both new layers as\nwell as new feature channels to the previous ones. Recently, ",
                    "Citation Text": "P. F. Christ, M. E. A. Elshaer, F. Ettlinger, S. Tatavarty, M. Bickel,\nP. Bilic, M. Remp\ufb02er, M. Armbruster, F. Hofmann, M. DAnastasi, et al. ,\n\u201cAutomatic liver and lesion segmentation in ct using cascaded fully\nconvolutional neural networks and 3d conditional random \ufb01elds,\u201d in\nInternational Conference on Medical Image Computing and Computer-\nAssisted Intervention , pp. 415\u2013423, Springer, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1610.02177",
                        "Citation Paper Title": "Title:Automatic Liver and Lesion Segmentation in CT Using Cascaded Fully Convolutional Neural Networks and 3D Conditional Random Fields",
                        "Citation Paper Abstract": "Abstract:Automatic segmentation of the liver and its lesion is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT abdomen images using cascaded fully convolutional neural networks (CFCNs) and dense 3D conditional random fields (CRFs). We train and cascade two FCNs for a combined segmentation of the liver and its lesions. In the first step, we train a FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions from the predicted liver ROIs of step 1. We refine the segmentations of the CFCN using a dense 3D CRF that accounts for both spatial coherence and appearance. CFCN models were trained in a 2-fold cross-validation on the abdominal CT dataset 3DIRCAD comprising 15 hepatic tumor volumes. Our results show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94% for liver with computation times below 100s per volume. We experimentally demonstrate the robustness of the proposed method as a decision support system with a high accuracy and speed for usage in daily clinical routine.",
                        "Citation Paper Authors": "Authors:Patrick Ferdinand Christ, Mohamed Ezzeldin A. Elshaer, Florian Ettlinger, Sunil Tatavarty, Marc Bickel, Patrick Bilic, Markus Rempfler, Marco Armbruster, Felix Hofmann, Melvin D'Anastasi, Wieland H. Sommer, Seyed-Ahmad Ahmadi, Bjoern H. Menze"
                    }
                },
                {
                    "Sentence ID": 2,
                    "Sentence": ". It gives\na brief overview regarding the programming model, which\nincludes RDDs, parallel computing etc. It also introduces a few\nimplementations in the environment. ",
                    "Citation Text": "X. Meng, J. Bradley, B. Yavuz, E. Sparks, S. Venkataraman, D. Liu,\nJ. Freeman, D. Tsai, M. Amde, S. Owen, et al. , \u201cMllib: Machine learning\nin apache spark,\u201d Journal of Machine Learning Research , vol. 17, no. 34,\npp. 1\u20137, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1505.06807",
                        "Citation Paper Title": "Title:MLlib: Machine Learning in Apache Spark",
                        "Citation Paper Abstract": "Abstract:Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed.",
                        "Citation Paper Authors": "Authors:Xiangrui Meng, Joseph Bradley, Burak Yavuz, Evan Sparks, Shivaram Venkataraman, Davies Liu, Jeremy Freeman, DB Tsai, Manish Amde, Sean Owen, Doris Xin, Reynold Xin, Michael J. Franklin, Reza Zadeh, Matei Zaharia, Ameet Talwalkar"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1711.09189v1": {
            "Paper Title": "A Near-optimal Algorithm for Edge Connectivity-based Hierarchical Graph\n  Decomposition",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.08330v1": {
            "Paper Title": "Adaptive Cardinality Estimation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.07581v1": {
            "Paper Title": "Spec-QP: Speculative Query Planning for Joins over Knowledge Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.07295v1": {
            "Paper Title": "Bitmap Filter: Speeding up Exact Set Similarity Joins with Bitwise\n  Operations",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.04710v2": {
            "Paper Title": "Spatio-Temporal Data Mining: A Survey of Problems and Methods",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.06608v1": {
            "Paper Title": "Loom: Query-aware Partitioning of Online Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.05573v2": {
            "Paper Title": "PlinyCompute: A Platform for High-Performance, Distributed,\n  Data-Intensive Tool Development",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.05787v1": {
            "Paper Title": "WebRelate: Integrating Web Data with Spreadsheets using Examples",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.05090v1": {
            "Paper Title": "Efficiency Analysis of ASP Encodings for Sequential Pattern Mining Tasks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.04971v1": {
            "Paper Title": "DataVizard: Recommending Visual Presentations for Structured Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.04436v1": {
            "Paper Title": "SQLNet: Generating Structured Queries From Natural Language Without\n  Reinforcement Learning",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.04001v1": {
            "Paper Title": "Automated Migration of Hierarchical Data to Relational Tables using\n  Programming-by-Example",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.03955v1": {
            "Paper Title": "StreetX: Spatio-Temporal Access Control Model for Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.02952v1": {
            "Paper Title": "Marginal Release Under Local Differential Privacy",
            "Sentences": [
                {
                    "Sentence ID": 16,
                    "Sentence": ", where RR is ap-\nplied to a Bloom \ufb01lter encoding a large set of possible URLs. In a\nfollow-up paper, Fanti et al. ",
                    "Citation Text": "G. Fanti, V . Pihur, and \u00b4U. Erlingsson. Building a rappor with\nthe unknown: Privacy-preserving learning of associations\nand data dictionaries. Proceedings on Privacy Enhancing\nTechnologies , 2016(3):41\u201361, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1503.01214",
                        "Citation Paper Title": "Title:Building a RAPPOR with the Unknown: Privacy-Preserving Learning of Associations and Data Dictionaries",
                        "Citation Paper Abstract": "Abstract:Techniques based on randomized response enable the collection of potentially sensitive data from clients in a privacy-preserving manner with strong local differential privacy guarantees. One of the latest such technologies, RAPPOR, allows the marginal frequencies of an arbitrary set of strings to be estimated via privacy-preserving crowdsourcing. However, this original estimation process requires a known set of possible strings; in practice, this dictionary can often be extremely large and sometimes completely unknown.\nIn this paper, we propose a novel decoding algorithm for the RAPPOR mechanism that enables the estimation of \"unknown unknowns,\" i.e., strings we do not even know we should be estimating. To enable learning without explicit knowledge of the dictionary, we develop methodology for estimating the joint distribution of two or more variables collected with RAPPOR. This is a critical step towards understanding relationships between multiple variables collected in a privacy-preserving manner.",
                        "Citation Paper Authors": "Authors:Giulia Fanti, Vasyl Pihur, \u00dalfar Erlingsson"
                    }
                },
                {
                    "Sentence ID": 9,
                    "Sentence": "under the\nname of\r-ampli\ufb01cation, with an application to mining association\nrules. Duchi et al. ",
                    "Citation Text": "J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Local\nprivacy and statistical minimax rates. In FOCS . IEEE, 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1302.3203",
                        "Citation Paper Title": "Title:Local Privacy, Data Processing Inequalities, and Statistical Minimax Rates",
                        "Citation Paper Abstract": "Abstract:Working under a model of privacy in which data remains private even from the statistician, we study the tradeoff between privacy guarantees and the utility of the resulting statistical estimators. We prove bounds on information-theoretic quantities, including mutual information and Kullback-Leibler divergence, that depend on the privacy guarantees. When combined with standard minimax techniques, including the Le Cam, Fano, and Assouad methods, these inequalities allow for a precise characterization of statistical rates under local privacy constraints. We provide a treatment of several canonical families of problems: mean estimation, parameter estimation in fixed-design regression, multinomial probability estimation, and nonparametric density estimation. For all of these families, we provide lower and upper bounds that match up to constant factors, and exhibit new (optimal) privacy-preserving mechanisms and computationally efficient estimators that achieve the bounds.",
                        "Citation Paper Authors": "Authors:John C. Duchi, Michael I. Jordan, Martin J. Wainwright"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1711.01299v1": {
            "Paper Title": "BoostClean: Automated Error Detection and Repair for Machine Learning",
            "Sentences": [
                {
                    "Sentence ID": 32,
                    "Sentence": ".\nWhile the work on relational queries is extensive, analytical\nqueries (aggregates, advanced statistical analytics, learning etc.)\nis less studied. Projects like ActiveClean ",
                    "Citation Text": "S. Krishnan, J. Wang, E. Wu, M. J. Franklin, and\nK. Goldberg. Activeclean: Interactive data cleaning forstatistical modeling. PVLDB , 9(12):948\u2013959, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1601.03797",
                        "Citation Paper Title": "Title:ActiveClean: Interactive Data Cleaning While Learning Convex Loss Models",
                        "Citation Paper Abstract": "Abstract:Data cleaning is often an important step to ensure that predictive models, such as regression and classification, are not affected by systematic errors such as inconsistent, out-of-date, or outlier data. Identifying dirty data is often a manual and iterative process, and can be challenging on large datasets. However, many data cleaning workflows can introduce subtle biases into the training processes due to violation of independence assumptions. We propose ActiveClean, a progressive cleaning approach where the model is updated incrementally instead of re-training and can guarantee accuracy on partially cleaned data. ActiveClean supports a popular class of models called convex loss models (e.g., linear regression and SVMs). ActiveClean also leverages the structure of a user's model to prioritize cleaning those records likely to affect the results. We evaluate ActiveClean on five real-world datasets UCI Adult, UCI EEG, MNIST, Dollars For Docs, and WorldBank with both real and synthetic errors. Our results suggest that our proposed optimizations can improve model accuracy by up-to 2.5x for the same amount of data cleaned. Furthermore for a fixed cleaning budget and on all real dirty datasets, ActiveClean returns more accurate models than uniform sampling and Active Learning.",
                        "Citation Paper Authors": "Authors:Sanjay Krishnan, Jiannan Wang, Eugene Wu, Michael J. Franklin, Ken Goldberg"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1711.01283v1": {
            "Paper Title": "Mandolin: A Knowledge Discovery Framework for the Web of Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.01046v1": {
            "Paper Title": "Elasticutor: Rapid Elasticity for Realtime Stateful Stream Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.01034v1": {
            "Paper Title": "PS-DBSCAN: An Efficient Parallel DBSCAN Algorithm Based on Platform Of\n  AI (PAI)",
            "Sentences": []
        },
        "http://arxiv.org/abs/1711.00121v1": {
            "Paper Title": "Dynamical SimRank Search on Time-Varying Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.09359v2": {
            "Paper Title": "Generating Time-Based Label Refinements to Discover More Precise Process\n  Models",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.06103v4": {
            "Paper Title": "Modeling Relational Data with Graph Convolutional Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.02263v2": {
            "Paper Title": "Graph Convolutional Matrix Completion",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": ",\na more e\ufb03cient alternating least squares optimization\noptimization method (GRALS) is introduced to the\ngraph-regularized matrix completion problem. Most\nrecently, Monti et al. ",
                    "Citation Text": "Federico Monti, Michael M. Bronstein, and Xavier\nBresson. Geometric matrix completion with recurrent\nmulti-graph neural networks. NIPS, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1704.06803",
                        "Citation Paper Title": "Title:Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks",
                        "Citation Paper Abstract": "Abstract:Matrix completion models are among the most common formulations of recommender systems. Recent works have showed a boost of performance of these techniques when introducing the pairwise relationships between users/items in the form of graphs, and imposing smoothness priors on these graphs. However, such techniques do not fully exploit the local stationarity structures of user/item graphs, and the number of parameters to learn is linear w.r.t. the number of users and items. We propose a novel approach to overcome these limitations by using geometric deep learning on graphs. Our matrix completion architecture combines graph convolutional neural networks and recurrent neural networks to learn meaningful statistical graph-structured patterns and the non-linear diffusion process that generates the known ratings. This neural network system requires a constant number of parameters independent of the matrix size. We apply our method on both synthetic and real datasets, showing that it outperforms state-of-the-art techniques.",
                        "Citation Paper Authors": "Authors:Federico Monti, Michael M. Bronstein, Xavier Bresson"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1709.06416v2": {
            "Paper Title": "Weld: Rethinking the Interface Between Data-Intensive Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.07736v1": {
            "Paper Title": "BigSparse: High-performance external graph analytics",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.07660v1": {
            "Paper Title": "Verifying Equivalence of Database-Driven Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.07411v1": {
            "Paper Title": "STREAK: An Efficient Engine for Processing Top-k SPARQL Queries with\n  Spatial Filters",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.06590v1": {
            "Paper Title": "MEDOC: a Python wrapper to load MEDLINE into a local MySQL database",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.08312v2": {
            "Paper Title": "Continuous Monitoring of Pareto Frontiers on Partially Ordered\n  Attributes for Many Users",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06715v2": {
            "Paper Title": "Empowering In-Memory Relational Database Engines with Native Graph\n  Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.04469v1": {
            "Paper Title": "Pure Operation-Based Replicated Data Types",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.04419v1": {
            "Paper Title": "Querying Best Paths in Graph Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.05693v1": {
            "Paper Title": "Mining Frequent Patterns in Process Models",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": "uses the process model to\nbuild the patterns, checking their frequency in the logs. Extending these mining techniques, the local process mining\napproach of Niek Tax et al. ",
                    "Citation Text": "Tax, N., Sidorova, N., Haakma, R., van der Aalst, W. M., 2016. Mining local process models. Journal of Innovation in Digital Ecosystems.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1606.06066",
                        "Citation Paper Title": "Title:Mining Local Process Models",
                        "Citation Paper Abstract": "Abstract:In this paper we describe a method to discover frequent behavioral patterns in event logs. We express these patterns as \\emph{local process models}. Local process model mining can be positioned in-between process discovery and episode / sequential pattern mining. The technique presented in this paper is able to learn behavioral patterns involving sequential composition, concurrency, choice and loop, like in process mining. However, we do not look at start-to-end models, which distinguishes our approach from process discovery and creates a link to episode / sequential pattern mining. We propose an incremental procedure for building local process models capturing frequent patterns based on so-called process trees. We propose five quality dimensions and corresponding metrics for local process models, given an event log. We show monotonicity properties for some quality dimensions, enabling a speedup of local process model discovery through pruning. We demonstrate through a real life case study that mining local patterns allows us to get insights in processes where regular start-to-end process discovery techniques are only able to learn unstructured, flower-like, models.",
                        "Citation Paper Authors": "Authors:Niek Tax, Natalia Sidorova, Reinder Haakma, Wil M. P. van der Aalst"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1710.04144v1": {
            "Paper Title": "GUIDES - Geospatial Urban Infrastructure Data Engineering Solutions",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.09420v1": {
            "Paper Title": "SOPE: A Spatial Order Preserving Encryption Model for Multi-dimensional\n  Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.03289v1": {
            "Paper Title": "Efficient mining of maximal biclusters in mixed-attribute datasets",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.02047v2": {
            "Paper Title": "InferSpark: Statistical Inference at Scale",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.02817v1": {
            "Paper Title": "Discovery of Paradigm Dependencies",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.02690v1": {
            "Paper Title": "Unique Entity Estimation with Application to the Syrian Conflict",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.00093v3": {
            "Paper Title": "EmbedJoin: Efficient Edit Similarity Joins via Embeddings",
            "Sentences": [
                {
                    "Sentence ID": 4,
                    "Sentence": "with an O(K) distortion,2which serves as the main tool in our algorithm. For sketching , very\nrecently Belazzougui and Zhang ",
                    "Citation Text": "Belazzougui, D., and Zhang, Q. Edit distance: Sketching, streaming and document\nexchange. In FOCS(2016), p. to appear.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1607.04200",
                        "Citation Paper Title": "Title:Edit Distance: Sketching, Streaming and Document Exchange",
                        "Citation Paper Abstract": "Abstract:We show that in the document exchange problem, where Alice holds $x \\in \\{0,1\\}^n$ and Bob holds $y \\in \\{0,1\\}^n$, Alice can send Bob a message of size $O(K(\\log^2 K+\\log n))$ bits such that Bob can recover $x$ using the message and his input $y$ if the edit distance between $x$ and $y$ is no more than $K$, and output \"error\" otherwise. Both the encoding and decoding can be done in time $\\tilde{O}(n+\\mathsf{poly}(K))$. This result significantly improves the previous communication bounds under polynomial encoding/decoding time. We also show that in the referee model, where Alice and Bob hold $x$ and $y$ respectively, they can compute sketches of $x$ and $y$ of sizes $\\mathsf{poly}(K \\log n)$ bits (the encoding), and send to the referee, who can then compute the edit distance between $x$ and $y$ together with all the edit operations if the edit distance is no more than $K$, and output \"error\" otherwise (the decoding). To the best of our knowledge, this is the first result for sketching edit distance using $\\mathsf{poly}(K \\log n)$ bits. Moreover, the encoding phase of our sketching algorithm can be performed by scanning the input string in one pass. Thus our sketching algorithm also implies the first streaming algorithm for computing edit distance and all the edits exactly using $\\mathsf{poly}(K \\log n)$ bits of space.",
                        "Citation Paper Authors": "Authors:Djamal Belazzougui, Qin Zhang"
                    }
                },
                {
                    "Sentence ID": 7,
                    "Sentence": ". Recently Chakraborty et al. gives a weak emb edding to the Hamming space ",
                    "Citation Text": "Chakraborty, D., Goldenberg, E., and Kouck \u00b4y, M.Streaming algorithms for embed-\nding and computing edit distance in the low distance regime. InSTOC(2016), pp. 712\u2013725.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1607.03718",
                        "Citation Paper Title": "Title:Streaming Algorithms For Computing Edit Distance Without Exploiting Suffix Trees",
                        "Citation Paper Abstract": "Abstract:The edit distance is a way of quantifying how similar two strings are to one another by counting the minimum number of character insertions, deletions, and substitutions required to transform one string into the other.\nIn this paper we study the computational problem of computing the edit distance between a pair of strings where their distance is bounded by a parameter $k\\ll n$. We present two streaming algorithms for computing edit distance: One runs in time $O(n+k^2)$ and the other $n+O(k^3)$. By writing $n+O(k^3)$ we want to emphasize that the number of operations per an input symbol is a small constant. In particular, the running time does not depend on the alphabet size, and the algorithm should be easy to implement.\nPreviously a streaming algorithm with running time $O(n+k^4)$ was given in the paper by the current authors (STOC'16). The best off-line algorithm runs in time $O(n+k^2)$ (Landau et al., 1998) which is known to be optimal under the Strong Exponential Time Hypothesis.",
                        "Citation Paper Authors": "Authors:Diptarka Chakraborty, Elazar Goldenberg, Michal Kouck\u00fd"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1710.02317v1": {
            "Paper Title": "Enumeration Problems for Regular Path Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.03028v2": {
            "Paper Title": "Assisting Service Providers In Peer-to-peer Marketplaces: Maximizing\n  Gain Over Flexible Attributes",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.06712v2": {
            "Paper Title": "Towards a Holistic Integration of Spreadsheets with Databases: A\n  Scalable Storage Engine for Presentational Data Management",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.01854v1": {
            "Paper Title": "InfiniViz: Interactive Visual Exploration using Progressive Bin\n  Refinement",
            "Sentences": [
                {
                    "Sentence ID": 58,
                    "Sentence": "incrementally computes visualizations in a\ndistributed environment.\nRecent approaches have looked at incorporating sampling\ninto visualizations. VAS ",
                    "Citation Text": "Y . Park, M. Cafarella, and B. Mozafari, \u201cVisualization-aware Sampling\nfor Very Large Databases,\u201d ICDE , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1510.03921",
                        "Citation Paper Title": "Title:Visualization-Aware Sampling for Very Large Databases",
                        "Citation Paper Abstract": "Abstract:Interactive visualizations are crucial in ad hoc data exploration and analysis. However, with the growing number of massive datasets, generating visualizations in interactive timescales is increasingly challenging. One approach for improving the speed of the visualization tool is via data reduction in order to reduce the computational overhead, but at a potential cost in visualization accuracy. Common data reduction techniques, such as uniform and stratified sampling, do not exploit the fact that the sampled tuples will be transformed into a visualization for human consumption.\nWe propose a visualization-aware sampling (VAS) that guarantees high quality visualizations with a small subset of the entire dataset. We validate our method when applied to scatter and map plots for three common visualization goals: regression, density estimation, and clustering. The key to our sampling method's success is in choosing tuples which minimize a visualization-inspired loss function. Our user study confirms that optimizing this loss function correlates strongly with user success in using the resulting visualizations. We also show the NP-hardness of our optimization problem and propose an efficient approximation algorithm. Our experiments show that, compared to previous methods, (i) using the same sample size, VAS improves user's success by up to 35% in various visualization tasks, and (ii) VAS can achieve a required visualization quality up to 400 times faster.",
                        "Citation Paper Authors": "Authors:Yongjoo Park, Michael Cafarella, Barzan Mozafari"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1709.02529v2": {
            "Paper Title": "FAST: Frequency-Aware Spatio-Textual Indexing for In-Memory Continuous\n  Filter Query Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.01615v1": {
            "Paper Title": "($k$,$\u03b5$)-Anonymity: $k$-Anonymity with $\u03b5$-Differential\n  Privacy",
            "Sentences": [
                {
                    "Sentence ID": 20,
                    "Sentence": "proposes t-closeness, both of which protect against\ninference-based attacks. None of the proposed models consider\nthe combination of other anonymisation protocols.arXiv:1710.01615v1  [cs.CR]  4 Oct 2017Zakerzadeh et. al. ",
                    "Citation Text": "H. Zakerzadeh, C. C. Aggarwal, and K. Barker, \u201cTowards breaking\nthe curse of dimensionality for high-dimensional privacy: An extended\nversion,\u201d in SDM , 2014.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1401.1174",
                        "Citation Paper Title": "Title:Towards Breaking the Curse of Dimensionality for High-Dimensional Privacy: An Extended Version",
                        "Citation Paper Abstract": "Abstract:The curse of dimensionality has remained a challenge for a wide variety of algorithms in data mining, clustering, classification and privacy. Recently, it was shown that an increasing dimensionality makes the data resistant to effective privacy. The theoretical results seem to suggest that the dimensionality curse is a fundamental barrier to privacy preservation. However, in practice, we show that some of the common properties of real data can be leveraged in order to greatly ameliorate the negative effects of the curse of dimensionality. In real data sets, many dimensions contain high levels of inter-attribute correlations. Such correlations enable the use of a process known as vertical fragmentation in order to decompose the data into vertical subsets of smaller dimensionality. An information-theoretic criterion of mutual information is used in the vertical decomposition process. This allows the use of an anonymization process, which is based on combining results from multiple independent fragments. We present a general approach which can be applied to the k-anonymity, l-diversity, and t-closeness models. In the presence of inter-attribute correlations, such an approach continues to be much more robust in higher dimensionality, without losing accuracy. We present experimental results illustrating the effectiveness of the approach. This approach is resilient enough to prevent identity, attribute, and membership disclosure attack.",
                        "Citation Paper Authors": "Authors:Hessam Zakerzadeh, Charu C. Aggrawal, Ken Barker"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1710.02035v1": {
            "Paper Title": "HANDY: A Hybrid Association Rules Mining Approach for Network Layer\n  Discovery of Services for Mobile Ad hoc Network",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.05730v2": {
            "Paper Title": "On Measuring Bias in Online Information",
            "Sentences": [
                {
                    "Sentence ID": 11,
                    "Sentence": ". Biases can be introduced at di\u000berent stages of\nthe design, implementation, training and deployment\nof machine learning algorithms. There are reports for\ndiscriminatory ads based on either race [33, 35], or gen-\nder ",
                    "Citation Text": "C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. S.\nZemel. Fairness through awareness. In ITCS , pages\n214{226, 2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1104.3913",
                        "Citation Paper Title": "Title:Fairness Through Awareness",
                        "Citation Paper Abstract": "Abstract:We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of \"fair affirmative action,\" which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.",
                        "Citation Paper Authors": "Authors:Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, Rich Zemel"
                    }
                },
                {
                    "Sentence ID": 22,
                    "Sentence": ".\nSince most users try to access information that they\nagree with ",
                    "Citation Text": "D. Koutra, P. N. Bennett, and E. Horvitz. Events and\ncontroversies: In\ruences of a shocking news event on\ninformation seeking. In WWW , pages 614{624, 2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1405.1486",
                        "Citation Paper Title": "Title:Events and Controversies: Influences of a Shocking News Event on Information Seeking",
                        "Citation Paper Abstract": "Abstract:It has been suggested that online search and retrieval contributes to the intellectual isolation of users within their preexisting ideologies, where people's prior views are strengthened and alternative viewpoints are infrequently encountered. This so-called \"filter bubble\" phenomenon has been called out as especially detrimental when it comes to dialog among people on controversial, emotionally charged topics, such as the labeling of genetically modified food, the right to bear arms, the death penalty, and online privacy. We seek to identify and study information-seeking behavior and access to alternative versus reinforcing viewpoints following shocking, emotional, and large-scale news events. We choose for a case study to analyze search and browsing on gun control/rights, a strongly polarizing topic for both citizens and leaders of the United States. We study the period of time preceding and following a mass shooting to understand how its occurrence, follow-on discussions, and debate may have been linked to changes in the patterns of searching and browsing. We employ information-theoretic measures to quantify the diversity of Web domains of interest to users and understand the browsing patterns of users. We use these measures to characterize the influence of news events on these web search and browsing patterns.",
                        "Citation Paper Authors": "Authors:Danai Koutra, Paul Bennett, Eric Horvitz"
                    }
                },
                {
                    "Sentence ID": 14,
                    "Sentence": ". Other e\u000borts try to ensure temporal transparency\nfor policy changing events in decision making systems ",
                    "Citation Text": "M. Ferreira, M. B. Zafar, and K. P. Gummadi. The case for\ntemporal transparency: Detecting policy change events in\nblack-box decision making systems. arXiv preprint\narXiv:1610.10064 , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1610.10064",
                        "Citation Paper Title": "Title:The Case for Temporal Transparency: Detecting Policy Change Events in Black-Box Decision Making Systems",
                        "Citation Paper Abstract": "Abstract:Bringing transparency to black-box decision making systems (DMS) has been a topic of increasing research interest in recent years. Traditional active and passive approaches to make these systems transparent are often limited by scalability and/or feasibility issues. In this paper, we propose a new notion of black-box DMS transparency, named, temporal transparency, whose goal is to detect if/when the DMS policy changes over time, and is mostly invariant to the drawbacks of traditional approaches. We map our notion of temporal transparency to time series changepoint detection methods, and develop a framework to detect policy changes in real-world DMS's. Experiments on New York Stop-question-and-frisk dataset reveal a number of publicly announced and unannounced policy changes, highlighting the utility of our framework.",
                        "Citation Paper Authors": "Authors:Miguel Ferreira, Muhammad Bilal Zafar, Krishna P. Gummadi"
                    }
                },
                {
                    "Sentence ID": 15,
                    "Sentence": "and reducing the discrimination degree\nof algorithms against individuals of a protected group ",
                    "Citation Text": "B. Fish, J. Kun, and \u0013A. D. Lelkes. A con\fdence-based\napproach for balancing fairness and accuracy. In SDM ,\npages 144{152, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1601.05764",
                        "Citation Paper Title": "Title:A Confidence-Based Approach for Balancing Fairness and Accuracy",
                        "Citation Paper Abstract": "Abstract:We study three classical machine learning algorithms in the context of algorithmic fairness: adaptive boosting, support vector machines, and logistic regression. Our goal is to maintain the high accuracy of these learning algorithms while reducing the degree to which they discriminate against individuals because of their membership in a protected group.\nOur first contribution is a method for achieving fairness by shifting the decision boundary for the protected group. The method is based on the theory of margins for boosting. Our method performs comparably to or outperforms previous algorithms in the fairness literature in terms of accuracy and low discrimination, while simultaneously allowing for a fast and transparent quantification of the trade-off between bias and error.\nOur second contribution addresses the shortcomings of the bias-error trade-off studied in most of the algorithmic fairness literature. We demonstrate that even hopelessly naive modifications of a biased algorithm, which cannot be reasonably said to be fair, can still achieve low bias and high accuracy. To help to distinguish between these naive algorithms and more sensible algorithms we propose a new measure of fairness, called resilience to random bias (RRB). We demonstrate that RRB distinguishes well between our naive and sensible fairness algorithms. RRB together with bias and accuracy provides a more complete picture of the fairness of an algorithm.",
                        "Citation Paper Authors": "Authors:Benjamin Fish, Jeremy Kun, \u00c1d\u00e1m D. Lelkes"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1710.00867v1": {
            "Paper Title": "Clustering Stream Data by Exploring the Evolution of Density Mountain",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.00608v1": {
            "Paper Title": "Constrained Differential Privacy for Count Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06810v2": {
            "Paper Title": "Efficient Graph Edit Distance Computation and Verification via\n  Anchor-aware Lower Bound Estimation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.09471v3": {
            "Paper Title": "Diversified Coherent Core Search on Multi-Layer Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.00027v1": {
            "Paper Title": "Toward a System Building Agenda for Data Integration",
            "Sentences": []
        },
        "http://arxiv.org/abs/1710.00813v1": {
            "Paper Title": "A Practical Python API for Querying AFLOWLIB",
            "Sentences": [
                {
                    "Sentence ID": 9,
                    "Sentence": "R. H. Taylor, F. Rose, C. Toher, O. Levy, K. Yang, M. B. Nardelli, and S. Curtarolo. A\nRESTfulAPIforexchangingmaterialsdataintheAFLOWLIB.orgconsortium. Computational\nMaterials Science , 93 (Supplement C):178 \u2013 192, 2014. ",
                    "Citation Text": "S. van der Walt, S. C. Colbert, and G. Varoquaux. The numpy array: A structure for e\ufb03cient\nnumerical computation. Computing in Science Engineering , 13(2):22\u201330, March 2011.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1102.1523",
                        "Citation Paper Title": "Title:The NumPy array: a structure for efficient numerical computation",
                        "Citation Paper Abstract": "Abstract:In the Python world, NumPy arrays are the standard representation for numerical data. Here, we show how these arrays enable efficient implementation of numerical computations in a high-level language. Overall, three techniques are applied to improve performance: vectorizing calculations, avoiding copying data in memory, and minimizing operation counts. We first present the NumPy array structure, then show how to use it for efficient computation, and finally how to share array data with other libraries.",
                        "Citation Paper Authors": "Authors:Stefan Van Der Walt, S. Chris Colbert, Ga\u00ebl Varoquaux (Parietal)"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1709.10039v1": {
            "Paper Title": "Answering UCQs under updates and in the presence of integrity\n  constraints",
            "Sentences": [
                {
                    "Sentence ID": 5,
                    "Sentence": ", the enumeration and testing\nproblem under updates has been studied for q-hierarchical and (more general) acyclic CQs in\na setting that is very similar to our setting and the setting of ",
                    "Citation Text": "Christoph Berkholz, Jens Keppeler, and Nicole Schweikardt. Answering conjunctive queries\nunder updates. In Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on\nPrinciples of Database Systems, PODS'17, Chicago, IL, USA, May 14{19, 2017 , pages\n303{318, 2017. Full version available at http://arxiv.org/abs/1702.06370 . URL: http:\n//doi.org/10.1145/3034786.3034789 ,doi:10.1145/3034786.3034789 .",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1702.06370",
                        "Citation Paper Title": "Title:Answering Conjunctive Queries under Updates",
                        "Citation Paper Abstract": "Abstract:We consider the task of enumerating and counting answers to $k$-ary conjunctive queries against relational databases that may be updated by inserting or deleting tuples. We exhibit a new notion of q-hierarchical conjunctive queries and show that these can be maintained efficiently in the following sense. During a linear time preprocessing phase, we can build a data structure that enables constant delay enumeration of the query results; and when the database is updated, we can update the data structure and restart the enumeration phase within constant time. For the special case of self-join free conjunctive queries we obtain a dichotomy: if a query is not q-hierarchical, then query enumeration with sublinear$^\\ast$ delay and sublinear update time (and arbitrary preprocessing time) is impossible.\nFor answering Boolean conjunctive queries and for the more general problem of counting the number of solutions of k-ary queries we obtain complete dichotomies: if the query's homomorphic core is q-hierarchical, then size of the the query result can be computed in linear time and maintained with constant update time. Otherwise, the size of the query result cannot be maintained with sublinear update time. All our lower bounds rely on the OMv-conjecture, a conjecture on the hardness of online matrix-vector multiplication that has recently emerged in the field of fine-grained complexity to characterise the hardness of dynamic problems. The lower bound for the counting problem additionally relies on the orthogonal vectors conjecture, which in turn is implied by the strong exponential time hypothesis.\n$^\\ast)$ By sublinear we mean $O(n^{1-\\varepsilon})$ for some $\\varepsilon>0$, where $n$ is the size of the active domain of the current database.",
                        "Citation Paper Authors": "Authors:Christoph Berkholz, Jens Keppeler, Nicole Schweikardt"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1705.10977v2": {
            "Paper Title": "Time is What Prevents Everything from Happening at Once: Propagation\n  Time-conscious Influence Maximization",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.09099v1": {
            "Paper Title": "PMV: Pre-partitioned Generalized Matrix-Vector Multiplication for\n  Scalable Graph Mining",
            "Sentences": [
                {
                    "Sentence ID": 3,
                    "Sentence": ". Even though\nthese distributed-memory systems achieve faster performance and\nhigher scalability than single machine systems do, they cannot pro-\ncess graphs that do not /f_it into the distributed-memory. Pregelix ",
                    "Citation Text": "Yingyi Bu, Vinayak R. Borkar, Jianfeng Jia, Michael J. Carey, and Tyson Condie.\n2014. Pregelix: Big(ger) Graph Analytics on a Data/f_low Engine. PVLDB 8, 2\n(2014), 161\u2013172.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1407.0455",
                        "Citation Paper Title": "Title:Pregelix: Big(ger) Graph Analytics on A Dataflow Engine",
                        "Citation Paper Abstract": "Abstract:There is a growing need for distributed graph processing systems that are capable of gracefully scaling to very large graph datasets. Unfortunately, this challenge has not been easily met due to the intense memory pressure imposed by process-centric, message passing designs that many graph processing systems follow. Pregelix is a new open source distributed graph processing system that is based on an iterative dataflow design that is better tuned to handle both in-memory and out-of-core workloads. As such, Pregelix offers improved performance characteristics and scaling properties over current open source systems (e.g., we have seen up to 15x speedup compared to Apache Giraph and up to 35x speedup compared to distributed GraphLab), and makes more effective use of available machine resources to support Big(ger) Graph Analytics.",
                        "Citation Paper Authors": "Authors:Yingyi Bu, Vinayak Borkar, Jianfeng Jia, Michael J. Carey, Tyson Condie"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1708.05045v2": {
            "Paper Title": "Cross-lingual Entity Alignment via Joint Attribute-Preserving Embedding",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.07941v1": {
            "Paper Title": "Efficiently Discovering Locally Exceptional yet Globally Representative\n  Subgroups",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06907v1": {
            "Paper Title": "Doctoral Advisor or Medical Condition: Towards Entity-specific Rankings\n  of Knowledge Base Properties [Extended Version]",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06745v1": {
            "Paper Title": "VCExplorer: A Interactive Graph Exploration Framework Based on Hub\n  Vertices with Graph Consolidation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06723v1": {
            "Paper Title": "SBG-Sketch: A Self-Balanced Sketch for Labeled-Graph Stream\n  Summarization",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.03147v2": {
            "Paper Title": "WRS: Waiting Room Sampling for Accurate Triangle Counting in Real Graph\n  Streams",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.09003v1": {
            "Paper Title": "CASP-DM: Context Aware Standard Process for Data Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06202v1": {
            "Paper Title": "A Comparative Quantitative Analysis of Contemporary Big Data Clustering\n  Algorithms for Market Segmentation in Hospitality Industry",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.08674v2": {
            "Paper Title": "Discovering Sequential Patterns in Event-Based Spatio-Temporal Data by\n  Means of Microclustering - Extended Report",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.06176v1": {
            "Paper Title": "Zooming in on NYC taxi data with Portal",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.01414v2": {
            "Paper Title": "Efficient Approximate Query Answering over Sensor Data with\n  Deterministic Error Guarantees",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.05376v1": {
            "Paper Title": "A Rule-Based Approach to Analyzing Database Schema Objects with Datalog",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.05183v1": {
            "Paper Title": "Fast OLAP Query Execution in Main Memory on Large Data in a Cluster",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.10007v3": {
            "Paper Title": "VERIFAS: A Practical Verifier for Artifact Systems",
            "Sentences": [
                {
                    "Sentence ID": 17,
                    "Sentence": "in Section 5 and conclude in Section 6. An ap-\npendixprovidesfurthertechnicaldetails,ourfullrunningexample,\nand a table of symbols.\n2. THE MODEL\nInthissectionwepresentthevariantofHierarchicalArtifactSys-\ntemsusedinourstudy. Thevariant,denotedHAS*,di\ufb00ersfromthe\nHAS model used in ",
                    "Citation Text": "A. Deutsch, Y. Li, and V. Vianu. Veri\ufb01cation of hierarchical\nartifact systems. In PODS, pages 179\u2013194, 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1604.00967",
                        "Citation Paper Title": "Title:Verification of Hierarchical Artifact Systems",
                        "Citation Paper Abstract": "Abstract:Data-driven workflows, of which IBM's Business Artifacts are a prime exponent, have been successfully deployed in practice, adopted in industrial standards, and have spawned a rich body of research in academia, focused primarily on static analysis. The present work represents a significant advance on the problem of artifact verification, by considering a much richer and more realistic model than in previous work, incorporating core elements of IBM's successful Guard-Stage-Milestone model. In particular, the model features task hierarchy, concurrency, and richer artifact data. It also allows database key and foreign key dependencies, as well as arithmetic constraints. The results show decidability of verification and establish its complexity, making use of novel techniques including a hierarchy of Vector Addition Systems and a variant of quantifier elimination tailored to our context.",
                        "Citation Paper Authors": "Authors:Alin Deutsch, Yuliang Li, Victor Vianu"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1709.03949v1": {
            "Paper Title": "Skyline Queries in O(1) time?",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.03685v1": {
            "Paper Title": "Optimal On The Fly Index Selection in Polynomial Time",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.00700v1": {
            "Paper Title": "Generating Custom Code for Efficient Query Execution on Heterogeneous\n  Processors",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.00535v4": {
            "Paper Title": "Composing Differential Privacy and Secure Computation: A case study on\n  scaling private record linkage",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.09299v1": {
            "Paper Title": "Distributed Holistic Clustering on Linked Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.09171v1": {
            "Paper Title": "Enforcing Privacy in Cloud Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.08197v1": {
            "Paper Title": "Cross-Age LFW: A Database for Studying Cross-Age Face Recognition in\n  Unconstrained Environments",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.08191v1": {
            "Paper Title": "T-DB: Toward Fully Functional Transparent Encrypted Databases in DBaaS\n  Framework",
            "Sentences": []
        },
        "http://arxiv.org/abs/1709.01142v1": {
            "Paper Title": "Implementation and Evaluation of a Framework to calculate Impact\n  Measures for Wikipedia Authors",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.07975v1": {
            "Paper Title": "Plausible Deniability for Privacy-Preserving Data Synthesis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.07859v1": {
            "Paper Title": "LevelHeaded: Making Worst-Case Optimal Joins Work in the Common Case",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.00205v2": {
            "Paper Title": "Keyword Search on RDF Graphs - A Query Graph Assembly Approach",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08288v2": {
            "Paper Title": "Select Your Questions Wisely: For Entity Resolution With Crowd Errors",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": "designed crowdsourcing systems based on a probabilistic frame-\nwork, but does not employ transitivity to reduce the crowdsourcing\ncost. Wang et. al. ",
                    "Citation Text": "J. Wang, G. Li, T. Kraska, M. J. Franklin, and J. Feng. Leveraging Transitive\nRelations for Crowdsourced Joins. In SIGMOD , 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1408.6916",
                        "Citation Paper Title": "Title:Leveraging Transitive Relations for Crowdsourced Joins",
                        "Citation Paper Abstract": "Abstract:The development of crowdsourced query processing systems has recently attracted a significant attention in the database community. A variety of crowdsourced queries have been investigated. In this paper, we focus on the crowdsourced join query which aims to utilize humans to find all pairs of matching objects from two collections. As a human-only solution is expensive, we adopt a hybrid human-machine approach which first uses machines to generate a candidate set of matching pairs, and then asks humans to label the pairs in the candidate set as either matching or non-matching. Given the candidate pairs, existing approaches will publish all pairs for verification to a crowdsourcing platform. However, they neglect the fact that the pairs satisfy transitive relations. As an example, if $o_1$ matches with $o_2$, and $o_2$ matches with $o_3$, then we can deduce that $o_1$ matches with $o_3$ without needing to crowdsource $(o_1, o_3)$. To this end, we study how to leverage transitive relations for crowdsourced joins. We propose a hybrid transitive-relations and crowdsourcing labeling framework which aims to crowdsource the minimum number of pairs to label all the candidate pairs. We prove the optimal labeling order in an ideal setting and propose a heuristic labeling order in practice. We devise a parallel labeling algorithm to efficiently crowdsource the pairs following the order. We evaluate our approaches in both simulated environment and a real crowdsourcing platform. Experimental results show that our approaches with transitive relations can save much more money and time than existing methods, with a little loss in the result quality.",
                        "Citation Paper Authors": "Authors:Jiannan Wang, Guoliang Li, Tim Kraska, Michael J. Franklin, Jianhua Feng"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1708.04517v2": {
            "Paper Title": "Privacy-Preserving Mechanisms for Parametric Survival Analysis with\n  Weibull Distribution",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.07436v2": {
            "Paper Title": "Differentially Private Regression for Discrete-Time Survival Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.07308v1": {
            "Paper Title": "Ease.ml: Towards Multi-tenant Resource Sharing for Machine Learning\n  Workloads",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.06884v1": {
            "Paper Title": "Big Data Meets HPC Log Analytics: Scalable Approach to Understanding\n  Systems at Extreme Scale",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.06574v1": {
            "Paper Title": "S4: A New Secure Scheme for Enforcing Privacy in Cloud Data Warehouses",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.06521v1": {
            "Paper Title": "Strider-lsa: Massive RDF Stream Reasoning in the Cloud",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": "follows on the work\nof RDFox but considers a distributed approach. Nevertheless,\nthe system is not fault tolerant and does not addresses stream\nprocessing. The Kognac system ",
                    "Citation Text": "J. Urbani, S. Dutta, S. Gurajada, and G. Weikum. KOGNAC: ef\ufb01cient\nencoding of large knowledge graphs. CoRR , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1604.04795",
                        "Citation Paper Title": "Title:KOGNAC: Efficient Encoding of Large Knowledge Graphs",
                        "Citation Paper Abstract": "Abstract:Many Web applications require efficient querying of large Knowledge Graphs (KGs). We propose KOGNAC, a dictionary-encoding algorithm designed to improve SPARQL querying with a judicious combination of statistical and semantic techniques. In KOGNAC, frequent terms are detected with a frequency approximation algorithm and encoded to maximise compression. Infrequent terms are semantically grouped into ontological classes and encoded to increase data locality. We evaluated KOGNAC in combination with state-of-the-art RDF engines, and observed that it significantly improves SPARQL querying on KGs with up to 1B edges.",
                        "Citation Paper Authors": "Authors:Jacopo Urbani, Sourav Dutta, Sairam Gurajada, Gerhard Weikum"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1708.05926v1": {
            "Paper Title": "Tamper-Evident Complex Genomic Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.00115v2": {
            "Paper Title": "Ontological Multidimensional Data Models and Contextual Data Qality",
            "Sentences": [
                {
                    "Sentence ID": 75,
                    "Sentence": ".\nUnlike sticky programs, for complexity-theoretic reasons, WSprograms do not allow FO rewritabil-\nity for CQA. However, a hybrid algorithm is proposed in ",
                    "Citation Text": "Milani, M., Bertossi, L. and Cal `\u0131, A. A Hybrid Approach to /Q_uery Answering under Expressive Datalog\u0006. InProc. of\nthe International Conference on Web Reasoning and Rule Systems (RR) , Springer LNCS 9898, 2016, pp. 144-158.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1604.06770",
                        "Citation Paper Title": "Title:A Hybrid Approach to Query Answering under Expressive Datalog+/-",
                        "Citation Paper Abstract": "Abstract:Datalog+/- is a family of ontology languages that combine good computational properties with high expressive power. Datalog+/- languages are provably able to capture the most relevant Semantic Web languages. In this paper we consider the class of weakly-sticky (WS) Datalog+/- programs, which allow for certain useful forms of joins in rule bodies as well as extending the well-known class of weakly-acyclic TGDs. So far, only non-deterministic algorithms were known for answering queries on WS Datalog+/- programs. We present novel deterministic query answering algorithms under WS Datalog+/-. In particular, we propose: (1) a bottom-up grounding algorithm based on a query-driven chase, and (2) a hybrid approach based on transforming a WS program into a so-called sticky one, for which query rewriting techniques are known. We discuss how our algorithms can be optimized and effectively applied for query answering in real-world scenarios.",
                        "Citation Paper Authors": "Authors:Mostafa Milani, Andrea Cali, Leopoldo Bertossi"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1703.02529v3": {
            "Paper Title": "NoScope: Optimizing Neural Network Queries over Video at Scale",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.02536v1": {
            "Paper Title": "A Framework for Inferring Causality from Multi-Relational Observational\n  Data using Conditional Independence",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.02125v1": {
            "Paper Title": "T-Crowd: Effective Crowdsourcing for Tabular Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.02029v1": {
            "Paper Title": "From Appearance to Essence: Comparing Truth Discovery Methods without\n  Using Ground Truth",
            "Sentences": []
        },
        "http://arxiv.org/abs/1708.02018v1": {
            "Paper Title": "SmartMTD: A Graph-Based Approach for Effective Multi-Truth Discovery",
            "Sentences": [
                {
                    "Sentence ID": 24,
                    "Sentence": ": the original version of this method is ap-\nplied,which also adoptsmutualexclusion.\nThe second type of baselines consists of three existing MTD\nmethods:\n\u2022LTM ",
                    "Citation Text": "Bo Zhao, Benjamin IP Rubinstein, Jim Gemmell, and Jiawe i Han. 2012. A\nbayesian approach to discovering truth from con\ufb02icting sou rces for data inte-\ngration.Proc.theVLDB Endowment 5, 6(2012), 550\u2013561.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1203.0058",
                        "Citation Paper Title": "Title:A Bayesian Approach to Discovering Truth from Conflicting Sources for Data Integration",
                        "Citation Paper Abstract": "Abstract:In practical data integration systems, it is common for the data sources being integrated to provide conflicting information about the same entity. Consequently, a major challenge for data integration is to derive the most complete and accurate integrated records from diverse and sometimes conflicting sources. We term this challenge the truth finding problem. We observe that some sources are generally more reliable than others, and therefore a good model of source quality is the key to solving the truth finding problem. In this work, we propose a probabilistic graphical model that can automatically infer true records and source quality without any supervision. In contrast to previous methods, our principled approach leverages a generative process of two types of errors (false positive and false negative) by modeling two different aspects of source quality. In so doing, ours is also the first approach designed to merge multi-valued attribute types. Our method is scalable, due to an efficient sampling-based inference algorithm that needs very few iterations in practice and enjoys linear time complexity, with an even faster incremental variant. Experiments on two real world datasets show that our new method outperforms existing state-of-the-art approaches to the truth finding problem.",
                        "Citation Paper Authors": "Authors:Bo Zhao, Benjamin I. P. Rubinstein, Jim Gemmell, Jiawei Han"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1708.00363v1": {
            "Paper Title": "An Analytical Study of Large SPARQL Query Logs",
            "Sentences": [
                {
                    "Sentence ID": 5,
                    "Sentence": ". In order to generate\nquery workloads containing the aforementioned types\nof queries, we have used gMark ",
                    "Citation Text": "G. Bagan, A. Bonifati, R. Ciucanu, G. H. L.\nFletcher, A. Lemay, and N. Advokaat. gmark:\nSchema-driven generation of graphs and queries.\nIEEE Trans. Knowl. Data Eng. , 29(4):856\u2013869,\n2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1511.08386",
                        "Citation Paper Title": "Title:gMark: Schema-Driven Generation of Graphs and Queries",
                        "Citation Paper Abstract": "Abstract:Massive graph data sets are pervasive in contemporary application domains. Hence, graph database systems are becoming increasingly important. In the experimental study of these systems, it is vital that the research community has shared solutions for the generation of database instances and query workloads having predictable and controllable properties. In this paper, we present the design and engineering principles of gMark, a domain- and query language-independent graph instance and query workload generator. A core contribution of gMark is its ability to target and control the diversity of properties of both the generated instances and the generated workloads coupled to these instances. Further novelties include support for regular path queries, a fundamental graph query paradigm, and schema-driven selectivity estimation of queries, a key feature in controlling workload chokepoints. We illustrate the flexibility and practical usability of gMark by showcasing the framework's capabilities in generating high quality graphs and workloads, and its ability to encode user-defined schemas across a variety of application domains.",
                        "Citation Paper Authors": "Authors:Guillaume Bagan, Angela Bonifati, Radu Ciucanu, George H. L. Fletcher, Aur\u00e9lien Lemay, Nicky Advokaat"
                    }
                },
                {
                    "Sentence ID": 14,
                    "Sentence": ", but becomes Ptimeif their\nhypertree width is bounded by a constant ",
                    "Citation Text": "G. Gottlob, N. Leone, and F. Scarcello. Hypertree\ndecompositions and tractable queries. J. Comput.\nSyst. Sci. , 64(3):579\u2013627, 2002.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:cs/9812022",
                        "Citation Paper Title": "Title:Hypertree Decompositions and Tractable Queries",
                        "Citation Paper Abstract": "Abstract:  Several important decision problems on conjunctive queries (CQs) are NP-complete in general but become tractable, and actually highly parallelizable, if restricted to acyclic or nearly acyclic queries. Examples are the evaluation of Boolean CQs and query containment. These problems were shown tractable for conjunctive queries of bounded treewidth and of bounded degree of cyclicity. The so far most general concept of nearly acyclic queries was the notion of queries of bounded query-width introduced by Chekuri and Rajaraman (1997). While CQs of bounded query width are tractable, it remained unclear whether such queries are efficiently recognizable. Chekuri and Rajaraman stated as an open problem whether for each constant k it can be determined in polynomial time if a query has query width less than or equal to k. We give a negative answer by proving this problem NP-complete (specifically, for k=4). In order to circumvent this difficulty, we introduce the new concept of hypertree decomposition of a query and the corresponding notion of hypertree width. We prove: (a) for each k, the class of queries with query width bounded by k is properly contained in the class of queries whose hypertree width is bounded by k; (b) unlike query width, constant hypertree-width is efficiently recognizable; (c) Boolean queries of constant hypertree width can be efficiently evaluated.",
                        "Citation Paper Authors": "Authors:G. Gottlob, N. Leone, F. Scarcello"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1707.09930v1": {
            "Paper Title": "Debugging Transactions and Tracking their Provenance with Reenactment",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.01148v3": {
            "Paper Title": "Runtime Optimization of Join Location in Parallel Data Management\n  Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.01770v2": {
            "Paper Title": "Enabling Smart Data: Noise filtering in Big Data classification",
            "Sentences": [
                {
                    "Sentence ID": 5,
                    "Sentence": ".\n\u000fOn the other hand, data level approaches (also called \flters ) try to develop\nstrategies to cleanse the dataset as a previous step to the \ft of the classi\fer,\nby either creating ensembles of classi\fers ",
                    "Citation Text": "C. E. Brodley, M. A. Friedl, Identifying Mislabeled Training Data, Journal\nof Arti\fcial Intelligence Research 11 (1999) 131{167.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1106.0219",
                        "Citation Paper Title": "Title:Identifying Mislabeled Training Data",
                        "Citation Paper Abstract": "Abstract:This paper presents a new approach to identifying and    eliminating mislabeled training instances for supervised learning. The    goal of this approach is to improve classification accuracies produced    by learning algorithms by improving the quality of the training data.    Our approach uses a set of learning algorithms to create classifiers    that serve as noise filters for the training data.  We evaluate single    algorithm, majority vote and consensus filters on five datasets that    are prone to labeling errors.  Our experiments illustrate that    filtering significantly improves classification accuracy for noise    levels up to 30 percent.  An analytical and empirical evaluation of    the precision of our approach shows that consensus filters are    conservative at throwing away good data at the expense of retaining    bad data and that majority filters are better at detecting bad data at    the expense of throwing away good data.  This suggests that for    situations in which there is a paucity of data, consensus filters are    preferable, whereas majority vote filters are preferable for    situations with an abundance of data.",
                        "Citation Paper Authors": "Authors:C. E. Brodley, M. A. Friedl"
                    }
                },
                {
                    "Sentence ID": 32,
                    "Sentence": ". While feature selection,\ndiscretization or imbalanced algorithms to cope with the high dimensionality\nhave drawn the attention of current Big Data frameworks (such as Spark's ML-\nlib ",
                    "Citation Text": "X. Meng, J. Bradley, B. Yavuz, E. Sparks, S. Venkataraman, D. Liu, J. Free-\nman, D. Tsai, M. Amde, S. Owen, D. Xin, R. Xin, M. J. Franklin, R. Zadeh,\nM. Zaharia, A. Talwalkar, Mllib: Machine learning in apache spark, Journal\nof Machine Learning Research 17 (34) (2016) 1{7.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1505.06807",
                        "Citation Paper Title": "Title:MLlib: Machine Learning in Apache Spark",
                        "Citation Paper Abstract": "Abstract:Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed.",
                        "Citation Paper Authors": "Authors:Xiangrui Meng, Joseph Bradley, Burak Yavuz, Evan Sparks, Shivaram Venkataraman, Davies Liu, Jeremy Freeman, DB Tsai, Manish Amde, Sean Owen, Doris Xin, Reynold Xin, Michael J. Franklin, Reza Zadeh, Matei Zaharia, Ameet Talwalkar"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1707.08482v1": {
            "Paper Title": "Confidentiality enforcement by hybrid control of information flows",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.08272v1": {
            "Paper Title": "A Change-Sensitive Algorithm for Maintaining Maximal Bicliques in a\n  Dynamic Bipartite Graph",
            "Sentences": [
                {
                    "Sentence ID": 8,
                    "Sentence": "present methods\nfor maintaining k-cores andk-trusses in a dynamic graph,\nand ",
                    "Citation Text": "A. Das, M. Svendsen, and S. Tirthapura. Change-sensitive algo-\nrithms for maintaining maximal cliques in a dynamic graph. arXiv\npreprint arXiv:1601.06311 , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1707.08272",
                        "Citation Paper Title": "Title:A Change-Sensitive Algorithm for Maintaining Maximal Bicliques in a Dynamic Bipartite Graph",
                        "Citation Paper Abstract": "Abstract:We consider the maintenance of maximal bicliques from a dynamic bipartite graph that changes over time due to the addition or deletion of edges. When the set of edges in a graph changes, we are interested in knowing the change in the set of maximal bicliques (the \"change\"), rather than in knowing the set of maximal bicliques that remain unaffected. The challenge in an efficient algorithm is to enumerate the change without explicitly enumerating the set of all maximal bicliques. In this work, we present (1) near-tight bounds on the magnitude of change in the set of maximal bicliques of a graph, due to a change in the edge set (2) a \"change-sensitive\" algorithm for enumerating the change in the set of maximal bicliques, whose time complexity is proportional to the magnitude of change that actually occurred in the set of maximal bicliques in the graph. To our knowledge, these are the first algorithms for enumerating maximal bicliques in a dynamic graph, with such provable performance guarantees. Our algorithms are easy to implement, and experimental results show that their performance exceeds that of current baseline implementations by orders of magnitude.",
                        "Citation Paper Authors": "Authors:Apurba Das, Srikanta Tirthapura"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1708.00497v1": {
            "Paper Title": "Car sharing through the data analysis lens",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.07794v1": {
            "Paper Title": "Relational Learning and Feature Extraction by Querying over\n  Heterogeneous Information Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.05340v2": {
            "Paper Title": "PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge\n  Graphs via Entity Linking",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.05681v2": {
            "Paper Title": "Fixpoint Semantics and Optimization of Recursive Datalog Programs with\n  Aggregates",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.03602v1": {
            "Paper Title": "Using RDF Summary Graph For Keyword-based Semantic Searches",
            "Sentences": []
        },
        "http://arxiv.org/abs/1707.00904v1": {
            "Paper Title": "Sequential Checking: Reallocation-Free Data-Distribution Algorithm for\n  Scale-out Storage",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.02996v2": {
            "Paper Title": "ROSA: R Optimizations with Static Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.03022v2": {
            "Paper Title": "Precision Interfaces",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.05136v2": {
            "Paper Title": "The Causality/Repair Connection in Databases: Causality-Programs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.08259v1": {
            "Paper Title": "Relational Algebra for In-Database Process Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.00617v3": {
            "Paper Title": "In Search of an Entity Resolution OASIS: Optimal Asymptotic Sequential\n  Importance Sampling",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.07835v1": {
            "Paper Title": "A Semantic Cross-Species Derived Data Management Application",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.06697v1": {
            "Paper Title": "Index Search Algorithms for Databases and Modern CPUs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.06664v1": {
            "Paper Title": "Arrays of (locality-sensitive) Count Estimators (ACE): High-Speed\n  Anomaly Detection via Cache Lookups",
            "Sentences": [
                {
                    "Sentence ID": 40,
                    "Sentence": ": This is a\nmoreadvancedversionofLOF.LoOPusesdistance/density\nbased algorithm similar to LOF to detect outliers, but\nwith statistical methods to achieve better result stabil-\nity. We use the implementation provided by ELKI.\n7.LDOF (Local Distance based Outlier Factor) ",
                    "Citation Text": "K. Zhang, M. Hutter, and H. Jin. A new local\ndistance-based outlier detection approach for scattered\nreal-world data. Advances in knowledge discovery and\ndata mining , pages 813\u2013822, 2009.\n14",
                    "Citation": {
                        "Citation Paper ID": "arXiv:0903.3257",
                        "Citation Paper Title": "Title:A New Local Distance-Based Outlier Detection Approach for Scattered Real-World Data",
                        "Citation Paper Abstract": "Abstract:  Detecting outliers which are grossly different from or inconsistent with the remaining dataset is a major challenge in real-world KDD applications. Existing outlier detection methods are ineffective on scattered real-world datasets due to implicit data patterns and parameter setting issues. We define a novel \"Local Distance-based Outlier Factor\" (LDOF) to measure the {outlier-ness} of objects in scattered datasets which addresses these issues. LDOF uses the relative location of an object to its neighbours to determine the degree to which the object deviates from its neighbourhood. Properties of LDOF are theoretically analysed including LDOF's lower bound and its false-detection probability, as well as parameter settings. In order to facilitate parameter settings in real-world applications, we employ a top-n technique in our outlier detection approach, where only the objects with the highest LDOF values are regarded as outliers. Compared to conventional approaches (such as top-n KNN and top-n LOF), our method top-n LDOF is more effective at detecting outliers in scattered data. It is also easier to set parameters, since its performance is relatively stable over a large range of parameter values, as illustrated by experimental results on both real-world and synthetic datasets.",
                        "Citation Paper Authors": "Authors:Ke Zhang, Marcus Hutter, Huidong Jin"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1706.05714v1": {
            "Paper Title": "Evolutionary Data Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.03968v2": {
            "Paper Title": "Asynchronous Graph Pattern Matching on Multiprocessor Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.03374v1": {
            "Paper Title": "DenseAlert: Incremental Dense-Subtensor Detection in Tensor Streams",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.07538v2": {
            "Paper Title": "Infrastructure for Usable Machine Learning: The Stanford DAWN Project",
            "Sentences": [
                {
                    "Sentence ID": 1,
                    "Sentence": ". In practice, we have found\nthat, when combined with SIMD-optimized execution this optimized join is fast, matching optimized engines\nfor each of SQL and graphs ",
                    "Citation Text": "C. R. Aberger, S. Tu, K. Olukotun, and C. R \u00b4e. EmptyHeaded: A relational engine for graph processing. In\nSIGMOD , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1503.02368",
                        "Citation Paper Title": "Title:EmptyHeaded: A Relational Engine for Graph Processing",
                        "Citation Paper Abstract": "Abstract:There are two types of high-performance graph processing engines: low- and high-level engines. Low-level engines (Galois, PowerGraph, Snap) provide optimized data structures and computation models but require users to write low-level imperative code, hence ensuring that efficiency is the burden of the user. In high-level engines, users write in query languages like datalog (SociaLite) or SQL (Grail). High-level engines are easier to use but are orders of magnitude slower than the low-level graph engines. We present EmptyHeaded, a high-level engine that supports a rich datalog-like query language and achieves performance comparable to that of low-level engines. At the core of EmptyHeaded's design is a new class of join algorithms that satisfy strong theoretical guarantees but have thus far not achieved performance comparable to that of specialized graph processing engines. To achieve high performance, EmptyHeaded introduces a new join engine architecture, including a novel query optimizer and data layouts that leverage single-instruction multiple data (SIMD) parallelism. With this architecture, EmptyHeaded outperforms high-level approaches by up to three orders of magnitude on graph pattern queries, PageRank, and Single-Source Shortest Paths (SSSP) and is an order of magnitude faster than many low-level baselines. We validate that EmptyHeaded competes with the best-of-breed low-level engine (Galois), achieving comparable performance on PageRank and at most 3x worse performance on SSSP.",
                        "Citation Paper Authors": "Authors:Christopher R. Aberger, Susan Tu, Kunle Olukotun, Christopher R\u00e9"
                    }
                },
                {
                    "Sentence ID": 2,
                    "Sentence": "that produces high-quality models from low-quality rules. We\nare also pursuing new lines of research in weakly supervised ML to improve model quality without manual user\nintervention, such as feature discovery [24, 25] and structure learning ",
                    "Citation Text": "S. H. Bach, B. D. He, A. Ratner, and C. R \u00b4e. Learning the structure of generative models without labeled data. In\nICML , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1703.00854",
                        "Citation Paper Title": "Title:Learning the Structure of Generative Models without Labeled Data",
                        "Citation Paper Abstract": "Abstract:Curating labeled training data has become the primary bottleneck in machine learning. Recent frameworks address this bottleneck with generative models to synthesize labels at scale from weak supervision sources. The generative model's dependency structure directly affects the quality of the estimated labels, but selecting a structure automatically without any labeled data is a distinct challenge. We propose a structure estimation method that maximizes the $\\ell_1$-regularized marginal pseudolikelihood of the observed data. Our analysis shows that the amount of unlabeled data required to identify the true structure scales sublinearly in the number of possible dependencies for a broad class of models. Simulations show that our method is 100$\\times$ faster than a maximum likelihood approach and selects $1/4$ as many extraneous dependencies. We also show that our method provides an average of 1.5 F1 points of improvement over existing, user-developed information extraction applications on real-world data such as PubMed journal abstracts.",
                        "Citation Paper Authors": "Authors:Stephen H. Bach, Bryan He, Alexander Ratner, Christopher R\u00e9"
                    }
                },
                {
                    "Sentence ID": 17,
                    "Sentence": ". We have obtained promising\nearly results with a new system called Snorkel ",
                    "Citation Text": "A. J. Ratner, S. H. Bach, H. E. Ehrenberg, and C. R \u00b4e. Snorkel: Fast training set generation for information\nextraction. In SIGMOD , 2017. https://github.com/HazyResearch/snorkel .",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1711.10160",
                        "Citation Paper Title": "Title:Snorkel: Rapid Training Data Creation with Weak Supervision",
                        "Citation Paper Abstract": "Abstract:Labeling training data is increasingly the largest bottleneck in deploying machine learning systems. We present Snorkel, a first-of-its-kind system that enables users to train state-of-the-art models without hand labeling any training data. Instead, users write labeling functions that express arbitrary heuristics, which can have unknown accuracies and correlations. Snorkel denoises their outputs without access to ground truth by incorporating the first end-to-end implementation of our recently proposed machine learning paradigm, data programming. We present a flexible interface layer for writing labeling functions based on our experience over the past year collaborating with companies, agencies, and research labs. In a user study, subject matter experts build models 2.8x faster and increase predictive performance an average 45.5% versus seven hours of hand labeling. We study the modeling tradeoffs in this new setting and propose an optimizer for automating tradeoff decisions that gives up to 1.8x speedup per pipeline execution. In two collaborations, with the U.S. Department of Veterans Affairs and the U.S. Food and Drug Administration, and on four open-source text and image data sets representative of other deployments, Snorkel provides 132% average improvements to predictive performance over prior heuristic approaches and comes within an average 3.60% of the predictive performance of large hand-curated training sets.",
                        "Citation Paper Authors": "Authors:Alexander Ratner, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, Christopher R\u00e9"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1706.02562v1": {
            "Paper Title": "Pain-Free Random Differential Privacy with Sensitivity Sampling",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.02473v1": {
            "Paper Title": "Securing Databases from Probabilistic Inference",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.02109v1": {
            "Paper Title": "Guided Interaction Exploration in Artifact-centric Process Models",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.00485v3": {
            "Paper Title": "Are Key-Foreign Key Joins Safe to Avoid when Learning High-Capacity\n  Classifiers?",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.00757v1": {
            "Paper Title": "Efficient Detection of Points of Interest from Georeferenced Visual\n  Content",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.00327v1": {
            "Paper Title": "One button machine for automating feature engineering in relational\n  databases",
            "Sentences": [
                {
                    "Sentence ID": 10,
                    "Sentence": "is the most recent work which uses stacking and meta-\ndata to assist model selection and tuning. TPOT ",
                    "Citation Text": "R. S. Olson, N. Bartley, R. J. Urbanowicz, and J. H. Moore. Evaluation\nof a tree-based pipeline optimization tool for automating data science. In\nProceedings of the Genetic and Evolutionary Computation Conference\n2016 , GECCO \u201916, pages 485\u2013492, New York, NY , USA, 2016. ACM.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1603.06212",
                        "Citation Paper Title": "Title:Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science",
                        "Citation Paper Abstract": "Abstract:As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning---pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design.",
                        "Citation Paper Authors": "Authors:Randal S. Olson, Nathan Bartley, Ryan J. Urbanowicz, Jason H. Moore"
                    }
                },
                {
                    "Sentence ID": 2,
                    "Sentence": "are among\nthe \ufb01rst works trying to \ufb01nd the best combination of data\npreprocessing, hyper-parameter tuning and model selection.\nBoth works are based on Bayesian optimization ",
                    "Citation Text": "E. Brochu, V . M. Cora, and N. De Freitas. A tutorial on bayesian\noptimization of expensive cost functions, with application to active\nuser modeling and hierarchical reinforcement learning. arXiv preprint\narXiv:1012.2599 , 2010.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1012.2599",
                        "Citation Paper Title": "Title:A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning",
                        "Citation Paper Abstract": "Abstract:We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.",
                        "Citation Paper Authors": "Authors:Eric Brochu, Vlad M. Cora, Nando de Freitas"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1705.09276v2": {
            "Paper Title": "Synthesizing Mapping Relationships Using Table Corpus",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.00080v3": {
            "Paper Title": "Efficient Computation of Subspace Skyline over Categorical Domains",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.03856v2": {
            "Paper Title": "Probabilistic Database Summarization for Interactive Data Exploration",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.08317v1": {
            "Paper Title": "A Cloud-based Service for Real-Time Performance Evaluation of NoSQL\n  Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08084v2": {
            "Paper Title": "Erasure Coding for Small Objects in In-Memory KV Storage",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.02855v2": {
            "Paper Title": "A Decision Tree Based Approach Towards Adaptive Profiling of Distributed\n  Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1706.05913v1": {
            "Paper Title": "Fusing restricted information",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.05720v1": {
            "Paper Title": "Subjective Knowledge Acquisition and Enrichment Powered By Crowdsourcing",
            "Sentences": [
                {
                    "Sentence ID": 28,
                    "Sentence": "present approaches that use the wisdom of crowd to perform taxon-\nomy construction. Crowdsourcing also proved to have good perfor-\nmance in applications such as entity resolution ",
                    "Citation Text": "J. Wang, T. Kraska, M. J. Franklin, and J. Feng. CrowdER:\nCrowdsourcing entity resolution. PVLDB , 5(11):1483\u20131494,\n2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1208.1927",
                        "Citation Paper Title": "Title:CrowdER: Crowdsourcing Entity Resolution",
                        "Citation Paper Abstract": "Abstract:Entity resolution is central to data integration and data cleaning. Algorithmic approaches have been improving in quality, but remain far from perfect. Crowdsourcing platforms offer a more accurate but expensive (and slow) way to bring human insight into the process. Previous work has proposed batching verification tasks for presentation to human workers but even with batching, a human-only approach is infeasible for data sets of even moderate size, due to the large numbers of matches to be tested. Instead, we propose a hybrid human-machine approach in which machines are used to do an initial, coarse pass over all the data, and people are used to verify only the most likely matching pairs. We show that for such a hybrid system, generating the minimum number of verification tasks of a given size is NP-Hard, but we develop a novel two-tiered heuristic approach for creating batched tasks. We describe this method, and present the results of extensive experiments on real data sets using a popular crowdsourcing platform. The experiments show that our hybrid approach achieves both good efficiency and high accuracy compared to machine-only or human-only alternatives.",
                        "Citation Paper Authors": "Authors:Jiannan Wang, Tim Kraska, Michael J. Franklin, Jianhua Feng"
                    }
                },
                {
                    "Sentence ID": 16,
                    "Sentence": "are introduced in Section 7. We conclude our work\nin Section 8.\n2. PROBLEM DEFINITION\nA knowledge base is a repository of storing entities and relations\nin a real world scenario. Similar with ",
                    "Citation Text": "S. Lacoste-Julien, K. Palla, A. Davies, G. Kasneci,\nT. Graepel, and Z. Ghahramani. Sigma: simple greedy\nmatching for aligning large knowledge bases. In The 19th\nACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, KDD 2013, Chicago, IL, USA,\nAugust 11-14, 2013 , pages 572\u2013580, 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1207.4525",
                        "Citation Paper Title": "Title:SiGMa: Simple Greedy Matching for Aligning Large Knowledge Bases",
                        "Citation Paper Abstract": "Abstract:The Internet has enabled the creation of a growing number of large-scale knowledge bases in a variety of domains containing complementary information. Tools for automatically aligning these knowledge bases would make it possible to unify many sources of structured knowledge and answer complex queries. However, the efficient alignment of large-scale knowledge bases still poses a considerable challenge. Here, we present Simple Greedy Matching (SiGMa), a simple algorithm for aligning knowledge bases with millions of entities and facts. SiGMa is an iterative propagation algorithm which leverages both the structural information from the relationship graph as well as flexible similarity measures between entity properties in a greedy local search, thus making it scalable. Despite its greedy nature, our experiments indicate that SiGMa can efficiently match some of the world's largest knowledge bases with high precision. We provide additional experiments on benchmark datasets which demonstrate that SiGMa can outperform state-of-the-art approaches both in accuracy and efficiency.",
                        "Citation Paper Authors": "Authors:Simon Lacoste-Julien, Konstantina Palla, Alex Davies, Gjergji Kasneci, Thore Graepel, Zoubin Ghahramani"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1705.05688v1": {
            "Paper Title": "Strider: A Hybrid Adaptive Distributed RDF Stream Processing Engine",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.04928v1": {
            "Paper Title": "Big Data: Challenges, Opportunities and Realities",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.04915v1": {
            "Paper Title": "Discovering Multiple Truths with a Hybrid Model",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.00761v1": {
            "Paper Title": "F-tree: an algorithm for clustering transactional data using frequency\n  tree",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.06868v2": {
            "Paper Title": "A Real-Time Framework for Task Assignment in Hyperlocal Spatial\n  Crowdsourcing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.07405v1": {
            "Paper Title": "The Flexible Group Spatial Keyword Query",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.06860v1": {
            "Paper Title": "Location Privacy in Spatial Crowdsourcing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.04599v1": {
            "Paper Title": "A novel approach for fast mining frequent itemsets use N-list structure\n  based on MapReduce",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.04302v1": {
            "Paper Title": "On a Distributed Approach for Density-based Clustering",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.04301v1": {
            "Paper Title": "A Tree-based Approach for Detecting Redundant Business Rules in very\n  Large Financial Datasets",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.03978v1": {
            "Paper Title": "Reverse k Nearest Neighbor Search over Trajectories",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.02809v2": {
            "Paper Title": "NetClus: A Scalable Framework for Locating Top-K Sites for Placement of\n  Trajectory-Aware Services",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.02384v1": {
            "Paper Title": "PreCog: Improving Crowdsourced Data Quality Before Acquisition",
            "Sentences": [
                {
                    "Sentence ID": 76,
                    "Sentence": "show that this is less e\ufb00ective than a more customized ap-\nproach. An alternative is to use existing model explanation\nalgorithms ",
                    "Citation Text": "M. T. Ribeiro, S. Singh, and C. Guestrin. \"why should I\ntrust you?\": Explaining the predictions of any classi\ufb01er. In\nSIGKDD , 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1602.04938",
                        "Citation Paper Title": "Title:\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier",
                        "Citation Paper Abstract": "Abstract:Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.",
                        "Citation Paper Authors": "Authors:Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1704.01788v1": {
            "Paper Title": "A Survey of Skyline Query Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.01286v1": {
            "Paper Title": "Dynamic Conjunctive Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.01087v1": {
            "Paper Title": "Probabilistic Search for Structured Data via Probabilistic Programming\n  and Nonparametric Bayes",
            "Sentences": []
        },
        "http://arxiv.org/abs/1705.02936v1": {
            "Paper Title": "Link Prediction using Top-$k$ Shortest Distances",
            "Sentences": []
        },
        "http://arxiv.org/abs/1704.00630v1": {
            "Paper Title": "Towards a property graph generator for benchmarking",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.10692v1": {
            "Paper Title": "Knowledge Rich Natural Language Queries over Structured Biological\n  Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.09823v1": {
            "Paper Title": "Variance-based Clustering Technique for Distributed Data Mining\n  Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.09807v1": {
            "Paper Title": "Grid-based Approaches for Distributed Data Mining Applications",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.09141v1": {
            "Paper Title": "A Framework for Assessing Achievability of Data-Quality Constraints",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.09218v1": {
            "Paper Title": "DataSlicer: Task-Based Data Selection for Visual Data Exploration",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.08732v1": {
            "Paper Title": "80 New Packages to Mine Database Query Logs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.08668v1": {
            "Paper Title": "Enumerating k-Vertex Connected Components in Large Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.08614v1": {
            "Paper Title": "GraphZip: Dictionary-based Compression for Mining Graph Streams",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.08273v1": {
            "Paper Title": "An Asymptotically Tighter Bound on Sampling for Frequent Itemsets Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.08219v1": {
            "Paper Title": "Flare: Native Compilation for Heterogeneous Workloads in Apache Spark",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.07920v1": {
            "Paper Title": "Changing Fashion Cultures",
            "Sentences": [
                {
                    "Sentence ID": 15,
                    "Sentence": ". This large-scale\ndatabase strengthened attribute estimation through a data -\ndriven deep learned architecture. Liu et al. veri\ufb01ed that\nfashion landmarks improve the attribute recognition in a\nfashion database ",
                    "Citation Text": "Z. Liu, S. Yan, P. Luo, X. Wang, and X. Tang. Fashion land-\nmark detection in the wild. European Conference on Com-\nputer Vision (ECCV), 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1608.03049",
                        "Citation Paper Title": "Title:Fashion Landmark Detection in the Wild",
                        "Citation Paper Abstract": "Abstract:Visual fashion analysis has attracted many attentions in the recent years. Previous work represented clothing regions by either bounding boxes or human joints. This work presents fashion landmark detection or fashion alignment, which is to predict the positions of functional key points defined on the fashion items, such as the corners of neckline, hemline, and cuff. To encourage future studies, we introduce a fashion landmark dataset with over 120K images, where each image is labeled with eight landmarks. With this dataset, we study fashion alignment by cascading multiple convolutional neural networks in three stages. These stages gradually improve the accuracies of landmark predictions. Extensive experiments demonstrate the effectiveness of the proposed method, as well as its generalization ability to pose estimation. Fashion landmark is also compared to clothing bounding boxes and human joints in two applications, fashion attribute prediction and clothes retrieval, showing that fashion landmark is a more discriminative representation to understand fashion images.",
                        "Citation Paper Authors": "Authors:Ziwei Liu, Sijie Yan, Ping Luo, Xiaogang Wang, Xiaoou Tang"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1703.07795v1": {
            "Paper Title": "Hierarchical Summarization of Metric Changes",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.07213v1": {
            "Paper Title": "Efficient Analytical Queries on Semantic Web Data Cubes",
            "Sentences": [
                {
                    "Sentence ID": 16,
                    "Sentence": ". Moreover, the evaluation of\nqueries that only contain AND and UNION operators\nis already NP-complete, as proved in ",
                    "Citation Text": "M. Schmidt, M. Meier, G. Lausen, Foundations of SPARQL\nquery optimization, in: Proceedings of ICDT, ACM, New York,\nNY , 2010, pp. 4\u201333.\n19",
                    "Citation": {
                        "Citation Paper ID": "arXiv:0812.3788",
                        "Citation Paper Title": "Title:Foundations of SPARQL Query Optimization",
                        "Citation Paper Abstract": "Abstract:  The SPARQL query language is a recent W3C standard for processing RDF data, a format that has been developed to encode information in a machine-readable way. We investigate the foundations of SPARQL query optimization and (a) provide novel complexity results for the SPARQL evaluation problem, showing that the main source of complexity is operator OPTIONAL alone; (b) propose a comprehensive set of algebraic query rewriting rules; (c) present a framework for constraint-based SPARQL optimization based upon the well-known chase procedure for Conjunctive Query minimization. In this line, we develop two novel termination conditions for the chase. They subsume the strongest conditions known so far and do not increase the complexity of the recognition problem, thus making a larger class of both Conjunctive and SPARQL queries amenable to constraint-based optimization. Our results are of immediate practical interest and might empower any SPARQL query optimizer.",
                        "Citation Paper Authors": "Authors:Michael Schmidt, Michael Meier, Georg Lausen"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1703.05481v1": {
            "Paper Title": "Empirical Analysis on Comparing the Performance of Alpha Miner Algorithm\n  in SQL Query Language and NoSQL Column-Oriented Databases Using Apache\n  Phoenix",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.05160v1": {
            "Paper Title": "A New Unbiased and Efficient Class of LSH-Based Samplers and Estimators\n  for Partition Function Computation in Log-Linear Models",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.04290v1": {
            "Paper Title": "MTBase: Optimizing Cross-Tenant Database Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.04206v1": {
            "Paper Title": "Application of Bitcoin Data-Structures & Design Principles to Supply\n  Chain Management",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.00391v2": {
            "Paper Title": "A Hypercat-enabled Semantic Internet of Things Data Hub: Technical\n  Report",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.04057v1": {
            "Paper Title": "BLOCKBENCH: A Framework for Analyzing Private Blockchains",
            "Sentences": [
                {
                    "Sentence ID": 7,
                    "Sentence": "exploits the application-level protocol to surround the tar-\ngeted nodes with ones under the attacker's control. At the\nnetwork level, BGP hijacking ",
                    "Citation Text": "M. Apostolaki, A. Zohar, and L. Vanbever. Hijacking\nbitcoin: Large-scale network attacks on\ncrypto-currencies. https://arxiv.org/abs/1605.07524,\n2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1605.07524",
                        "Citation Paper Title": "Title:Hijacking Bitcoin: Routing Attacks on Cryptocurrencies",
                        "Citation Paper Abstract": "Abstract:As the most successful cryptocurrency to date, Bitcoin constitutes a target of choice for attackers. While many attack vectors have already been uncovered, one important vector has been left out though: attacking the currency via the Internet routing infrastructure itself. Indeed, by manipulating routing advertisements (BGP hijacks) or by naturally intercepting traffic, Autonomous Systems (ASes) can intercept and manipulate a large fraction of Bitcoin traffic.\nThis paper presents the first taxonomy of routing attacks and their impact on Bitcoin, considering both small-scale attacks, targeting individual nodes, and large-scale attacks, targeting the network as a whole. While challenging, we show that two key properties make routing attacks practical: (i) the efficiency of routing manipulation; and (ii) the significant centralization of Bitcoin in terms of mining and routing. Specifically, we find that any network attacker can hijack few (<100) BGP prefixes to isolate ~50% of the mining power---even when considering that mining pools are heavily multi-homed. We also show that on-path network attackers can considerably slow down block propagation by interfering with few key Bitcoin messages.\nWe demonstrate the feasibility of each attack against the deployed Bitcoin software. We also quantify their effectiveness on the current Bitcoin topology using data collected from a Bitcoin supernode combined with BGP routing data.\nThe potential damage to Bitcoin is worrying. By isolating parts of the network or delaying block propagation, attackers can cause a significant amount of mining power to be wasted, leading to revenue losses and enabling a wide range of exploits such as double spending. To prevent such effects in practice, we provide both short and long-term countermeasures, some of which can be deployed immediately.",
                        "Citation Paper Authors": "Authors:Maria Apostolaki, Aviv Zohar, Laurent Vanbever"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1703.02722v1": {
            "Paper Title": "Scaling Distributed Transaction Processing and Recovery based on\n  Dependency Logging",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.02638v1": {
            "Paper Title": "Constellation Queries over Big Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.02591v1": {
            "Paper Title": "Energy-Aware Disk Storage Management: Online Approach with Application\n  in DBMS",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.02475v1": {
            "Paper Title": "OrpheusDB: Bolt-on Versioning for Relational Databases",
            "Sentences": [
                {
                    "Sentence ID": 15,
                    "Sentence": "in\nthat it shares the concerns of minimizing storage and recreation\ncost; however, the paper considered the unstructured setting from\nan algorithmic viewpoint, and did not aim to build a full-\ufb02edged\ndataset versioning system. Lastly, Chavan et al. ",
                    "Citation Text": "A. Chavan, S. Huang, A. Deshpande, A. Elmore, S. Madden, and\nA. Parameswaran. Towards a uni\ufb01ed query language for provenance and\nversioning. In TaPP 15 , 2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1506.04815",
                        "Citation Paper Title": "Title:Towards a unified query language for provenance and versioning",
                        "Citation Paper Abstract": "Abstract:Organizations and teams collect and acquire data from various sources, such as social interactions, financial transactions, sensor data, and genome sequencers. Different teams in an organization as well as different data scientists within a team are interested in extracting a variety of insights which require combining and collaboratively analyzing datasets in diverse ways. DataHub is a system that aims to provide robust version control and provenance management for such a scenario. To be truly useful for collaborative data science, one also needs the ability to specify queries and analysis tasks over the versioning and the provenance information in a unified manner. In this paper, we present an initial design of our query language, called VQuel, that aims to support such unified querying over both types of information, as well as the intermediate and final results of analyses. We also discuss some of the key language design and implementation challenges moving forward.",
                        "Citation Paper Authors": "Authors:Amit Chavan, Silu Huang, Amol Deshpande, Aaron Elmore, Samuel Madden, Aditya Parameswaran"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1703.02212v1": {
            "Paper Title": "No-But-Semantic-Match: Computing Semantically Matched XML Keyword Search\n  Results",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.01910v1": {
            "Paper Title": "DIMSpan - Transactional Frequent Subgraph Mining with Distributed\n  In-Memory Dataflow Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.01298v1": {
            "Paper Title": "Defining Domain-Independent Discovery Informatics",
            "Sentences": []
        },
        "http://arxiv.org/abs/1703.00123v2": {
            "Paper Title": "DTNC: A New Server-side Data Cleansing Framework for Cellular Trajectory\n  Services",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.08745v1": {
            "Paper Title": "Optimal Categorical Attribute Transformation for Granularity Change in\n  Relational Databases for Binary Decision Problems in Educational Data Mining",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.08409v1": {
            "Paper Title": "Query Combinators",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.08327v1": {
            "Paper Title": "ArrayBridge: Interweaving declarative array processing with\n  high-performance computing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.08051v1": {
            "Paper Title": "From Complex Event Processing to Simple Event Processing",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.08042v1": {
            "Paper Title": "Instant restore after a media failure",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.06379v1": {
            "Paper Title": "Probabilistic Complex Event Recognition: A Survey",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.06370v1": {
            "Paper Title": "Answering Conjunctive Queries under Updates",
            "Sentences": [
                {
                    "Sentence ID": 29,
                    "Sentence": "Bernard M. E. Moret and Henry D. Shapiro. Algorithms from P to NP: Volume 1: Design\n& E\u000eciency . Benjamin-Cummings, 1991. isbn: 0-8053-8008-6. ",
                    "Citation Text": "Hung Q. Ngo, Dung T. Nguyen, Christopher Re, and Atri Rudra. \\Beyond worst-case\nanalysis for joins with minesweeper\". In: Proceedings of the 33rd ACM SIGMOD-SIGACT-\nSIGART Symposium on Principles of Database Systems, PODS'14, Snowbird, UT, USA,\nJune 22{27, 2014 . 2014, pp. 234{245. doi:10.1145/2594538.2594547 .",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1302.0914",
                        "Citation Paper Title": "Title:Beyond Worst-Case Analysis for Joins with Minesweeper",
                        "Citation Paper Abstract": "Abstract:We describe a new algorithm, Minesweeper, that is able to satisfy stronger runtime guarantees than previous join algorithms (colloquially, `beyond worst-case guarantees') for data in indexed search trees. Our first contribution is developing a framework to measure this stronger notion of complexity, which we call {\\it certificate complexity}, that extends notions of Barbay et al. and Demaine et al.; a certificate is a set of propositional formulae that certifies that the output is correct. This notion captures a natural class of join algorithms. In addition, the certificate allows us to define a strictly stronger notion of runtime complexity than traditional worst-case guarantees. Our second contribution is to develop a dichotomy theorem for the certificate-based notion of complexity. Roughly, we show that Minesweeper evaluates $\\beta$-acyclic queries in time linear in the certificate plus the output size, while for any $\\beta$-cyclic query there is some instance that takes superlinear time in the certificate (and for which the output is no larger than the certificate size). We also extend our certificate-complexity analysis to queries with bounded treewidth and the triangle query.",
                        "Citation Paper Authors": "Authors:Hung Q. Ngo, Dung T. Nguyen, Christopher R\u00e9, Atri Rudra"
                    }
                },
                {
                    "Sentence ID": 6,
                    "Sentence": "Andrey Balmin, Yannis Papakonstantinou, and Victor Vianu. \\Incremental validation of\nXML documents\". In: ACM Trans. Database Syst. 29.4 (2004), pp. 710{751. doi:10.\n1145/1042046.1042050 . ",
                    "Citation Text": "Christoph Berkholz, Jens Keppeler, and Nicole Schweikardt. \\Answering Conjunctive Que-\nries under Updates\". In: Proceedings of the 36th ACM SIGMOD-SIGACT-SIGART Sym-\nposium on Principles of Database Systems, PODS'17 . To appear. 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1702.06370",
                        "Citation Paper Title": "Title:Answering Conjunctive Queries under Updates",
                        "Citation Paper Abstract": "Abstract:We consider the task of enumerating and counting answers to $k$-ary conjunctive queries against relational databases that may be updated by inserting or deleting tuples. We exhibit a new notion of q-hierarchical conjunctive queries and show that these can be maintained efficiently in the following sense. During a linear time preprocessing phase, we can build a data structure that enables constant delay enumeration of the query results; and when the database is updated, we can update the data structure and restart the enumeration phase within constant time. For the special case of self-join free conjunctive queries we obtain a dichotomy: if a query is not q-hierarchical, then query enumeration with sublinear$^\\ast$ delay and sublinear update time (and arbitrary preprocessing time) is impossible.\nFor answering Boolean conjunctive queries and for the more general problem of counting the number of solutions of k-ary queries we obtain complete dichotomies: if the query's homomorphic core is q-hierarchical, then size of the the query result can be computed in linear time and maintained with constant update time. Otherwise, the size of the query result cannot be maintained with sublinear update time. All our lower bounds rely on the OMv-conjecture, a conjecture on the hardness of online matrix-vector multiplication that has recently emerged in the field of fine-grained complexity to characterise the hardness of dynamic problems. The lower bound for the counting problem additionally relies on the orthogonal vectors conjecture, which in turn is implied by the strong exponential time hypothesis.\n$^\\ast)$ By sublinear we mean $O(n^{1-\\varepsilon})$ for some $\\varepsilon>0$, where $n$ is the size of the active domain of the current database.",
                        "Citation Paper Authors": "Authors:Christoph Berkholz, Jens Keppeler, Nicole Schweikardt"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1702.06298v1": {
            "Paper Title": "Computing Influence of a Product through Uncertain Reverse Skyline",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.05607v1": {
            "Paper Title": "End-to-End Differentially-Private Parameter Tuning in Spatial Histograms",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.05597v1": {
            "Paper Title": "One-Pass Error Bounded Trajectory Simplification",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.05200v1": {
            "Paper Title": "Hybrid Indexes to Expedite Spatial-Visual Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.04746v1": {
            "Paper Title": "Spectral Algorithms for Temporal Graph Cuts",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.04242v1": {
            "Paper Title": "Bizur: A Key-value Consensus Algorithm for Scalable File-systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.03519v1": {
            "Paper Title": "A Technical Report: Entity Extraction using Both Character-based and\n  Token-based Similarity",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.03390v1": {
            "Paper Title": "K-Dominant Skyline Join Queries: Extending the Join Paradigm to\n  K-Dominant Skylines",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.03825v1": {
            "Paper Title": "Analyzing and Visualizing Scalar Fields on Graphs",
            "Sentences": [
                {
                    "Sentence ID": 25,
                    "Sentence": "propose interactive visual system to let users explore networks\nwith multiple node or edge attributes. However, these methods\ndo not consider hierarchical relationships among components-\nof-interest and graph attributes simultaneously.\nSariyuce et al. ",
                    "Citation Text": "A. E. Sariyuce, C. Seshadhri, A. Pinar, and U. V . Catalyurek, \u201cFinding\nthe hierarchy of dense subgraphs using nucleus decompositions,\u201d WWW ,\n2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1411.3312",
                        "Citation Paper Title": "Title:Finding the Hierarchy of Dense Subgraphs using Nucleus Decompositions",
                        "Citation Paper Abstract": "Abstract:Finding dense substructures in a graph is a fundamental graph mining operation, with applications in bioinformatics, social networks, and visualization to name a few. Yet most standard formulations of this problem (like clique, quasiclique, k-densest subgraph) are NP-hard. Furthermore, the goal is rarely to find the \"true optimum\", but to identify many (if not all) dense substructures, understand their distribution in the graph, and ideally determine relationships among them. Current dense subgraph finding algorithms usually optimize some objective, and only find a few such subgraphs without providing any structural relations. We define the nucleus decomposition of a graph, which represents the graph as a forest of nuclei. Each nucleus is a subgraph where smaller cliques are present in many larger cliques. The forest of nuclei is a hierarchy by containment, where the edge density increases as we proceed towards leaf nuclei. Sibling nuclei can have limited intersections, which enables discovering overlapping dense subgraphs. With the right parameters, the nucleus decomposition generalizes the classic notions of k-cores and k-truss decompositions. We give provably efficient algorithms for nucleus decompositions, and empirically evaluate their behavior in a variety of real graphs. The tree of nuclei consistently gives a global, hierarchical snapshot of dense substructures, and outputs dense subgraphs of higher quality than other state-of-the-art solutions. Our algorithm can process graphs with tens of millions of edges in less than an hour.",
                        "Citation Paper Authors": "Authors:Ahmet Erdem Sariyuce, C. Seshadhri, Ali Pinar, Umit V. Catalyurek"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1702.02799v1": {
            "Paper Title": "UStore: A Distributed Storage With Rich Semantics",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.01446v2": {
            "Paper Title": "Efficient Algorithms for k-Regret Minimizing Sets",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.01786v1": {
            "Paper Title": "Unobtrusive Deferred Update Stabilization for Efficient Geo-Replication",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.01168v1": {
            "Paper Title": "Type- and Content-Driven Synthesis of SQL Queries from Natural Language",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.00820v1": {
            "Paper Title": "HoloClean: Holistic Data Repairs with Probabilistic Inference",
            "Sentences": [
                {
                    "Sentence ID": 36,
                    "Sentence": "; and (ii) in the presence of complex correlations,\nGibbs sampling require an exponential number of iterations in the\nnumber of random variables to mix, i.e., reach a stationary distri-\nbution, and accurately estimate the marginal probabilities of query\nvariables ",
                    "Citation Text": "C. D. Sa, C. Zhang, K. Olukotun, and C. R\u00e9. Rapidly mixing\ngibbs sampling for a class of factor graphs using hierarchy\nwidth. In NIPS , pages 3097\u20133105, 2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1510.00756",
                        "Citation Paper Title": "Title:Rapidly Mixing Gibbs Sampling for a Class of Factor Graphs Using Hierarchy Width",
                        "Citation Paper Abstract": "Abstract:Gibbs sampling on factor graphs is a widely used inference technique, which often produces good empirical results. Theoretical guarantees for its performance are weak: even for tree structured graphs, the mixing time of Gibbs may be exponential in the number of variables. To help understand the behavior of Gibbs sampling, we introduce a new (hyper)graph property, called hierarchy width. We show that under suitable conditions on the weights, bounded hierarchy width ensures polynomial mixing time. Our study of hierarchy width is in part motivated by a class of factor graph templates, hierarchical templates, which have bounded hierarchy width---regardless of the data used to instantiate them. We demonstrate a rich application from natural language processing in which Gibbs sampling provably mixes rapidly and achieves accuracy that exceeds human volunteers.",
                        "Citation Paper Authors": "Authors:Christopher De Sa, Ce Zhang, Kunle Olukotun, Christopher R\u00e9"
                    }
                },
                {
                    "Sentence ID": 37,
                    "Sentence": "to represent the probability distribution over variables Tc. Holo-\nClean is built on top of DeepDive ",
                    "Citation Text": "J. Shin, S. Wu, F. Wang, C. De Sa, C. Zhang, and C. R\u00e9.\nIncremental knowledge base construction using DeepDive.\nProc. VLDB Endow. , 8(11):1310\u20131321, July 2015.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1502.00731",
                        "Citation Paper Title": "Title:Incremental Knowledge Base Construction Using DeepDive",
                        "Citation Paper Abstract": "Abstract:Populating a database with unstructured information is a long-standing problem in industry and research that encompasses problems of extraction, cleaning, and integration. Recent names used for this problem include dealing with dark data and knowledge base construction (KBC). In this work, we describe DeepDive, a system that combines database and machine learning ideas to help develop KBC systems, and we present techniques to make the KBC process more efficient. We observe that the KBC process is iterative, and we develop techniques to incrementally produce inference results for KBC systems. We propose two methods for incremental inference, based respectively on sampling and variational techniques. We also study the tradeoff space of these methods and develop a simple rule-based optimizer. DeepDive includes all of these contributions, and we evaluate DeepDive on five KBC systems, showing that it can speed up KBC inference tasks by up to two orders of magnitude with negligible impact on quality.",
                        "Citation Paper Authors": "Authors:Jaeho Shin, Sen Wu, Feiran Wang, Christopher De Sa, Ce Zhang, Christopher R\u00e9"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1702.00567v1": {
            "Paper Title": "CrowdFusion: A Crowdsourced Approach on Data Fusion Refinement",
            "Sentences": []
        },
        "http://arxiv.org/abs/1702.00358v1": {
            "Paper Title": "OLA-RAW: Scalable Exploration over Raw Data",
            "Sentences": [
                {
                    "Sentence ID": 32,
                    "Sentence": "tackle online aggregation over multiple queries. The third piece\nof relevant work is online aggregation in MapReduce (Hadoop or Spark). BlinkDB [3, 2] implements a multi-stage ap-\nproximation mechanism based on pre-computed sampling synopses of multiple sizes, while EARL ",
                    "Citation Text": "N. Laptev, K. Zeng, and C. Zaniolo. Early Accurate Results for Advanced Analytics on MapReduce. PVLDB , 5(10), 2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1207.0142",
                        "Citation Paper Title": "Title:Early Accurate Results for Advanced Analytics on MapReduce",
                        "Citation Paper Abstract": "Abstract:Approximate results based on samples often provide the only way in which advanced analytical applications on very massive data sets can satisfy their time and resource constraints. Unfortunately, methods and tools for the computation of accurate early results are currently not supported in MapReduce-oriented systems although these are intended for `big data'. Therefore, we proposed and implemented a non-parametric extension of Hadoop which allows the incremental computation of early results for arbitrary work-flows, along with reliable on-line estimates of the degree of accuracy achieved so far in the computation. These estimates are based on a technique called bootstrapping that has been widely employed in statistics and can be applied to arbitrary functions and data distributions. In this paper, we describe our Early Accurate Result Library (EARL) for Hadoop that was designed to minimize the changes required to the MapReduce framework. Various tests of EARL of Hadoop are presented to characterize the frequent situations where EARL can provide major speed-ups over the current version of Hadoop.",
                        "Citation Paper Authors": "Authors:Nikolay Laptev, Kai Zeng, Carlo Zaniolo"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1701.09049v1": {
            "Paper Title": "Batch Incremental Shared Nearest Neighbor Density Based Clustering\n  Algorithm for Dynamic Datasets",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08924v1": {
            "Paper Title": "Validating and describing linked data portals using shapes",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08643v1": {
            "Paper Title": "Innovative Approaches for efficiently Warehousing Complex Data from the\n  Web",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08634v1": {
            "Paper Title": "Data Processing Benchmarks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08612v1": {
            "Paper Title": "XML Warehousing and OLAP",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.09045v1": {
            "Paper Title": "Big Data Technology Accelerate Genomics Precision Medicine",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08190v1": {
            "Paper Title": "Comparative Study Of Data Mining Query Languages",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08052v1": {
            "Paper Title": "Database Benchmarks",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08033v1": {
            "Paper Title": "X-WACoDa: An XML-based approach for Warehousing and Analyzing Complex\n  Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08029v1": {
            "Paper Title": "Index and Materialized View Selection in Data Warehouses",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.08028v1": {
            "Paper Title": "Biomedical Data Warehouses",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.07723v1": {
            "Paper Title": "The Many Faces of Data-centric Workflow Optimization: A Survey",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.07473v1": {
            "Paper Title": "Implementation of Tetris as a Model Counter",
            "Sentences": [
                {
                    "Sentence ID": 6,
                    "Sentence": "Our work builds on Tetris as developed by Abo Khamis et al. in ",
                    "Citation Text": "Mahmoud Abo Khamis, Hung Q. Ngo, Christopher R\u00e9, and Atri Rudra. Joins via geometric resolu-\ntions: Worst-case and beyond. In Proceedings of the 34th ACM SIGMOD-SIGACT-SIGAI Symposium\non Principles of Database Systems , PODS \u201915, pages 213\u2013228, New York, NY, USA, 2015. ACM.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1404.0703",
                        "Citation Paper Title": "Title:Joins via Geometric Resolutions: Worst-case and Beyond",
                        "Citation Paper Abstract": "Abstract:We present a simple geometric framework for the relational join. Using this framework, we design an algorithm that achieves the fractional hypertree-width bound, which generalizes classical and recent worst-case algorithmic results on computing joins. In addition, we use our framework and the same algorithm to show a series of what are colloquially known as beyond worst-case results. The framework allows us to prove results for data stored in Btrees, multidimensional data structures, and even multiple indices per table. A key idea in our framework is formalizing the inference one does with an index as a type of geometric resolution; transforming the algorithmic problem of computing joins to a geometric problem. Our notion of geometric resolution can be viewed as a geometric analog of logical resolution. In addition to the geometry and logic connections, our algorithm can also be thought of as backtracking search with memoization.",
                        "Citation Paper Authors": "Authors:Mahmoud Abo Khamis, Hung Q. Ngo, Christopher R\u00e9, Atri Rudra"
                    }
                },
                {
                    "Sentence ID": 23,
                    "Sentence": ". In that work, the auth ors introduced\nTetris as a beyond-worst-case algorithm for geometrically solvin g the database join problem. This in\nturn built on work on the Minesweeper ",
                    "Citation Text": "Hung Q. Ngo, Dung T. Nguyen, Christopher R\u00e9, and Atri Rud ra. Towards instance optimal join\nalgorithms for data in indexes. CoRR , abs/1302.0914, 2013.\n28",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1302.0914",
                        "Citation Paper Title": "Title:Beyond Worst-Case Analysis for Joins with Minesweeper",
                        "Citation Paper Abstract": "Abstract:We describe a new algorithm, Minesweeper, that is able to satisfy stronger runtime guarantees than previous join algorithms (colloquially, `beyond worst-case guarantees') for data in indexed search trees. Our first contribution is developing a framework to measure this stronger notion of complexity, which we call {\\it certificate complexity}, that extends notions of Barbay et al. and Demaine et al.; a certificate is a set of propositional formulae that certifies that the output is correct. This notion captures a natural class of join algorithms. In addition, the certificate allows us to define a strictly stronger notion of runtime complexity than traditional worst-case guarantees. Our second contribution is to develop a dichotomy theorem for the certificate-based notion of complexity. Roughly, we show that Minesweeper evaluates $\\beta$-acyclic queries in time linear in the certificate plus the output size, while for any $\\beta$-cyclic query there is some instance that takes superlinear time in the certificate (and for which the output is no larger than the certificate size). We also extend our certificate-complexity analysis to queries with bounded treewidth and the triangle query.",
                        "Citation Paper Authors": "Authors:Hung Q. Ngo, Dung T. Nguyen, Christopher R\u00e9, Atri Rudra"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1701.05724v1": {
            "Paper Title": "Logical Inferences with Contexts of RDF Triples",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": "in Section 7. We discuss the future work in\nSection 8 and conclude with Section 9.\n2. CONCEPTUAL MODEL\n2.1 Preliminaries\nHere we recall the singleton property concept with its syn-\ntax and semantics from ",
                    "Citation Text": "V. Nguyen, O. Bodenreider, and A. Sheth. Don't like\nrdf rei\fcation?: Making statements about statements\nusing singleton property. In Proceedings of the 23rd\nInternational Conference on World Wide Web , WWW\n'14, pages 759{770, 2014.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1509.04513",
                        "Citation Paper Title": "Title:On Reasoning with RDF Statements about Statements using Singleton Property Triples",
                        "Citation Paper Abstract": "Abstract:The Singleton Property (SP) approach has been proposed for representing and querying metadata about RDF triples such as provenance, time, location, and evidence. In this approach, one singleton property is created to uniquely represent a relationship in a particular context, and in general, generates a large property hierarchy in the schema. It has become the subject of important questions from Semantic Web practitioners. Can an existing reasoner recognize the singleton property triples? And how? If the singleton property triples describe a data triple, then how can a reasoner infer this data triple from the singleton property triples? Or would the large property hierarchy affect the reasoners in some way? We address these questions in this paper and present our study about the reasoning aspects of the singleton properties. We propose a simple mechanism to enable existing reasoners to recognize the singleton property triples, as well as to infer the data triples described by the singleton property triples. We evaluate the effect of the singleton property triples in the reasoning processes by comparing the performance on RDF datasets with and without singleton properties. Our evaluation uses as benchmark the LUBM datasets and the LUBM-SP datasets derived from LUBM with temporal information added through singleton properties.",
                        "Citation Paper Authors": "Authors:Vinh Nguyen, Olivier Bodenreider, Krishnaprasad Thirunarayan, Gang Fu, Evan Bolton, N\u00faria Queralt Rosinach, Laura I. Furlong, Michel Dumontier, Amit Sheth"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1701.05699v1": {
            "Paper Title": "Efficiently Computing Provenance Graphs for Queries with Negation",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.05099v1": {
            "Paper Title": "Cost Models for Selecting Materialized Views in Public Clouds",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.04339v1": {
            "Paper Title": "Transactional Partitioning: A New Abstraction for Main-Memory Databases",
            "Sentences": [
                {
                    "Sentence ID": 9,
                    "Sentence": "provides full ACID semantics\nbut only within partitions of the data, which limits the ease\nof application development and \ufb02exible deployments. Warp ",
                    "Citation Text": "R. Escriva, B. Wong, and E. G. Sirer. Warp:\nLightweight multi-key transactions for key-value\nstores. Technical report, Cornell University, Ithaca,\n2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1509.07815",
                        "Citation Paper Title": "Title:Warp: Lightweight Multi-Key Transactions for Key-Value Stores",
                        "Citation Paper Abstract": "Abstract:Traditional NoSQL systems scale by sharding data across multiple servers and by performing each operation on a small number of servers. Because transactions on multiple keys necessarily require coordination across multiple servers, NoSQL systems often explicitly avoid making transactional guarantees in order to avoid such coordination. Past work on transactional systems control this coordination by either increasing the granularity at which transactions are ordered, sacrificing serializability, or by making clock synchronicity assumptions.\nThis paper presents a novel protocol for providing serializable transactions on top of a sharded data store. Called acyclic transactions, this protocol allows multiple transactions to prepare and commit simultaneously, improving concurrency in the system, while ensuring that no cycles form between concurrently-committing transactions. We have fully implemented acyclic transactions in a document store called Warp. Experiments show that Warp achieves 4 times higher throughput than Sinfonia's mini-transactions on the standard TPC-C benchmark with no aborts. Further, the system achieves 75% of the throughput of the non-transactional key-value store it builds upon.",
                        "Citation Paper Authors": "Authors:Robert Escriva, Bernard Wong, Emin G\u00fcn Sirer"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1701.04182v1": {
            "Paper Title": "hMDAP: A Hybrid Framework for Multi-paradigm Data Analytical Processing\n  on Spark",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.03091v1": {
            "Paper Title": "SPARQL over GraphX",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.02494v1": {
            "Paper Title": "Dynamic Complexity under Definable Changes",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.01232v1": {
            "Paper Title": "Scalable Multi-Database Privacy-Preserving Record Linkage using Counting\n  Bloom Filters",
            "Sentences": []
        },
        "http://arxiv.org/abs/1701.01094v1": {
            "Paper Title": "Minimally-Supervised Attribute Fusion for Data Lakes",
            "Sentences": []
        },
        "http://arxiv.org/abs/2110.06485v3": {
            "Paper Title": "Communication-Efficient Triangle Counting under Local Differential\n  Privacy",
            "Sentences": [
                {
                    "Sentence ID": 12,
                    "Sentence": "that uses RR. Applying HR\nto an entire neighbor list (which has 2npossible values) will\nsimilarly result in O(nlog2n) =O(n2)download cost.\nPrevious work on distribution estimation [33, 44, 60] or\nheavy hitters ",
                    "Citation Text": "R. Bassily, K. Nissim, U. Stemmer, and A. Thakurta.\nPractical locally private heavy hitters. In Proc. NIPS\u201917 ,\npages 2285\u2014-2293, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1707.04982",
                        "Citation Paper Title": "Title:Practical Locally Private Heavy Hitters",
                        "Citation Paper Abstract": "Abstract:We present new practical local differentially private heavy hitters algorithms achieving optimal or near-optimal worst-case error and running time -- TreeHist and Bitstogram. In both algorithms, server running time is $\\tilde O(n)$ and user running time is $\\tilde O(1)$, hence improving on the prior state-of-the-art result of Bassily and Smith [STOC 2015] requiring $O(n^{5/2})$ server time and $O(n^{3/2})$ user time. With a typically large number of participants in local algorithms ($n$ in the millions), this reduction in time complexity, in particular at the user side, is crucial for making locally private heavy hitters algorithms usable in practice. We implemented Algorithm TreeHist to verify our theoretical analysis and compared its performance with the performance of Google's RAPPOR code.",
                        "Citation Paper Authors": "Authors:Raef Bassily, Kobbi Nissim, Uri Stemmer, Abhradeep Thakurta"
                    }
                },
                {
                    "Sentence ID": 8,
                    "Sentence": "have been widely used\nfor tabular data in LDP. Our work uses RR in part of our\nalgorithm but builds off of it significantly. One noteworthy\nresult in this area is HR (Hadamard Response) ",
                    "Citation Text": "J. Acharya, Z. Sun, and H. Zhang. Hadamard response:\nEstimating distributions privately, efficiently, and with\nlittle communication. In Proc. AISTATS\u201919 , pages 1120\u2013\n1129, 2019.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1802.04705",
                        "Citation Paper Title": "Title:Hadamard Response: Estimating Distributions Privately, Efficiently, and with Little Communication",
                        "Citation Paper Abstract": "Abstract:We study the problem of estimating $k$-ary distributions under $\\varepsilon$-local differential privacy. $n$ samples are distributed across users who send privatized versions of their sample to a central server. All previously known sample optimal algorithms require linear (in $k$) communication from each user in the high privacy regime $(\\varepsilon=O(1))$, and run in time that grows as $n\\cdot k$, which can be prohibitive for large domain size $k$.\nWe propose Hadamard Response (HR}, a local privatization scheme that requires no shared randomness and is symmetric with respect to the users. Our scheme has order optimal sample complexity for all $\\varepsilon$, a communication of at most $\\log k+2$ bits per user, and nearly linear running time of $\\tilde{O}(n + k)$.\nOur encoding and decoding are based on Hadamard matrices, and are simple to implement. The statistical performance relies on the coding theoretic aspects of Hadamard matrices, ie, the large Hamming distance between the rows. An efficient implementation of the algorithm using the Fast Walsh-Hadamard transform gives the computational gains.\nWe compare our approach with Randomized Response (RR), RAPPOR, and subset-selection mechanisms (SS), both theoretically, and experimentally. For $k=10000$, our algorithm runs about 100x faster than SS, and RAPPOR.",
                        "Citation Paper Authors": "Authors:Jayadev Acharya, Ziteng Sun, Huanyu Zhang"
                    }
                },
                {
                    "Sentence ID": 27,
                    "Sentence": "that improves the\nutility of an averaging query by correlating the noise of users\naccording to a graph.\nLDP. RR [33, 61] and RAPPOR ",
                    "Citation Text": "U. Erlingsson, V . Pihur, and A. Korolova. RAPPOR:\nRandomized aggregatable privacy-preserving ordinal\nresponse. In Proc. CCS\u201914 , pages 1054\u20131067, 2014.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1407.6981",
                        "Citation Paper Title": "Title:RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response",
                        "Citation Paper Abstract": "Abstract:Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports. This paper describes and motivates RAPPOR, details its differential-privacy and utility guarantees, discusses its practical deployment and properties in the face of different attack models, and, finally, gives results of its application to both synthetic and real-world data.",
                        "Citation Paper Authors": "Authors:\u00dalfar Erlingsson, Vasyl Pihur, Aleksandra Korolova"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2109.01537v2": {
            "Paper Title": "A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis",
            "Sentences": [
                {
                    "Sentence ID": 57,
                    "Sentence": ", we map speech segments to pre-\ntrained speech embeddings. Here, we use TRIpLET Loss network (TRILL),\nwhich has resulted in a good performance in non-semantic speech tasks includ-\ning AD classification on DementiaBank ",
                    "Citation Text": "Shor, J., Jansen, A., Maor, R., Lang, O., Tuval, O., de Chaumont Quitry,\nF., Tagliasacchi, M., Shavitt, I., Emanuel, D., Haviv, Y.A.: Towards\nlearning a universal non-semantic representation of speech. ArXiv\nabs/2002.12764 (2020)",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2002.12764",
                        "Citation Paper Title": "Title:Towards Learning a Universal Non-Semantic Representation of Speech",
                        "Citation Paper Abstract": "Abstract:The ultimate goal of transfer learning is to reduce labeled data requirements by exploiting a pre-existing embedding model trained for different datasets or tasks. The visual and language communities have established benchmarks to compare embeddings, but the speech community has yet to do so. This paper proposes a benchmark for comparing speech representations on non-semantic tasks, and proposes a representation based on an unsupervised triplet-loss objective. The proposed representation outperforms other representations on the benchmark, and even exceeds state-of-the-art performance on a number of transfer learning tasks. The embedding is trained on a publicly available dataset, and it is tested on a variety of low-resource downstream tasks, including personalization tasks and medical domain. The benchmark, models, and evaluation code are publicly released.",
                        "Citation Paper Authors": "Authors:Joel Shor, Aren Jansen, Ronnie Maor, Oran Lang, Omry Tuval, Felix de Chaumont Quitry, Marco Tagliasacchi, Ira Shavitt, Dotan Emanuel, Yinnon Haviv"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2105.14307v2": {
            "Paper Title": "Towards a Dichotomy for Minimally Factorizing the Provenance of\n  Self-Join Free Conjunctive Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1903.00226v5": {
            "Paper Title": "A Trichotomy for Regular Trail Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/2101.01945v7": {
            "Paper Title": "Fine-Grained Complexity of Regular Path Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/2002.00540v3": {
            "Paper Title": "Optimizing Query Predicates with Disjunctions for Column-Oriented\n  Engines",
            "Sentences": [
                {
                    "Sentence ID": 21,
                    "Sentence": "do not seem to implement any ad-\nditional optimizations, and based on conversations with developers from Vertica ",
                    "Citation Text": "Andrew Lamb, Matt Fuller, Ramakrishna Varadarajan, Nga Tran, Ben Vandier, Lyric Doshi, and\nChuck Bear. The vertica analytic database: C-store 7 years later. arXiv preprint arXiv:1208.4173 ,\n2012.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1208.4173",
                        "Citation Paper Title": "Title:The Vertica Analytic Database: C-Store 7 Years Later",
                        "Citation Paper Abstract": "Abstract:This paper describes the system architecture of the Vertica Analytic Database (Vertica), a commercialization of the design of the C-Store research prototype. Vertica demonstrates a modern commercial RDBMS system that presents a classical relational interface while at the same time achieving the high performance expected from modern \"web scale\" analytic systems by making appropriate architectural choices. Vertica is also an instructive lesson in how academic systems research can be directly commercialized into a successful product.",
                        "Citation Paper Authors": "Authors:Andrew Lamb, Matt Fuller, Ramakrishna Varadarajan, Nga Tran, Ben Vandier, Lyric Doshi, Chuck Bear"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2112.12965v2": {
            "Paper Title": "Error-bounded Approximate Time Series Joins Using Compact Dictionary\n  Representations of Time Series",
            "Sentences": []
        },
        "http://arxiv.org/abs/2009.05774v7": {
            "Paper Title": "Sequential composition of propositional logic programs",
            "Sentences": []
        },
        "http://arxiv.org/abs/2103.00558v5": {
            "Paper Title": "Is Simple Uniform Sampling Effective for Center-Based Clustering with\n  Outliers: When and Why?",
            "Sentences": []
        },
        "http://arxiv.org/abs/2101.03058v5": {
            "Paper Title": "Answer Counting under Guarded TGDs",
            "Sentences": []
        },
        "http://arxiv.org/abs/2107.04553v2": {
            "Paper Title": "Can Deep Neural Networks Predict Data Correlations from Column Names?",
            "Sentences": [
                {
                    "Sentence ID": 46,
                    "Sentence": ". They form the basis for this study as well. Other\napplications of language models in the context of databases include\ndata discovery and integration [ 21,30] as well as data preparation\ntasks ",
                    "Citation Text": "Nan Tang, Ju Fan, Fangyi Li, Jianhong Tu, Xiaoyong Du, Guoliang Li, Sam\nMadden, and Mourad Ouzzani. 2021. Rpt: Relational pre-trained transformer is\nalmost all you need towards democratizing data preparation. PVLDB 14, 8 (2021),\n1254\u20131261. https://doi.org/10.14778/3457390.3457391 arXiv:2012.02469",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2012.02469",
                        "Citation Paper Title": "Title:RPT: Relational Pre-trained Transformer Is Almost All You Need towards Democratizing Data Preparation",
                        "Citation Paper Abstract": "Abstract:Can AI help automate human-easy but computer-hard data preparation tasks that burden data scientists, practitioners, and crowd workers? We answer this question by presenting RPT, a denoising auto-encoder for tuple-to-X models (X could be tuple, token, label, JSON, and so on). RPT is pre-trained for a tuple-to-tuple model by corrupting the input tuple and then learning a model to reconstruct the original tuple. It adopts a Transformer-based neural translation architecture that consists of a bidirectional encoder (similar to BERT) and a left-to-right autoregressive decoder (similar to GPT), leading to a generalization of both BERT and GPT. The pre-trained RPT can already support several common data preparation tasks such as data cleaning, auto-completion and schema matching. Better still, RPT can be fine-tuned on a wide range of data preparation tasks, such as value normalization, data transformation, data annotation, etc. To complement RPT, we also discuss several appealing techniques such as collaborative training and few-shot learning for entity resolution, and few-shot learning and NLP question-answering for information extraction. In addition, we identify a series of research opportunities to advance the field of data preparation.",
                        "Citation Paper Authors": "Authors:Nan Tang, Ju Fan, Fangyi Li, Jianhong Tu, Xiaoyong Du, Guoliang Li, Sam Madden, Mourad Ouzzani"
                    }
                },
                {
                    "Sentence ID": 58,
                    "Sentence": ", have recently led to significant advances on a multitude\nof NLP tasks ",
                    "Citation Text": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement De-\nlangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,\nJoe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu,\nCanwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,\nand Alexander Rush. 2020. Transformers: State-of-the-Art Natural Language\nProcessing. In EMNLP . 38\u201345. https://doi.org/10.18653/v1/2020.emnlp-demos.6\narXiv:arXiv:1910.03771v5",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1910.03771",
                        "Citation Paper Title": "Title:HuggingFace's Transformers: State-of-the-art Natural Language Processing",
                        "Citation Paper Abstract": "Abstract:Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \\textit{Transformers} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \\textit{Transformers} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \\url{this https URL}.",
                        "Citation Paper Authors": "Authors:Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, Alexander M. Rush"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2112.00710v2": {
            "Paper Title": "Stateful Entities: Object-oriented Cloud Applications as Distributed\n  Dataflows",
            "Sentences": [
                {
                    "Sentence ID": 17,
                    "Sentence": "The idea of democratizing distributed systems programming\nis not new. For instance, in ",
                    "Citation Text": "Alvin Cheung, Natacha Crooks, Joseph M. Hellerstein, and Matthew Milano.\n2021. New Directions in Cloud Programming. In CIDR .",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2101.01159",
                        "Citation Paper Title": "Title:New Directions in Cloud Programming",
                        "Citation Paper Abstract": "Abstract:  Nearly twenty years after the launch of AWS, it remains difficult for most developers to harness the enormous potential of the cloud. In this paper we lay out an agenda for a new generation of cloud programming research aimed at bringing research ideas to programmers in an evolutionary fashion. Key to our approach is a separation of distributed programs into a PACT of four facets: Program semantics, Availablity, Consistency and Targets of optimization. We propose to migrate developers gradually to PACT programming by lifting familiar code into our more declarative level of abstraction. We then propose a multi-stage compiler that emits human-readable code at each stage that can be hand-tuned by developers seeking more control. Our agenda raises numerous research challenges across multiple areas including language design, query optimization, transactions, distributed consistency, compilers and program synthesis.",
                        "Citation Paper Authors": "Authors:Alvin Cheung, Natacha Crooks, Joseph M. Hellerstein, Mae Milano"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2106.14052v2": {
            "Paper Title": "Combining Inductive and Deductive Reasoning for Query Answering over\n  Incomplete Knowledge Graphs",
            "Sentences": [
                {
                    "Sentence ID": 22,
                    "Sentence": "), but these works typically focus on the task of link\nprediction rather than query answering. Recently, a type-aware\nmodel (called TEMP) for query answering over incomplete KGs has\nbeen proposed ",
                    "Citation Text": "Zhiwei Hu, V\u00edctor Guti\u00e9rrez-Basulto, Zhiliang Xiang, Xiaoli Li, Ru Li, and Jeff Z.\nPan. 2022. Type-aware Embeddings for Multi-Hop Reasoning over Knowledge\nGraphs. In IJCAI 2022 . 3078\u20133084.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2205.00782",
                        "Citation Paper Title": "Title:Type-aware Embeddings for Multi-Hop Reasoning over Knowledge Graphs",
                        "Citation Paper Abstract": "Abstract:Multi-hop reasoning over real-life knowledge graphs (KGs) is a highly challenging problem as traditional subgraph matching methods are not capable to deal with noise and missing information. To address this problem, it has been recently introduced a promising approach based on jointly embedding logical queries and KGs into a low-dimensional space to identify answer entities. However, existing proposals ignore critical semantic knowledge inherently available in KGs, such as type information. To leverage type information, we propose a novel TypE-aware Message Passing (TEMP) model, which enhances the entity and relation representations in queries, and simultaneously improves generalization, deductive and inductive reasoning. Remarkably, TEMP is a plug-and-play model that can be easily incorporated into existing embedding-based models to improve their performance. Extensive experiments on three real-world datasets demonstrate TEMP's effectiveness.",
                        "Citation Paper Authors": "Authors:Zhiwei Hu, V\u00edctor Guti\u00e9rrez-Basulto, Zhiliang Xiang, Xiaoli Li, Ru Li, Jeff Z. Pan"
                    }
                },
                {
                    "Sentence ID": 35,
                    "Sentence": "The task of answering queries that involve multiple atoms using em-\nbedding techniques has recently received a lot of attention (see ",
                    "Citation Text": "Hongyu Ren, Mikhail Galkin, and Michael Cochez et al. 2023. Neural Graph\nReasoning: Complex Logical Query Answering Meets Graph Databases. CoRR\nabs/2303.14617 (2023).",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2303.14617",
                        "Citation Paper Title": "Title:Neural Graph Reasoning: Complex Logical Query Answering Meets Graph Databases",
                        "Citation Paper Abstract": "Abstract:Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves a far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs in a latent space. The task received a significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and applications.\nRefining the CLQA task, we introduce the concept of Neural Graph Databases (NGDBs). Extending the idea of graph databases (graph DBs), NGDB consists of a Neural Graph Storage and a Neural Graph Engine. Inside Neural Graph Storage, we design a graph store, a feature store, and further embed information in a latent embedding store using an encoder. Given a query, Neural Query Engine learns how to perform query planning and execution in order to efficiently retrieve the correct results by interacting with the Neural Graph Storage. Compared with traditional graph DBs, NGDBs allow for a flexible and unified modeling of features in diverse modalities using the embedding store. Moreover, when the graph is incomplete, they can provide robust retrieval of answers which a normal graph DB cannot recover. Finally, we point out promising directions, unsolved problems and applications of NGDB for future research.",
                        "Citation Paper Authors": "Authors:Hongyu Ren, Mikhail Galkin, Michael Cochez, Zhaocheng Zhu, Jure Leskovec"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/1910.09017v8": {
            "Paper Title": "Demystifying Graph Databases: Analysis and Taxonomy of Data\n  Organization, System Designs, and Graph Queries",
            "Sentences": [
                {
                    "Sentence ID": 73,
                    "Sentence": ", designs related to network interface cards\nsuch as SmartNICs ",
                    "Citation Text": "Salvatore Di Girolamo, Konstantin Taranov, Andreas Kurth, Michael Schaffner, Timo Schneider, Jakub Ber\u00e1nek, Maciej\nBesta, Luca Benini, Duncan Roweth, and Torsten Hoefler. 2019. Network-Accelerated Non-Contiguous Memory\nTransfers. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and\nAnalysis (SC \u201919) . ACM, Article 56, 14 pages.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1908.08590",
                        "Citation Paper Title": "Title:Network-Accelerated Non-Contiguous Memory Transfers",
                        "Citation Paper Abstract": "Abstract:Applications often communicate data that is non-contiguous in the send- or the receive-buffer, e.g., when exchanging a column of a matrix stored in row-major order. While non-contiguous transfers are well supported in HPC (e.g., MPI derived datatypes), they can still be up to 5x slower than contiguous transfers of the same size. As we enter the era of network acceleration, we need to investigate which tasks to offload to the NIC: In this work we argue that non-contiguous memory transfers can be transparently networkaccelerated, truly achieving zero-copy communications. We implement and extend sPIN, a packet streaming processor, within a Portals 4 NIC SST model, and evaluate strategies for NIC-offloaded processing of MPI datatypes, ranging from datatype-specific handlers to general solutions for any MPI datatype. We demonstrate up to 10x speedup in the unpack throughput of real applications, demonstrating that non-contiguous memory transfers are a first-class candidate for network acceleration.",
                        "Citation Paper Authors": "Authors:Salvatore Di Girolamo, Konstantin Taranov, Andreas Kurth, Michael Schaffner, Timo Schneider, Jakub Ber\u00e1nek, Maciej Besta, Luca Benini, Duncan Roweth, Torsten Hoefler"
                    }
                },
                {
                    "Sentence ID": 39,
                    "Sentence": ".\n34Finally, contrarily to the general static graph processing and graph streaming, little research\nexists into accelerating graph databases using different types of hardware architectures, accelerators,\nand hardware-related designs, for example FPGAs ",
                    "Citation Text": "Maciej Besta, Dimitri Stanojevic, Johannes De Fine Licht, Tal Ben-Nun, and Torsten Hoefler. 2019. Graph Processing\non FPGAs: Taxonomy, Survey, Challenges. (2019). arXiv:1903.06697",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1903.06697",
                        "Citation Paper Title": "Title:Graph Processing on FPGAs: Taxonomy, Survey, Challenges",
                        "Citation Paper Abstract": "Abstract:Graph processing has become an important part of various areas, such as machine learning, computational sciences, medical applications, social network analysis, and many others. Various graphs, for example web or social networks, may contain up to trillions of edges. The sheer size of such datasets, combined with the irregular nature of graph processing, poses unique challenges for the runtime and the consumed power. Field Programmable Gate Arrays (FPGAs) can be an energy-efficient solution to deliver specialized hardware for graph processing. This is reflected by the recent interest in developing various graph algorithms and graph processing frameworks on FPGAs. To facilitate understanding of this emerging domain, we present the first survey and taxonomy on graph computations on FPGAs. Our survey describes and categorizes existing schemes and explains key ideas. Finally, we discuss research and engineering challenges to outline the future of graph computations on FPGAs.",
                        "Citation Paper Authors": "Authors:Maciej Besta, Dimitri Stanojevic, Johannes De Fine Licht, Tal Ben-Nun, Torsten Hoefler"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2109.10889v2": {
            "Paper Title": "General Space-Time Tradeoffs via Relational Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/2012.01917v2": {
            "Paper Title": "Mapping Patterns for Virtual Knowledge Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/1907.01988v7": {
            "Paper Title": "Trade-offs in Static and Dynamic Evaluation of Hierarchical Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/2001.02299v9": {
            "Paper Title": "The LDBC Social Network Benchmark",
            "Sentences": []
        },
        "http://arxiv.org/abs/2111.10968v6": {
            "Paper Title": "Functorial aggregation",
            "Sentences": []
        },
        "http://arxiv.org/abs/2110.06532v5": {
            "Paper Title": "Finding Materialized Models for Model Reuse",
            "Sentences": [
                {
                    "Sentence ID": 62,
                    "Sentence": ". This paper also tries to solve a data\nmanagement problem in machine learning, i.e., materialize d\nmodel query problem, and we construct a novel metric to\n\ufb01nd appropriate materialized models. More recently, ",
                    "Citation Text": "W. Zhang, Z. Yang, Y. Wang, Y. Shen, Y. Li, L. Wang, and B. Cu i.\nGrain: Improving data ef\ufb01ciency of graph neural networks vi a\ndiversi\ufb01ed in\ufb02uence maximization. VLDB , 14(11):2473\u20132482, 2021.\nMinjun Zhao received the BS degree in infor-\nmation security from Hainan University, China, in\n2019. He is currently working toward the PhD de-\ngree in the College of Computer Science, Zhe-\njiang University, China. His research interests\ninclude data management for machine learning\nand data mining.\nLu Chen received the PhD degree in computer\nscience from Zhejiang University, China, in 2016.\nShe was an assistant professor in Aalborg Uni-\nversity for a 2-year period from 2017 to 2019,\nand she was an associated professor in Aalborg\nUniversity for a 1-year period from 2019 to 2020.\nShe is currently a ZJU Plan 100 Professor in\nthe College of Computer Science, Zhejiang Uni-\nversity, Hangzhou, China. Her research interests\ninclude indexing and querying metric spaces,\ngraph databases, and graph mining.\nKeyu Yang received the PhD degree in com-\nputer science from Zhejiang University, China, in\n2021. He is currently a Senior Algorithm Engi-\nneer with Huawei Technologies, China. His re-\nsearch interests include machine learning inter-\naction with data management technology, and\nmetric data management.\nYuntao Du received the BS degree in data sci-\nence from East China Normal University, China,\nin 2020. He is currently working toward the\nMaster degree in the College of Computer Sci-\nence, Zhejiang University, China. His research\ninterests include recommender system and spa-\ntiotemporal data mining.\nYunjun Gao received the PhD degree in com-\nputer science from Zhejiang University, China,\nin 2008. He is currently a professor in the\nCollege of Computer Science, Zhejiang Univer-\nsity, China. His research interests include spa-\ntial and spatio-temporal databases, metric and\nincomplete/uncertain data management, graph\ndatabases, spatio-textual data processing, and\ndatabase usability. He is a member of the ACM\nand the IEEE.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2108.00219",
                        "Citation Paper Title": "Title:Grain: Improving Data Efficiency of Graph Neural Networks via Diversified Influence Maximization",
                        "Citation Paper Abstract": "Abstract:Data selection methods, such as active learning and core-set selection, are useful tools for improving the data efficiency of deep learning models on large-scale datasets. However, recent deep learning models have moved forward from independent and identically distributed data to graph-structured data, such as social networks, e-commerce user-item graphs, and knowledge graphs. This evolution has led to the emergence of Graph Neural Networks (GNNs) that go beyond the models existing data selection methods are designed for. Therefore, we present Grain, an efficient framework that opens up a new perspective through connecting data selection in GNNs with social influence maximization. By exploiting the common patterns of GNNs, Grain introduces a novel feature propagation concept, a diversified influence maximization objective with novel influence and diversity functions, and a greedy algorithm with an approximation guarantee into a unified framework. Empirical studies on public datasets demonstrate that Grain significantly improves both the performance and efficiency of data selection (including active learning and core-set selection) for GNNs. To the best of our knowledge, this is the first attempt to bridge two largely parallel threads of research, data selection, and social influence maximization, in the setting of GNNs, paving new ways for improving data efficiency.",
                        "Citation Paper Authors": "Authors:Wentao Zhang, Zhi Yang, Yexin Wang, Yu Shen, Yang Li, Liang Wang, Bin Cui"
                    }
                },
                {
                    "Sentence ID": 56,
                    "Sentence": "also utilizes the concepts of incremental view maintenance\nand multi-query optimization to boost CNN predictions in\nocclusion based explanations. Besides, the concepts of dat a\nprovenance and cleaning are used to incrementally update\nmodel parameters ",
                    "Citation Text": "Y. Wu, V . Tannen, and S. B. Davidson. Priu: A provenance-\nbased approach for incrementally updating regression mode ls. In\nSIGMOD , pages 447\u2013462, 2020.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2002.11791",
                        "Citation Paper Title": "Title:PrIU: A Provenance-Based Approach for Incrementally Updating Regression Models",
                        "Citation Paper Abstract": "Abstract:The ubiquitous use of machine learning algorithms brings new challenges to traditional database problems such as incremental view update. Much effort is being put in better understanding and debugging machine learning models, as well as in identifying and repairing errors in training datasets. Our focus is on how to assist these activities when they have to retrain the machine learning model after removing problematic training samples in cleaning or selecting different subsets of training data for interpretability. This paper presents an efficient provenance-based approach, PrIU, and its optimized version, PrIU-opt, for incrementally updating model parameters without sacrificing prediction accuracy. We prove the correctness and convergence of the incrementally updated model parameters, and validate it experimentally. Experimental results show that up to two orders of magnitude speed-ups can be achieved by PrIU-opt compared to simply retraining the model from scratch, yet obtaining highly similar models.",
                        "Citation Paper Authors": "Authors:Yinjun Wu, Val Tannen, Susan B. Davidson"
                    }
                },
                {
                    "Sentence ID": 27,
                    "Sentence": ". Model reuse1leverages the knowledge of the mate-\nrialized model (i.e., initial model) to improve the learnin g\nperformance (e.g., high accuracy, low loss) ",
                    "Citation Text": "D. Jin, B. Sisman, H. Wei, X. L. Dong, and D. Koutra. Deep tr ansfer\nlearning for multi-source entity linkage via domain adapta tion.\nVLDB , 15(3):465\u2013477, 2021.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2110.14509",
                        "Citation Paper Title": "Title:Deep Transfer Learning for Multi-source Entity Linkage via Domain Adaptation",
                        "Citation Paper Abstract": "Abstract:Multi-source entity linkage focuses on integrating knowledge from multiple sources by linking the records that represent the same real world entity. This is critical in high-impact applications such as data cleaning and user stitching. The state-of-the-art entity linkage pipelines mainly depend on supervised learning that requires abundant amounts of training data. However, collecting well-labeled training data becomes expensive when the data from many sources arrives incrementally over time. Moreover, the trained models can easily overfit to specific data sources, and thus fail to generalize to new sources due to significant differences in data and label distributions. To address these challenges, we present AdaMEL, a deep transfer learning framework that learns generic high-level knowledge to perform multi-source entity linkage. AdaMEL models the attribute importance that is used to match entities through an attribute-level self-attention mechanism, and leverages the massive unlabeled data from new data sources through domain adaptation to make it generic and data-source agnostic. In addition, AdaMEL is capable of incorporating an additional set of labeled data to more accurately integrate data sources with different attribute importance. Extensive experiments show that our framework achieves state-of-the-art results with 8.21% improvement on average over methods based on supervised learning. Besides, it is more stable in handling different sets of data sources in less runtime.",
                        "Citation Paper Authors": "Authors:Di Jin, Bunyamin Sisman, Hao Wei, Xin Luna Dong, Danai Koutra"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2011.15028v6": {
            "Paper Title": "The LDBC Graphalytics Benchmark",
            "Sentences": []
        },
        "http://arxiv.org/abs/2104.02234v8": {
            "Paper Title": "DeepEverest: Accelerating Declarative Top-K Queries for Deep Neural\n  Network Interpretation",
            "Sentences": [
                {
                    "Sentence ID": 45,
                    "Sentence": ",\nand uses a VGG16 network [ 30,47]. The second, called ImageNet-\nResNet50 , uses as inputs 10,000 images from the validation set of\nImageNet ",
                    "Citation Text": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean\nMa, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al .\n2015. ImageNet Large Scale Visual Recognition Challenge. International Journal\nof Computer Vision 115, 3 (2015), 211\u2013252.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1409.0575",
                        "Citation Paper Title": "Title:ImageNet Large Scale Visual Recognition Challenge",
                        "Citation Paper Abstract": "Abstract:The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions.\nThis paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.",
                        "Citation Paper Authors": "Authors:Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei"
                    }
                },
                {
                    "Sentence ID": 46,
                    "Sentence": ", and others [ 8,21,22,24,27,32,57] support visual\ninspection of ML models and features. These systems could utilize\nDeepEverest to accelerate some of the queries used to build the\nvisualizations. DeepBase ",
                    "Citation Text": "Thibault Sellam, Kevin Lin, Ian Huang, Michelle Yang, Carl Vondrick, and Eugene\nWu. 2019. DeepBase: Deep Inspection of Neural Networks. In Proceedings of the\n2019 International Conference on Management of Data . ACM, 1117\u20131134.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1808.04486",
                        "Citation Paper Title": "Title:DeepBase: Deep Inspection of Neural Networks",
                        "Citation Paper Abstract": "Abstract:Although deep learning models perform remarkably well across a range of tasks such as language translation and object recognition, it remains unclear what high-level logic, if any, they follow. Understanding this logic may lead to more transparency, better model design, and faster experimentation. Recent machine learning research has leveraged statistical methods to identify hidden units that behave (e.g., activate) similarly to human understandable logic, but those analyses require considerable manual effort. Our insight is that many of those studies follow a common analysis pattern, which we term Deep Neural Inspection. There is opportunity to provide a declarative abstraction to easily express, execute, and optimize them.\nThis paper describes DeepBase, a system to inspect neural network behaviors through a unified interface. We model logic with user-provided hypothesis functions that annotate the data with high-level labels (e.g., part-of-speech tags, image captions). DeepBase lets users quickly identify individual or groups of units that have strong statistical dependencies with desired hypotheses. We discuss how DeepBase can express existing analyses, propose a set of simple and effective optimizations to speed up a standard Python implementation by up to 72x, and reproduce recent studies from the NLP literature.",
                        "Citation Paper Authors": "Authors:Thibault Sellam, Kevin Lin, Ian Yiran Huang, Yiru Chen, Michelle Yang, Carl Vondrick, Eugene Wu"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2007.14997v2": {
            "Paper Title": "Aggregate Analytic Window Query over Spatial Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/2105.14435v4": {
            "Paper Title": "Convergence of Datalog over (Pre-) Semirings",
            "Sentences": []
        },
        "http://arxiv.org/abs/2103.07532v3": {
            "Paper Title": "Comprehensive and Comprehensible Data Catalogs: The What, Who, Where,\n  When, Why, and How of Metadata Management",
            "Sentences": []
        },
        "http://arxiv.org/abs/2003.06880v6": {
            "Paper Title": "Grammars for Document Spanners",
            "Sentences": [
                {
                    "Sentence ID": 23,
                    "Sentence": "based on( X,d)-\nmappings rather than on partial mappings as de\ufb01ned in ",
                    "Citation Text": "F. Maturana, C. Riveros, D. Vrgo\u02c7 c, Document spanners for extract-\ning incomplete information: Expressiveness and complexity, in: PODS ,\n2018, pp. 125\u2013136.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1707.00827",
                        "Citation Paper Title": "Title:Document Spanners for Extracting Incomplete Information: Expressiveness and Complexity",
                        "Citation Paper Abstract": "Abstract:Rule-based information extraction has lately received a fair amount of attention from the database community, with several languages appearing in the last few years. Although information extraction systems are intended to deal with semistructured data, all language proposals introduced so far are designed to output relations, thus making them incapable of handling incomplete information. To remedy the situation, we propose to extend information extraction languages with the ability to use mappings, thus allowing us to work with documents which have missing or optional parts. Using this approach, we simplify the semantics of regex formulas and extraction rules, two previously defined methods for extracting information, extend them with the ability to handle incomplete data, and study how they compare in terms of expressive power. We also study computational properties of these languages, focusing on the query enumeration problem, as well as satisfiability and containment.",
                        "Citation Paper Authors": "Authors:Francisco Maturana, Cristian Riveros, Domagoj Vrgo\u010d"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2111.10095v3": {
            "Paper Title": "An Index for Single Source All Destinations Distance Queries in Temporal\n  Graphs",
            "Sentences": [
                {
                    "Sentence ID": 55,
                    "Sentence": "intro-\nduce streaming algorithms for \fnding the fastest, short-\nest, latest departure, and earliest arrival paths. In ",
                    "Citation Text": "John Tang, Ilias Leontiadis, Salvatore Scellato, Vin-\ncenzo Nicosia, Cecilia Mascolo, Mirco Musolesi, and\nVito Latora. Applications of Temporal Graph Met-\nrics to Real-World Networks , pages 135{159. Springer,\nBerlin, Heidelberg, 2013.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1305.6974",
                        "Citation Paper Title": "Title:Applications of Temporal Graph Metrics to Real-World Networks",
                        "Citation Paper Abstract": "Abstract:Real world networks exhibit rich temporal information: friends are added and removed over time in online social networks; the seasons dictate the predator-prey relationship in food webs; and the propagation of a virus depends on the network of human contacts throughout the day. Recent studies have demonstrated that static network analysis is perhaps unsuitable in the study of real world network since static paths ignore time order, which, in turn, results in static shortest paths overestimating available links and underestimating their true corresponding lengths. Temporal extensions to centrality and efficiency metrics based on temporal shortest paths have also been proposed. Firstly, we analyse the roles of key individuals of a corporate network ranked according to temporal centrality within the context of a bankruptcy scandal; secondly, we present how such temporal metrics can be used to study the robustness of temporal networks in presence of random errors and intelligent attacks; thirdly, we study containment schemes for mobile phone malware which can spread via short range radio, similar to biological viruses; finally, we study how the temporal network structure of human interactions can be exploited to effectively immunise human populations. Through these applications we demonstrate that temporal metrics provide a more accurate and effective analysis of real-world networks compared to their static counterparts.",
                        "Citation Paper Authors": "Authors:John Tang, Ilias Leontiadis, Salvatore Scellato, Vincenzo Nicosia, Cecilia Mascolo, Mirco Musolesi, Vito Latora"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2008.00842v2": {
            "Paper Title": "A Survey on the Evolution of Stream Processing Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/2109.07260v3": {
            "Paper Title": "Evaluation of Distributed Databases in Hybrid Clouds and Edge Computing:\n  Energy, Bandwidth, and Storage Consumption",
            "Sentences": []
        },
        "http://arxiv.org/abs/2105.08842v2": {
            "Paper Title": "rx-anon -- A Novel Approach on the De-Identification of Heterogeneous\n  Data based on a Modified Mondrian Algorithm",
            "Sentences": [
                {
                    "Sentence ID": 28,
                    "Sentence": "suggested to use trans-\nformers for NER tasks as an improvement to BiLSTM networks. In\naddition, Khan et al . ",
                    "Citation Text": "Muhammad Raza Khan, Morteza Ziyadi, and Mohamed AbdelHady. 2020. MT-\nBioNER: Multi-task Learning for Biomedical Named Entity Recognition using\nDeep Bidirectional Transformers. (2020). arXiv:2001.08904",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2001.08904",
                        "Citation Paper Title": "Title:MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition using Deep Bidirectional Transformers",
                        "Citation Paper Abstract": "Abstract:Conversational agents such as Cortana, Alexa and Siri are continuously working on increasing their capabilities by adding new domains. The support of a new domain includes the design and development of a number of NLU components for domain classification, intents classification and slots tagging (including named entity recognition). Each component only performs well when trained on a large amount of labeled data. Second, these components are deployed on limited-memory devices which requires some model compression. Third, for some domains such as the health domain, it is hard to find a single training data set that covers all the required slot types. To overcome these mentioned problems, we present a multi-task transformer-based neural architecture for slot tagging. We consider the training of a slot tagger using multiple data sets covering different slot types as a multi-task learning problem. The experimental results on the biomedical domain have shown that the proposed approach outperforms the previous state-of-the-art systems for slot tagging on the different benchmark biomedical datasets in terms of (time and memory) efficiency and effectiveness. The output slot tagger can be used by the conversational agent to better identify entities in the input utterances.",
                        "Citation Paper Authors": "Authors:Muhammad Raza Khan, Morteza Ziyadi, Mohamed AbdelHady"
                    }
                },
                {
                    "Sentence ID": 62,
                    "Sentence": "raises the question, whether transformers can also lead to advances\nin anonymizing free texts. Yan et al . ",
                    "Citation Text": "Hang Yan, Bocao Deng, Xiaonan Li, and Xipeng Qiu. 2019. TENER: Adapting\nTransformer Encoder for Named Entity Recognition. (2019). arXiv:1911.04474",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1911.04474",
                        "Citation Paper Title": "Title:TENER: Adapting Transformer Encoder for Named Entity Recognition",
                        "Citation Paper Abstract": "Abstract:The Bidirectional long short-term memory networks (BiLSTM) have been widely used as an encoder in models solving the named entity recognition (NER) task. Recently, the Transformer is broadly adopted in various Natural Language Processing (NLP) tasks owing to its parallelism and advantageous performance. Nevertheless, the performance of the Transformer in NER is not as good as it is in other NLP tasks. In this paper, we propose TENER, a NER architecture adopting adapted Transformer Encoder to model the character-level features and word-level features. By incorporating the direction and relative distance aware attention and the un-scaled attention, we prove the Transformer-like encoder is just as effective for NER as other NLP tasks.",
                        "Citation Paper Authors": "Authors:Hang Yan, Bocao Deng, Xiaonan Li, Xipeng Qiu"
                    }
                },
                {
                    "Sentence ID": 8,
                    "Sentence": "introduced an integrated\nsystem which uses Conditional Random Fields ( CRF) to identify PII.\nDernoncourt et al . ",
                    "Citation Text": "Franck Dernoncourt, Ji Young Lee, Ozlem Uzuner, and Peter Szolovits. 2017. De-\nidentification of patient notes with recurrent neural networks. J. of the American\nMedical Informatics Association 24, 3 (2017), 596\u2013606. arXiv:1606.03475",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1606.03475",
                        "Citation Paper Title": "Title:De-identification of Patient Notes with Recurrent Neural Networks",
                        "Citation Paper Abstract": "Abstract:Objective: Patient notes in electronic health records (EHRs) may contain critical information for medical investigations. However, the vast majority of medical investigators can only access de-identified notes, in order to protect the confidentiality of patients. In the United States, the Health Insurance Portability and Accountability Act (HIPAA) defines 18 types of protected health information (PHI) that needs to be removed to de-identify patient notes. Manual de-identification is impractical given the size of EHR databases, the limited number of researchers with access to the non-de-identified notes, and the frequent mistakes of human annotators. A reliable automated de-identification system would consequently be of high value.\nMaterials and Methods: We introduce the first de-identification system based on artificial neural networks (ANNs), which requires no handcrafted features or rules, unlike existing systems. We compare the performance of the system with state-of-the-art systems on two datasets: the i2b2 2014 de-identification challenge dataset, which is the largest publicly available de-identification dataset, and the MIMIC de-identification dataset, which we assembled and is twice as large as the i2b2 2014 dataset.\nResults: Our ANN model outperforms the state-of-the-art systems. It yields an F1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision of 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with a recall 99.25 and a precision of 99.06.\nConclusion: Our findings support the use of ANNs for de-identification of patient notes, as they show better performance than previously published systems while requiring no feature engineering.",
                        "Citation Paper Authors": "Authors:Franck Dernoncourt, Ji Young Lee, Ozlem Uzuner, Peter Szolovits"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2112.13736v3": {
            "Paper Title": "How do centrality measures choose the root of trees?",
            "Sentences": []
        },
        "http://arxiv.org/abs/2012.11965v4": {
            "Paper Title": "Tractable Orders for Direct Access to Ranked Answers of Conjunctive\n  Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/1904.07693v3": {
            "Paper Title": "Frequent Itemset Mining using QUBO",
            "Sentences": []
        },
        "http://arxiv.org/abs/2105.07597v3": {
            "Paper Title": "Variational Bandwidth Auto-encoder for Hybrid Recommender Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/2105.13336v5": {
            "Paper Title": "TENSILE: A Tensor granularity dynamic GPU memory scheduling method\n  toward multiple dynamic workloads system",
            "Sentences": []
        },
        "http://arxiv.org/abs/2111.12493v3": {
            "Paper Title": "Time and Memory Efficient Parallel Algorithm for Structural Graph\n  Summaries and two Extensions to Incremental Summarization and\n  $k$-Bisimulation for Long $k$-Chaining",
            "Sentences": []
        },
        "http://arxiv.org/abs/2111.06806v3": {
            "Paper Title": "First-Order Rewritability and Complexity of Two-Dimensional Temporal\n  Ontology-Mediated Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/2107.00938v2": {
            "Paper Title": "Instagrammable Data: Using Visuals to Showcase More Than Numbers on AJ\n  Labs Instagram Page",
            "Sentences": []
        },
        "http://arxiv.org/abs/2102.10185v4": {
            "Paper Title": "Cornus: Atomic Commit for a Cloud DBMS with Storage Disaggregation\n  (Extended Version)",
            "Sentences": []
        },
        "http://arxiv.org/abs/2107.01963v7": {
            "Paper Title": "PandaDB: Understanding Unstructured Data in Graph Database",
            "Sentences": [
                {
                    "Sentence ID": 30,
                    "Sentence": ". A collaborative\nquery is decomposed into several sub-queries on different\nmodules. Usually, a vector search engine is built for vector\nsimilarity search ",
                    "Citation Text": "J. Johnson, M. Douze, and H. J \u00b4egou, \u201cBillion-scale similarity search\nwith gpus,\u201d IEEE Transactions on Big Data , 2019.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1702.08734",
                        "Citation Paper Title": "Title:Billion-scale similarity search with GPUs",
                        "Citation Paper Abstract": "Abstract:Similarity search finds application in specialized database systems handling complex data such as images or videos, which are typically represented by high-dimensional features and require specific indexing structures. This paper tackles the problem of better utilizing GPUs for this task. While GPUs excel at data-parallel tasks, prior approaches are bottlenecked by algorithms that expose less parallelism, such as k-min selection, or make poor use of the memory hierarchy.\nWe propose a design for k-selection that operates at up to 55% of theoretical peak performance, enabling a nearest neighbor implementation that is 8.5x faster than prior GPU state of the art. We apply it in different similarity search scenarios, by proposing optimized design for brute-force, approximate and compressed-domain search based on product quantization. In all these setups, we outperform the state of the art by large margins. Our implementation enables the construction of a high accuracy k-NN graph on 95 million images from the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced our approach for the sake of comparison and reproducibility.",
                        "Citation Paper Authors": "Authors:Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou"
                    }
                },
                {
                    "Sentence ID": 13,
                    "Sentence": "are widely adopted for cloud and on-premise\nusage and focus on the querying and management of graph\ndata ",
                    "Citation Text": "R. Angles, M. Arenas, P. Barcel \u00b4o, P. Boncz, G. Fletcher, C. Gutierrez,\nT. Lindaaker, M. Paradies, S. Plantikow, J. Sequeda et al. , \u201cG-core:A core for future graph query languages,\u201d in Proceedings of the 2018\nInternational Conference on Management of Data , 2018, pp. 1421\u20131432.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1712.01550",
                        "Citation Paper Title": "Title:G-CORE: A Core for Future Graph Query Languages",
                        "Citation Paper Abstract": "Abstract:We report on a community effort between industry and academia to shape the future of graph query languages. We argue that existing graph database management systems should consider supporting a query language with two key characteristics. First, it should be composable, meaning, that graphs are the input and the output of queries. Second, the graph query language should treat paths as first-class citizens. Our result is G-CORE, a powerful graph query language design that fulfills these goals, and strikes a careful balance between path query expressivity and evaluation complexity.",
                        "Citation Paper Authors": "Authors:Renzo Angles, Marcelo Arenas, Pablo Barcel\u00f3, Peter Boncz, George H. L. Fletcher, Claudio Gutierrez, Tobias Lindaaker, Marcus Paradies, Stefan Plantikow, Juan Sequeda, Oskar van Rest, Hannes Voigt"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2106.01543v4": {
            "Paper Title": "Ver: View Discovery in the Wild",
            "Sentences": []
        },
        "http://arxiv.org/abs/2111.09917v2": {
            "Paper Title": "Interactive Set Discovery",
            "Sentences": [
                {
                    "Sentence ID": 3,
                    "Sentence": "shows the polynomial learnability of con-\njunctions of horn clauses and Abouzied et al. ",
                    "Citation Text": "Azza Abouzied, Dana Angluin, Christos Papadimitriou, Joseph Hellerstein, and\nAvi Silberschatz. 2013. Learning and Verifying Quantified Boolean Queries by\nExample. Proceedings of the PODS Conference (04 2013). https://doi.org/10.1145/\n2463664.2465220",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1304.4303",
                        "Citation Paper Title": "Title:Learning and Verifying Quantified Boolean Queries by Example",
                        "Citation Paper Abstract": "Abstract:To help a user specify and verify quantified queries --- a class of database queries known to be very challenging for all but the most expert users --- one can question the user on whether certain data objects are answers or non-answers to her intended query. In this paper, we analyze the number of questions needed to learn or verify qhorn queries, a special class of Boolean quantified queries whose underlying form is conjunctions of quantified Horn expressions. We provide optimal polynomial-question and polynomial-time learning and verification algorithms for two subclasses of the class qhorn with upper constant limits on a query's causal density.",
                        "Citation Paper Authors": "Authors:Azza Abouzied, Dana Angluin, Christos Papadimitriou, Joseph M. Hellerstein, Avi Silberschatz"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2112.08638v4": {
            "Paper Title": "Evaluating Hybrid Graph Pattern Queries Using Runtime Index Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/2103.06766v2": {
            "Paper Title": "Stable Tuple Embeddings for Dynamic Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.00152v3": {
            "Paper Title": "Efficient sorting, duplicate removal, grouping, and aggregation",
            "Sentences": []
        },
        "http://arxiv.org/abs/2107.09480v6": {
            "Paper Title": "Learned Sorted Table Search and Static Indexes in Small Model Space",
            "Sentences": [
                {
                    "Sentence ID": 24,
                    "Sentence": ".\n1.1.1 Core Methods and Benchmarking Platform\nThe Recursive Model Index ",
                    "Citation Text": "T. Kraska, A. Beutel, E. H Chi, J. Dean, and N. Polyzotis. The case for learned index structures. In\nProceedings of the 2018 International Conference on Management of Data , pages 489\u2013504. ACM, 2018.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1712.01208",
                        "Citation Paper Title": "Title:The Case for Learned Index Structures",
                        "Citation Paper Abstract": "Abstract:Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.",
                        "Citation Paper Authors": "Authors:Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, Neoklis Polyzotis"
                    }
                },
                {
                    "Sentence ID": 16,
                    "Sentence": ", extended with several\nvariants in [11,34,43] and more in-depth analysed by Fumagalli et al. ",
                    "Citation Text": "G. Fumagalli, D. Raimondi, R. Giancarlo, D. Malchiodi, and M. Frasca. On the choice of general\npurpose classi\ufb01ers in learned bloom \ufb01lters: An initial analysis within basic \ufb01lters. In Proceedings of\nthe 11th International Conference on Pattern Recognition Applications and Methods (ICPRAM) , pages\n675\u2013682, 2022.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2112.06563",
                        "Citation Paper Title": "Title:On the Choice of General Purpose Classifiers in Learned Bloom Filters: An Initial Analysis Within Basic Filters",
                        "Citation Paper Abstract": "Abstract:Bloom Filters are a fundamental and pervasive data structure. Within the growing area of Learned Data Structures, several Learned versions of Bloom Filters have been considered, yielding advantages over classic Filters. Each of them uses a classifier, which is the Learned part of the data structure. Although it has a central role in those new filters, and its space footprint as well as classification time may affect the performance of the Learned Filter, no systematic study of which specific classifier to use in which circumstances is available. We report progress in this area here, providing also initial guidelines on which classifier to choose among five classic classification paradigms.",
                        "Citation Paper Authors": "Authors:Giacomo Fumagalli, Davide Raimondi, Raffaele Giancarlo, Dario Malchiodi, Marco Frasca"
                    }
                },
                {
                    "Sentence ID": 46,
                    "Sentence": ". As a consequence, Learned Indexes can also make improvements in various related applications.\nIn particular, they are widely used for Databases, providing new challenges and opportunities ",
                    "Citation Text": "W. Wang, M. Zhang, G. Chen, H. V. Jagadish, B. C. Ooi, and K. Tan. Database meets deep learning:\nChallenges and opportunities. SIGMOD Rec. , 45(2):17\u201322, sep 2016.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1906.08986",
                        "Citation Paper Title": "Title:Database Meets Deep Learning: Challenges and Opportunities",
                        "Citation Paper Abstract": "Abstract:Deep learning has recently become very popular on account of its incredible success in many complex data-driven applications, such as image classification and speech recognition. The database community has worked on data-driven applications for many years, and therefore should be playing a lead role in supporting this new wave. However, databases and deep learning are different in terms of both techniques and applications. In this paper, we discuss research problems at the intersection of the two fields. In particular, we discuss possible improvements for deep learning systems from a database perspective, and analyze database applications that may benefit from deep learning techniques.",
                        "Citation Paper Authors": "Authors:Wei Wang, Meihui Zhang, Gang Chen, H. V. Jagadish, Beng Chin Ooi, Kian-Lee Tan"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2109.00720v5": {
            "Paper Title": "LightNER: A Lightweight Tuning Paradigm for Low-resource NER via\n  Pluggable Prompting",
            "Sentences": []
        },
        "http://arxiv.org/abs/2101.08819v2": {
            "Paper Title": "Saguaro: An Edge Computing-Enabled Hierarchical Permissioned Blockchain",
            "Sentences": [
                {
                    "Sentence ID": 56,
                    "Sentence": "improves performance by leveraging parallel execution of transactions. Several recent permis-\nsioned blockchains, e.g., blockchain relational database ",
                    "Citation Text": "S. Nathan, C. Govindarajan, A. Saraf, M. Sethi, and P. Jayachandran. Blockchain meets database:\ndesign and implementation of a blockchain relational database. Proceedings of the VLDB Endowment ,\n12(11):1539\u20131552, 2019.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1903.01919",
                        "Citation Paper Title": "Title:Blockchain Meets Database: Design and Implementation of a Blockchain Relational Database",
                        "Citation Paper Abstract": "Abstract:In this paper, we design and implement the first-ever decentralized replicated relational database with blockchain properties that we term blockchain relational database. We highlight several similarities between features provided by blockchain platforms and a replicated relational database, although they are conceptually different, primarily in their trust model. Motivated by this, we leverage the rich features, decades of research and optimization, and available tooling in relational databases to build a blockchain relational database. We consider a permissioned blockchain model of known, but mutually distrustful organizations each operating their own database instance that are replicas of one another. The replicas execute transactions independently and engage in decentralized consensus to determine the commit order for transactions. We design two approaches, the first where the commit order for transactions is agreed upon prior to executing them, and the second where transactions are executed without prior knowledge of the commit order while the ordering happens in parallel. We leverage serializable snapshot isolation (SSI) to guarantee that the replicas across nodes remain consistent and respect the ordering determined by consensus, and devise a new variant of SSI based on block height for the latter approach. We implement our system on PostgreSQL and present detailed performance experiments analyzing both approaches.",
                        "Citation Paper Authors": "Authors:Senthil Nathan, Chander Govindarajan, Adarsh Saraf, Manish Sethi, Praveen Jayachandran"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2106.08166v3": {
            "Paper Title": "Query Embedding on Hyper-relational Knowledge Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/2107.10407v3": {
            "Paper Title": "Designing a Location Trace Anonymization Contest",
            "Sentences": [
                {
                    "Sentence ID": 4,
                    "Sentence": ", where\ud835\udf05is the\nsize of input domain ( \ud835\udf05=1024 in our experiments). It outputs\nthe original region with probability\ud835\udc52\ud835\udf00\n\ud835\udf05\u22121+\ud835\udc52\ud835\udf00, and outputs\nanother region at random with the remaining probability. It\nprovides\ud835\udf00-DP for each region.\n\u2022PL(\ud835\udc59,\ud835\udc5f): The planar Laplace mechanism ",
                    "Citation Text": "Miguel E. Andr\u00e9s, Nicol\u00e1s E. Bordenabe, Konstantinos Chatzikokolakis, and\nCatuscia Palamidessi. 2013. Geo-Indistinguishability: Differential Privacy for\nLocation-based Systems. In Proceedings of the 20th ACM Conference on Computer\nand Communications Security (CCS\u201913) . 901\u2013914.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1212.1984",
                        "Citation Paper Title": "Title:Geo-Indistinguishability: Differential Privacy for Location-Based Systems",
                        "Citation Paper Abstract": "Abstract:The growing popularity of location-based systems, allowing unknown/untrusted servers to easily collect huge amounts of information regarding users' location, has recently started raising serious privacy concerns. In this paper we study geo-indistinguishability, a formal notion of privacy for location-based systems that protects the user's exact location, while allowing approximate information - typically needed to obtain a certain desired service - to be released. Our privacy definition formalizes the intuitive notion of protecting the user's location within a radius r with a level of privacy that depends on r, and corresponds to a generalized version of the well-known concept of differential privacy. Furthermore, we present a perturbation technique for achieving geo-indistinguishability by adding controlled random noise to the user's location. We demonstrate the applicability of our technique on a LBS application. Finally, we compare our mechanism with other ones in the literature. It turns our that our mechanism offers the best privacy guarantees, for the same utility, among all those which do not depend on the prior.",
                        "Citation Paper Authors": "Authors:Miguel E. Andr\u00e9s, Nicol\u00e1s E. Bordenabe, Konstantinos Chatzikokolakis, Catuscia Palamidessi"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2008.06824v4": {
            "Paper Title": "Conjunctive Queries: Unique Characterizations and Exact Learnability",
            "Sentences": [
                {
                    "Sentence ID": 20,
                    "Sentence": "fora weakerversion ofthe questio n, namelyforthe description logic\nEL,whenthelearningalgorithmisalso allowedtoaskequivalence queries. In ",
                    "Citation Text": "Maurice Funk, Jean Christoph Jung, and Carsten Lutz. Frontiers and exact learning of eli queries under dl-lite on-\ntologies. InLudDeRaedt,editor, ProceedingsoftheThirty-First InternationalJoint Confe renceonArti\ufb01cialIntelligence,\nIJCAI-22,pages2627\u20132633.InternationalJointConferencesonArti\ufb01cialIntell igenceOrganization,72022.MainTrack.\ndoi:10.24963/ijcai.2022/364 .",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2204.14172",
                        "Citation Paper Title": "Title:Frontiers and Exact Learning of ELI Queries under DL-Lite Ontologies",
                        "Citation Paper Abstract": "Abstract:We study ELI queries (ELIQs) in the presence of ontologies formulated in the description logic DL-Lite. For the dialect DL-LiteH, we show that ELIQs have a frontier (set of least general generalizations) that is of polynomial size and can be computed in polynomial time. In the dialect DL-LiteF, in contrast, frontiers may be infinite. We identify a natural syntactic restriction that enables the same positive results as for DL-LiteH. We use out results on frontiers to show that ELIQs are learnable in polynomial time in the presence of a DL-LiteH / restricted DL-LiteF ontology in Angluin's framework of exact learning with only membership queries.",
                        "Citation Paper Authors": "Authors:Maurice Funk, Jean Christoph Jung, Carsten Lutz"
                    }
                },
                {
                    "Sentence ID": 19,
                    "Sentence": "(in which we asked the same question), some answers\nhavebeenobtained.In ",
                    "Citation Text": "Maurice Funk, Jean Christoph Jung, and Carsten Lutz. Actively learning concepts and conjunctive queries under\nelr-ontologies. In IJCAI,2021.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2105.08326",
                        "Citation Paper Title": "Title:Actively Learning Concepts and Conjunctive Queries under ELr-Ontologies",
                        "Citation Paper Abstract": "Abstract:We consider the problem to learn a concept or a query in the presence of an ontology formulated in the description logic ELr, in Angluin's framework of active learning that allows the learning algorithm to interactively query an oracle (such as a domain expert). We show that the following can be learned in polynomial time: (1) EL-concepts, (2) symmetry-free ELI-concepts, and (3) conjunctive queries (CQs) that are chordal, symmetry-free, and of bounded arity. In all cases, the learner can pose to the oracle membership queries based on ABoxes and equivalence queries that ask whether a given concept/query from the considered class is equivalent to the target. The restriction to bounded arity in (3) can be removed when we admit unrestricted CQs in equivalence queries. We also show that EL-concepts are not polynomial query learnable in the presence of ELI-ontologies.",
                        "Citation Paper Authors": "Authors:Maurice Funk, Jean Christoph Jung, Carsten Lutz"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2110.00516v2": {
            "Paper Title": "LEMON: Explainable Entity Matching",
            "Sentences": [
                {
                    "Sentence ID": 14,
                    "Sentence": ".\nA particularly prominent group of approaches are local\npost hoc attribution methods (e.g., ",
                    "Citation Text": "M. T. Ribeiro, S. Singh, and C. Guestrin, \u201c\u201dWhy Should I Trust\nYou?\u201d: Explaining the Predictions of Any Classi\ufb01er,\u201d in Proc. KDD\n2016 . ACM, Aug. 2016, pp. 1135\u20131144.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1602.04938",
                        "Citation Paper Title": "Title:\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier",
                        "Citation Paper Abstract": "Abstract:Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.",
                        "Citation Paper Authors": "Authors:Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2107.09110v4": {
            "Paper Title": "OnlineSTL: Scaling Time Series Decomposition by 100x",
            "Sentences": []
        },
        "http://arxiv.org/abs/2110.08633v7": {
            "Paper Title": "Hydra: A System for Large Multi-Model Deep Learning",
            "Sentences": [
                {
                    "Sentence ID": 50,
                    "Sentence": "in particular has been a popular technique for reducing memory footprints at\ninference time. The goal of such systems is orthogonal to our own, and memory footprint reduction\ntechniques could be integrated into HYDRA in the future. One system ",
                    "Citation Text": "Greg Yang, Edward J. Hu, Igor Babuschkin, Szymon Sidor, Xiaodong Liu, David Farhi, Nick\nRyder, Jakub Pachocki, Weizhu Chen, and Jianfeng Gao. Tensor programs v: Tuning large\nneural networks via zero-shot hyperparameter transfer. 2022.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2203.03466",
                        "Citation Paper Title": "Title:Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer",
                        "Citation Paper Abstract": "Abstract:Hyperparameter (HP) tuning in deep learning is an expensive process, prohibitively so for neural networks (NNs) with billions of parameters. We show that, in the recently discovered Maximal Update Parametrization (muP), many optimal HPs remain stable even as model size changes. This leads to a new HP tuning paradigm we call muTransfer: parametrize the target model in muP, tune the HP indirectly on a smaller model, and zero-shot transfer them to the full-sized model, i.e., without directly tuning the latter at all. We verify muTransfer on Transformer and ResNet. For example, 1) by transferring pretraining HPs from a model of 13M parameters, we outperform published numbers of BERT-large (350M parameters), with a total tuning cost equivalent to pretraining BERT-large once; 2) by transferring from 40M parameters, we outperform published numbers of the 6.7B GPT-3 model, with tuning cost only 7% of total pretraining cost. A Pytorch implementation of our technique can be found at this http URL and installable via `pip install mup`.",
                        "Citation Paper Authors": "Authors:Greg Yang, Edward J. Hu, Igor Babuschkin, Szymon Sidor, Xiaodong Liu, David Farhi, Nick Ryder, Jakub Pachocki, Weizhu Chen, Jianfeng Gao"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2109.04881v2": {
            "Paper Title": "ProcK: Machine Learning for Knowledge-Intensive Processes",
            "Sentences": []
        },
        "http://arxiv.org/abs/2007.10568v3": {
            "Paper Title": "Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning",
            "Sentences": []
        },
        "http://arxiv.org/abs/2009.06207v8": {
            "Paper Title": "Contrastive Triple Extraction with Generative Transformer",
            "Sentences": []
        },
        "http://arxiv.org/abs/2104.09809v2": {
            "Paper Title": "Inference of Common Multidimensional Equally-Distributed Attributes",
            "Sentences": []
        },
        "http://arxiv.org/abs/2107.10836v2": {
            "Paper Title": "Qanaat: A Scalable Multi-Enterprise Permissioned Blockchain System with\n  Confidentiality Guarantees",
            "Sentences": []
        },
        "http://arxiv.org/abs/2112.00833v3": {
            "Paper Title": "AWESOME: Empowering Scalable Data Science on Social Media Data with an\n  Optimized Tri-Store Data System",
            "Sentences": []
        },
        "http://arxiv.org/abs/2108.13557v3": {
            "Paper Title": "Towards Observability for Production Machine Learning Pipelines",
            "Sentences": [
                {
                    "Sentence ID": 81,
                    "Sentence": "; recent\nwork has extended it to work in an approximate setting, while opti-\nmizing for metrics like coverage ",
                    "Citation Text": "M. Joglekar, H. Garcia-Molina, and A. Parameswaran, \u201cInteractive data explo-\nration with smart drill-down,\u201d IEEE Transactions on Knowledge and Data Engi-\nneering , vol. 31, no. 1, pp. 46\u201360, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1412.0364",
                        "Citation Paper Title": "Title:Interactive Data Exploration with Smart Drill-Down",
                        "Citation Paper Abstract": "Abstract:We present {\\em smart drill-down}, an operator for interactively exploring a relational table to discover and summarize \"interesting\" groups of tuples. Each group of tuples is described by a {\\em rule}. For instance, the rule $(a, b, \\star, 1000)$ tells us that there are a thousand tuples with value $a$ in the first column and $b$ in the second column (and any value in the third column). Smart drill-down presents an analyst with a list of rules that together describe interesting aspects of the table. The analyst can tailor the definition of interesting, and can interactively apply smart drill-down on an existing rule to explore that part of the table. We demonstrate that the underlying optimization problems are {\\sc NP-Hard}, and describe an algorithm for finding the approximately optimal list of rules to display when the user uses a smart drill-down, and a dynamic sampling scheme for efficiently interacting with large tables. Finally, we perform experiments on real datasets on our experimental prototype to demonstrate the usefulness of smart drill-down and study the performance of our algorithms.",
                        "Citation Paper Authors": "Authors:Manas Joglekar, Hector Garcia-Molina, Aditya Parameswaran"
                    }
                },
                {
                    "Sentence ID": 68,
                    "Sentence": "; however, it is unrealistic to\nassume such access, especially for a bolt-on observability system. A\nsolution idea is to learn an autoregressive model ",
                    "Citation Text": "Z. Yang, E. Liang, A. Kamsetty, C. Wu, Y. Duan, X. Chen, P. Abbeel, J. M.\nHellerstein, S. Krishnan, and I. Stoica, \u201cDeep unsupervised cardinality estimation,\u201d\nProc. VLDB Endow. , vol. 13, no. 3, p. 279\u2013292, nov 2019. [Online]. Available:\nhttps://doi.org/10.14778/3368289.3368294",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1905.04278",
                        "Citation Paper Title": "Title:Deep Unsupervised Cardinality Estimation",
                        "Citation Paper Abstract": "Abstract:Cardinality estimation has long been grounded in statistical tools for density estimation. To capture the rich multivariate distributions of relational tables, we propose the use of a new type of high-capacity statistical model: deep autoregressive models. However, direct application of these models leads to a limited estimator that is prohibitively expensive to evaluate for range or wildcard predicates. To produce a truly usable estimator, we develop a Monte Carlo integration scheme on top of autoregressive models that can efficiently handle range queries with dozens of dimensions or more.\nLike classical synopses, our estimator summarizes the data without supervision. Unlike previous solutions, we approximate the joint data distribution without any independence assumptions. Evaluated on real-world datasets and compared against real systems and dominant families of techniques, our estimator achieves single-digit multiplicative error at tail, an up to 90$\\times$ accuracy improvement over the second best method, and is space- and runtime-efficient.",
                        "Citation Paper Authors": "Authors:Zongheng Yang, Eric Liang, Amog Kamsetty, Chenggang Wu, Yan Duan, Xi Chen, Pieter Abbeel, Joseph M. Hellerstein, Sanjay Krishnan, Ion Stoica"
                    }
                },
                {
                    "Sentence ID": 41,
                    "Sentence": "in Approximate\nQuery Processing (AQP) [ 39,40], and also ensemble schemes ",
                    "Citation Text": "X. Liang, S. Sintos, Z. Shang, and S. Krishnan, Combining Aggregation and\nSampling (Nearly) Optimally for Approximate Query Processing . New York,\nNY, USA: Association for Computing Machinery, 2021, p. 1129\u20131141. [Online].\nAvailable: https://doi.org/10.1145/3448016.3457277Shreya Shankar and Aditya G. Parameswaran",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2103.15994",
                        "Citation Paper Title": "Title:Combining Aggregation and Sampling (Nearly) Optimally for Approximate Query Processing",
                        "Citation Paper Abstract": "Abstract:Sample-based approximate query processing (AQP) suffers from many pitfalls such as the inability to answer very selective queries and unreliable confidence intervals when sample sizes are small. Recent research presented an intriguing solution of combining materialized, pre-computed aggregates with sampling for accurate and more reliable AQP. We explore this solution in detail in this work and propose an AQP physical design called PASS, or Precomputation-Assisted Stratified Sampling. PASS builds a tree of partial aggregates that cover different partitions of the dataset. The leaf nodes of this tree form the strata for stratified samples. Aggregate queries whose predicates align with the partitions (or unions of partitions) are exactly answered with a depth-first search, and any partial overlaps are approximated with the stratified samples. We propose an algorithm for optimally partitioning the data into such a data structure with various practical approximation techniques.",
                        "Citation Paper Authors": "Authors:Xi Liang, Stavros Sintos, Zechao Shang, Sanjay Krishnan"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2101.06801v2": {
            "Paper Title": "Real-Time LSM-Trees for HTAP Workloads",
            "Sentences": [
                {
                    "Sentence ID": 10,
                    "Sentence": "is a hash index for key-value pairs where\nthe metadata, such as index pages, cannot be fully cached. Finally,\nthe LSM-based tuple compaction framework in AsterixDB ",
                    "Citation Text": "Wail Y. Alkowaileet, Sattam Alsubaiee, and Michael J. Carey. 2020. An LSM-based\nTuple Compaction Framework for Apache AsterixDB. Proc. VLDB Endow. 13, 9\n(2020), 1388\u20131400. http://www.vldb.org/pvldb/vol13/p1388-alkowaileet.pdf",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1910.08185",
                        "Citation Paper Title": "Title:An LSM-based Tuple Compaction Framework for Apache AsterixDB (Extended Version)",
                        "Citation Paper Abstract": "Abstract:Document database systems store self-describing semi-structured records, such as JSON, \"as-is\" without requiring the users to pre-define a schema. This provides users with the flexibility to change the structure of incoming records without worrying about taking the system offline or hindering the performance of currently running queries. However, the flexibility of such systems does not free. The large amount of redundancy in the records can introduce an unnecessary storage overhead and impact query performance.\nOur focus in this paper is to address the storage overhead issue by introducing a tuple compactor framework that infers and extracts the schema from self-describing semi-structured records during the data ingestion. As many prominent document stores, such as MongoDB and Couchbase, adopt Log Structured Merge (LSM) trees in their storage engines, our framework exploits LSM lifecycle events to piggyback the schema inference and extraction operations. We have implemented and empirically evaluated our approach to measure its impact on storage, data ingestion, and query performance in the context of Apache AsterixDB.",
                        "Citation Paper Authors": "Authors:Wail Y. Alkowaileet, Sattam Alsubaiee, Michael J. Carey"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2112.09290v2": {
            "Paper Title": "PeopleSansPeople: A Synthetic Data Generator for Human-Centric Computer\n  Vision",
            "Sentences": [
                {
                    "Sentence ID": 34,
                    "Sentence": ", existing games like GTA V [ 31,32,33], or game engines ",
                    "Citation Text": "Cesar Roberto de Souza, Adrien Gaidon, Yohann Cabon, and Antonio Manuel Lopez. Procedural\ngeneration of videos to train deep action recognition networks. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition , pages 4757\u20134767, 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1612.00881",
                        "Citation Paper Title": "Title:Procedural Generation of Videos to Train Deep Action Recognition Networks",
                        "Citation Paper Abstract": "Abstract:Deep learning for human action recognition in videos is making significant progress, but is slowed down by its dependency on expensive manual labeling of large video collections. In this work, we investigate the generation of synthetic training data for action recognition, as it has recently shown promising results for a variety of other computer vision tasks. We propose an interpretable parametric generative model of human action videos that relies on procedural generation and other computer graphics techniques of modern game engines. We generate a diverse, realistic, and physically plausible dataset of human action videos, called PHAV for \"Procedural Human Action Videos\". It contains a total of 39,982 videos, with more than 1,000 examples for each action of 35 categories. Our approach is not limited to existing motion capture sequences, and we procedurally define 14 synthetic actions. We introduce a deep multi-task representation learning architecture to mix synthetic and real videos, even if the action categories differ. Our experiments on the UCF101 and HMDB51 benchmarks suggest that combining our large set of synthetic videos with small real-world datasets can boost recognition performance, significantly outperforming fine-tuning state-of-the-art unsupervised generative models of videos.",
                        "Citation Paper Authors": "Authors:C\u00e9sar Roberto de Souza, Adrien Gaidon, Yohann Cabon, Antonio Manuel L\u00f3pez Pe\u00f1a"
                    }
                },
                {
                    "Sentence ID": 23,
                    "Sentence": "focus largely on embodied AI tasks. More generic tools\nfor object detection dataset generation include BlenderProc ",
                    "Citation Text": "Maximilian Denninger, Martin Sundermeyer, Dominik Winkelbauer, Youssef Zidan, Dmitry\nOle\ufb01r, Mohamad Elbadrawy, Ahsan Lodhi, and Harinandan Katam. Blenderproc. arXiv preprint\narXiv:1911.01911 , 2019.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1911.01911",
                        "Citation Paper Title": "Title:BlenderProc",
                        "Citation Paper Abstract": "Abstract:BlenderProc is a modular procedural pipeline, which helps in generating real looking images for the training of convolutional neural networks. These can be used in a variety of use cases including segmentation, depth, normal and pose estimation and many others. A key feature of our extension of blender is the simple to use modular pipeline, which was designed to be easily extendable. By offering standard modules, which cover a variety of scenarios, we provide a starting point on which new modules can be created.",
                        "Citation Paper Authors": "Authors:Maximilian Denninger, Martin Sundermeyer, Dominik Winkelbauer, Youssef Zidan, Dmitry Olefir, Mohamad Elbadrawy, Ahsan Lodhi, Harinandan Katam"
                    }
                },
                {
                    "Sentence ID": 18,
                    "Sentence": "develop\nsimulators for indoor object detection. Robotic simulators include AI-2THOR ",
                    "Citation Text": "Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro Herrasti,\nDaniel Gordon, Yuke Zhu, Abhinav Gupta, and Ali Farhadi. AI2-THOR: An interactive 3D\nenvironment for visual AI. arXiv preprint arXiv:1712.05474 , 2017.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:1712.05474",
                        "Citation Paper Title": "Title:AI2-THOR: An Interactive 3D Environment for Visual AI",
                        "Citation Paper Abstract": "Abstract:We introduce The House Of inteRactions (THOR), a framework for visual AI research, available at this http URL. AI2-THOR consists of near photo-realistic 3D indoor scenes, where AI agents can navigate in the scenes and interact with objects to perform tasks. AI2-THOR enables research in many different domains including but not limited to deep reinforcement learning, imitation learning, learning by interaction, planning, visual question answering, unsupervised representation learning, object detection and segmentation, and learning models of cognition. The goal of AI2-THOR is to facilitate building visually intelligent models and push the research forward in this domain.",
                        "Citation Paper Authors": "Authors:Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro Herrasti, Matt Deitke, Kiana Ehsani, Daniel Gordon, Yuke Zhu, Aniruddha Kembhavi, Abhinav Gupta, Ali Farhadi"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2107.05369v2": {
            "Paper Title": "How to Approximate Ontology-Mediated Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/2101.12602v3": {
            "Paper Title": "On the differential privacy of dynamic location obfuscation with\n  personalized error bounds",
            "Sentences": [
                {
                    "Sentence ID": 12,
                    "Sentence": ", see Fig. 4, For convenience, our grid is\nwith the cell scale 1km \u00021km and prior distribution \u0019values\nare uniformly and randomly generated in [0:01;0:03], seeJOURNAL OF LATEX CLASS FILES, VOL. XX, NO. X, MONTH 20XX 4 ",
                    "Citation Text": "S. Zhang, B. Duan, Z. Chen, T. Ni, and H. Zhong,\n\u201cRegionalized location obfuscation mechanism\nwith personalized privacy levels,\u201d arXiv eprint,\narXiv:2102.00654, Submitted , 2021.",
                    "Citation": {
                        "Citation Paper ID": "arXiv:2102.00654",
                        "Citation Paper Title": "Title:DPIVE: A Regionalized Location Obfuscation Scheme with Personalized Privacy Levels",
                        "Citation Paper Abstract": "Abstract:The popularity of cyber-physical systems is fueling the rapid growth of location-based services. This poses the risk of location privacy disclosure. Effective privacy preservation is foremost for various mobile applications. Recently, geo-indistinguishability and expected inference error are proposed for limiting location leakages. In this paper, we argue that personalization means regionalization for geo-indistinguishability, and we propose a regionalized location obfuscation mechanism called DPIVE with personalized utility sensitivities. This substantially corrects the differential and distortion privacy problem of PIVE framework proposed by Yu et al. on NDSS 2017. We develop DPIVE with two phases. In Phase I, we determine disjoint sets by partitioning all possible positions such that different locations in the same set share the Protection Location Set (PLS). In Phase II, we construct a probability distribution matrix in which the rows corresponding to the same PLS have their own sensitivity of utility (PLS diameter). Moreover, by designing QK-means algorithm for more search space in 2-D space, we improve DPIVE with refined location partition and present fine-grained personalization, enabling each location to have its own privacy level endowed with a customized privacy budget. Experiments with two public datasets demonstrate that our mechanisms have the superior performance, typically on skewed locations.",
                        "Citation Paper Authors": "Authors:Shun Zhang, Pengfei Lan, Benfei Duan, Zhili Chen, Hong Zhong, Neal N. Xiong"
                    }
                }
            ]
        },
        "http://arxiv.org/abs/2007.06540v2": {
            "Paper Title": "Open Data Quality",
            "Sentences": []
        },
        "http://arxiv.org/abs/2005.11317v2": {
            "Paper Title": "Privacy-Preserving Clustering of Unstructured Big Data for Cloud-Based\n  Enterprise Search Solutions",
            "Sentences": []
        },
        "http://arxiv.org/abs/2011.00096v3": {
            "Paper Title": "Independence in Infinite Probabilistic Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/2008.02352v6": {
            "Paper Title": "Efficient Compactions Between Storage Tiers with PrismDB",
            "Sentences": []
        },
        "http://arxiv.org/abs/2005.03468v2": {
            "Paper Title": "Indexing Metric Spaces for Exact Similarity Search",
            "Sentences": []
        },
        "http://arxiv.org/abs/2004.02580v3": {
            "Paper Title": "Distributed Processing of k Shortest Path Queries over Dynamic Road\n  Networks",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.03600v2": {
            "Paper Title": "Anomaly Detection in Large Labeled Multi-Graph Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/2008.09511v2": {
            "Paper Title": "Tuple-Independent Representations of Infinite Probabilistic Databases",
            "Sentences": []
        },
        "http://arxiv.org/abs/2012.03513v4": {
            "Paper Title": "Adaptive Deep Learning for Entity Resolution by Risk Analysis",
            "Sentences": []
        },
        "http://arxiv.org/abs/2006.06053v2": {
            "Paper Title": "Causal Feature Selection for Algorithmic Fairness",
            "Sentences": []
        },
        "http://arxiv.org/abs/2008.12379v4": {
            "Paper Title": "Factor Windows: Cost-based Query Rewriting for Optimizing Correlated\n  Window Aggregates",
            "Sentences": []
        },
        "http://arxiv.org/abs/2006.12101v4": {
            "Paper Title": "P3GM: Private High-Dimensional Data Release via Privacy Preserving\n  Phased Generative Model",
            "Sentences": []
        },
        "http://arxiv.org/abs/2008.00297v2": {
            "Paper Title": "The Price of Tailoring the Index to Your Data: Poisoning Attacks on\n  Learned Index Structures",
            "Sentences": []
        },
        "http://arxiv.org/abs/2001.06358v3": {
            "Paper Title": "Generative Datalog with Continuous Distributions",
            "Sentences": []
        },
        "http://arxiv.org/abs/2008.04443v3": {
            "Paper Title": "(Almost) All of Entity Resolution",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.06037v3": {
            "Paper Title": "Streaming enumeration on nested documents",
            "Sentences": []
        },
        "http://arxiv.org/abs/2009.04540v2": {
            "Paper Title": "Semantic Indexes for Machine Learning-based Queries over Unstructured\n  Data",
            "Sentences": []
        },
        "http://arxiv.org/abs/2004.00827v4": {
            "Paper Title": "Approximate Selection with Guarantees using Proxies",
            "Sentences": []
        },
        "http://arxiv.org/abs/2003.03079v2": {
            "Paper Title": "Language-aware Indexing for Conjunctive Path Queries",
            "Sentences": []
        },
        "http://arxiv.org/abs/2009.06206v5": {
            "Paper Title": "On Robustness and Bias Analysis of BERT-based Relation Extraction",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.08238v5": {
            "Paper Title": "Toward Evaluating Re-identification Risks in the Local Privacy Model",
            "Sentences": []
        },
        "http://arxiv.org/abs/2011.02615v3": {
            "Paper Title": "Competitive Data-Structure Dynamization",
            "Sentences": []
        },
        "http://arxiv.org/abs/2011.07423v3": {
            "Paper Title": "Declarative Approaches to Counterfactual Explanations for Classification",
            "Sentences": []
        },
        "http://arxiv.org/abs/2007.03014v2": {
            "Paper Title": "Topic-based Community Search over Spatial-Social Networks (Technical\n  Report)",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.03653v8": {
            "Paper Title": "Efficient Temporal Pattern Mining in Big Time Series Using Mutual\n  Information -- Full Version",
            "Sentences": []
        },
        "http://arxiv.org/abs/2002.09172v2": {
            "Paper Title": "Star Pattern Fragments: Accessing Knowledge Graphs through Star Patterns",
            "Sentences": []
        },
        "http://arxiv.org/abs/1902.02698v3": {
            "Paper Title": "Ranked Enumeration of Conjunctive Query Results",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.13442v2": {
            "Paper Title": "A Purely Regular Approach to Non-Regular Core Spanners",
            "Sentences": []
        },
        "http://arxiv.org/abs/1912.12740v4": {
            "Paper Title": "Practice of Streaming Processing of Dynamic Graphs: Concepts, Models,\n  and Systems",
            "Sentences": []
        },
        "http://arxiv.org/abs/2008.03053v2": {
            "Paper Title": "Efficient and Optimal Algorithms for Tree Summarization with Weighted\n  Terminologies",
            "Sentences": []
        },
        "http://arxiv.org/abs/2004.03488v2": {
            "Paper Title": "Modularis: Modular Relational Analytics over Heterogeneous Distributed\n  Platforms",
            "Sentences": []
        },
        "http://arxiv.org/abs/2002.09440v3": {
            "Paper Title": "A Toolkit for Generating Code Knowledge Graphs",
            "Sentences": []
        },
        "http://arxiv.org/abs/2009.10669v2": {
            "Paper Title": "There is No Such Thing as an \"Index\"! or: The next 500 Indexing Papers",
            "Sentences": []
        },
        "http://arxiv.org/abs/2005.14068v4": {
            "Paper Title": "Discovering Domain Orders through Order Dependencies",
            "Sentences": []
        },
        "http://arxiv.org/abs/2002.03614v4": {
            "Paper Title": "RDFFrames: Knowledge Graph Access for Machine Learning Tools",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.05073v3": {
            "Paper Title": "Exathlon: A Benchmark for Explainable Anomaly Detection over Time Series",
            "Sentences": []
        },
        "http://arxiv.org/abs/2009.11558v2": {
            "Paper Title": "An Analysis of Concurrency Control Protocols for In-Memory Databases\n  with CCBench (Extended Version)",
            "Sentences": []
        },
        "http://arxiv.org/abs/2009.00524v3": {
            "Paper Title": "Tensor Relational Algebra for Machine Learning System Design",
            "Sentences": []
        },
        "http://arxiv.org/abs/1907.00062v2": {
            "Paper Title": "DIEL: Interactive Visualization Beyond the Here and Now",
            "Sentences": []
        },
        "http://arxiv.org/abs/2011.01024v3": {
            "Paper Title": "Efficient Data Management with a Flexible Address Space",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.09394v2": {
            "Paper Title": "Knowledge Graph-based Question Answering with Electronic Health Records",
            "Sentences": []
        },
        "http://arxiv.org/abs/2005.13762v3": {
            "Paper Title": "CedrusDB: Persistent Key-Value Store with Memory-Mapped Lazy-Trie",
            "Sentences": []
        },
        "http://arxiv.org/abs/2010.14227v2": {
            "Paper Title": "Efficient, Simple and Automated Negative Sampling for Knowledge Graph\n  Embedding",
            "Sentences": []
        },
        "http://arxiv.org/abs/1906.09727v3": {
            "Paper Title": "Bag Query Containment and Information Theory",
            "Sentences": []
        },
        "http://arxiv.org/abs/2007.04503v6": {
            "Paper Title": "Efficient Trajectory Compression and Range Query Processing",
            "Sentences": []
        }
    }
}